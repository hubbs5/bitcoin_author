[, --DavidChaum , Sound good?Well, there's a little matter that it would lead to a paradigm shift from theway electronic transactions are handled in our society, where credit card usepredominates. But still--aren't you worried that your privacy will becomeillusory as information goes increasingly online: that you may be forced totrade some rights and some independence for the efficiencies and miracles ofthe digital age? , Chaum has spent his professional life in creativeconfrontation with this issue. After teaching at New York University and theUniversity of California, in 1990 Chaum founded a company, DigiCash, as a placewhere a contrary vision could have a voice. Interestingly enough, DigiCashbegan its life making a wallet with observer system for an automatic highway: asmart card that was put in a cigarette-pack-size, in-car unit integrated withthe dashboard. The card made payment as the car drove by at highway speeds,without (of course!) identifying the vehicle. DigiCash went on to create itswell-known online payments system, eCash. , Chaum also built up the Center forInformation Science in Amsterdam, and founded the International Association forCryptographic Research. We hope you enjoy the provocative ideas of one of theleaders in cryptographic research. , What'srequired for electronic commerce to take off?, Universalaccess to the necessary hardware is being addressed to some extent by thelow-cost network computer and merge with television. It's still true of coursethat more than half the people in the world have never even used a telephone.But the penetration of Net access in developed countries is beginning to reachcritical mass. , The third issue is that of privacy. I've been collectingsurveys lately on the extent to which consumers feel privacy is an obstacle totheir adoption of electronic commerce, and I'm finding that across all of thesurveys, consistently, privacy is a major issue. , While many people arefocused on making computers do more, to solve the first two problems, a few ofus are focused on technology for ensuring that there are certain thingscomputers will not do, such as invade your privacy. , Now when consumers find themselves in cyberspace andsee how powerful information technology is, I believe there will be a secondwave of concern. And this is what we may be starting to see in the surveys. Forexample, a Louis Harris poll reported a majority of Americans said they wouldnot use electronic commerce unless their privacy was protected. A surveypublished by MasterCard reported that privacy was among people's major concernsabout electronic commerce, and it was also a major benefit they hoped to getfrom e-commerce. And a poll, somewhat ironically commissioned by TRUSTe,revealed that a vast majority of respondents wish to control their owninformation, not just to rely on what an organization says it will not do withthe data. , All other viable technologies require theconsumer to trust the system providers, and even other parties, to effectivelyprotect and never misuse information. , Claude Shannon was the first to provide a proof thatsuch codes are unbreakable.1 He showed it for the "onetime pad" in which each bit of message content is XOR'd with a freshbit of random key. You can stare at a coded bit as long as you like, but you'llnever learn anything from it about whether its hiding a one or a zero messagebit, because you can learn nothing about the key that determines whether or notthe message bit was flipped to form the coded bit. , Such security has untilnow only been used to protect the secrecy of message content or keys--forexample, spy agencies use it. With computational security, such as is providedby DES, RSA, and elliptic curves, the system can be broken with enoughcomputing power. And we can't prove there isn't a clever trick that would beable to break them on a PC in seconds. In fact, for RSA we now know that aquantum computer could crack any key immediately.2, I think it willbecome more and more unreasonable to ask consumers to trust their informationalrights to a merely computationally secure system. Already many people suspectgovernment can break a lot of codes. This kind of worry reduces consumerconfidence; it's so much better if consumers are able to protect their owninterests. , These days the threat to privacy is not simply Big Brother andthe government. It also includes commercial and even extremist groups. , Thirdis what I've called credentials, which are actually a generalization ofpayments, and ultimately comprise the whole database of information about theconsumer, which today is distributed among the various organizations thatconsumers identify themselves to. But with the solution that I proposed,3 which uses a system of digital pseudonyms, control can be returned to theindividual. , It's like in the good old days when people carried documentssuch as letters of credit. In this system consumers maintain their owndatabases, and organizations know each consumer only under a unique pseudonymfor that relationship. An organization can make a query to a consumer, and theconsumer can prove he or she is answering correctly without revealing thesubstantiating data. If an organization wishes to add data to your database,they give you a signature, called a credential, on your pseudonym with them,which lets you use that data as a basis for proofs in answering subsequentqueries from other organizations. , First, I wantedto find out whether the technology could be used for evil. And second, I wantedto know how likely it would be to have a major positive impact. So I read abunch of stuff and talked to all kinds of people. I convinced myself it wasvery unlikely to be useful for bad purposes because its primary effect would beto distribute power and control. And I figured there was a 40 percentprobability it could have a very significant impact on the direction ofsociety. I really saw a divergence of worlds as information technology matured,with no middle ground: either a very ugly world driven by the inertia of thecurrent paradigm or something that could actually maintain and take us furtherin the direction of democracy. , Now it simply may have been a bit early because PDA's and suchstill seemed like science fiction in the mid-1980s, and even personal computersweren't really up to the cryptography then. But I decided that this conceptwasn't going to be given a chance unless someone actually proved that it wouldwork--proved it not in the sense that scientists use the term, but in the morepopular sense, to actually realize it, make it a commercially viable option.That was a whole other level of effort and that's what I founded the company todo. , However, this kind of system is whatcan easily be built, and I realized 15 years ago it was likely to be built,because it's the natural extension of the current paradigm of how we handleconsumer interactions. But the super-fine granularity and the authentication wenow have makes an enormous qualitative difference. , Your PC first creates "blank" coins thatare actually just random numbers. It then hides or "blinds" these byplacing them in envelopes, actually just a layer of special encryption usingsecret keys formed by and known only to your PC. The bank then deducts theamount from your account and signs the blinded blank coins, using an RSAdigital signature. , Then the PC removes the envelopes, using its secret keys,and stores the signed unblinded coins on its hard disc. Because the blindingcommutes with the signature, your PC can remove the blinding while leaving thesignature on the coin number. When you pay a merchant with some of the coins,it forwards them to the bank and waits to hear back before accepting thepayment. To ensure they haven't been spent before, the bank checks its list ofalready spent coins. And since they have the bank's signature on them, the bankknows that it must honor the payment to the merchant. But the bank has no ideafrom which account the coins were withdrawn, and thus has no knowledge of whothe payer was--since all the coins were blinded during withdrawal. , The systemprotects where, when, and on what you spend your money. And only you can spendyour money and nobody can stop you from being able to make payments--no matterwhat kind of mistakes your bank makes. Moreover, you have complete computerizedrecords and digitally signed receipts of every payment made. , Also, since eCash must be depositedimmediately when it is received in payment, to prevent someone else fromdepositing it first, banks can provide tax authorities up-to-the-minuteinformation on revenue received by each participant. The nice thing about eCashis that it offers protections to society in a way that is acceptable to asociety with our values. , Prepaidtelephone cards are the only way you can make phone calls at outside phonebooths in increasingly many countries apart from the US. Because the consumerbuys the card with cash, it's assumed to have the anonymity of cash. , Butevery time the card is used, a central record is made of the card's uniqueserial number, the telephone numbers, and times. Now it's not too hard todiscover which card is yours, by, for instance, looking for particular numbers,such as your home or office. The succession of similarly profiled cards used bythe same individual can be pieced together, resulting in a surprisinglydetailed history of a person's movements and associations. Yet people thinkthat they are anonymous and are accordingly uninhibited in their use of thecards. , There are other, more blatant, examples of false privacy. Prepaidsmart cards tied to bank accounts, for example, are even easier for theoperator to trace, but some have been advertised to consumers as providing "the privacy of cash." Similarly, credit card use on the Internet is fullytraceable by those operating the system, although some have claimed privacy asa feature. , There's economic pressureto put a lot on each card because it costs a lot to make them and get them intopeople's hands. A simple prepaid card is a break-even proposition, if that. Thegame then is how to rent out space. Unfortunately, from a privacy point ofview, the more you put on the same card, the worse it is. , The terminal maydisplay that it's taking a dollar, but it may take a hundred dollars, read outyour medical history, change your insurance, or simply put 110 volts across thechip and fry it. , Evenif it's supposed to use blinding, you can't really be sure that it is doing theblinding, or that it doesn't choose the keys used in the blinding according tosome pre-arranged scheme. There might be some trap door in it; it may savethings and later spit it out if it's given a certain command. So there can beall kinds of Trojan horses and traps that could be built into the card, andthey may or may not be detectable. , Because of this, what I see as the onlysatisfactory consumer platform for transactions is a device the consumer caninteract with directly. It's a workstation, a PDA, a cell phone, a dictationmachine, a digital camera. In the future these will be combined. Whatever thecombination, it will have the user interface that you choose, and it will keeptrack of a lot of things for you. , For offline use, there may have to be atamper-resistant smart-card chip involved. Now there are two basic places toput that chip. You can either put it at the front end of the PDA so that ittalks to the outside world directly and you don't know what's going on, or youcan put it at the back end, so that all communication between that chip and theoutside world is going through your PDA. I think the latter model is clearlymore appropriate. , It's through that hybrid ofconsumer-controlled device and smart card chip that you can arguably stillderive all the benefits of tamper-resistant cards for society, such as offlinetransactions, but maintain the paradigm where consumers are in control of theirown information. , If you put a card in a thin-client device, again you don'tknow what is being done with it. It's only where you have your own PDA, whereyou can see what you're agreeing to on your own equipment before you agree,where you can input agreement directly, and where you can be sure that thosecontrolling the terminal are not in effect pretending to be you, that youobtain a really sound system. Using a lesser technique doesn't get you veryfar. You really will want to be able to see and control what is done with yourcard. , The terminal could ofcourse just as easily communicate directly with issuing banks as with a singleacquirer, because it's basically getting onto the Internet. When you make thatleap, the whole credit card infrastructure becomes questionable. SET is aneffort to buttress that structure, to integrate and entrench the whole model ofcard association, issuer, and acquirer. , DigiCashhas been pretty successful with this product. We've licensed it to banks onthree continents, including the largest bank in half-a-dozen European countriesand some of the largest institutions in Japan. , It is certainly true,however, that the market for micropayments has not materialized as quickly asmany expected. You're dealing with the chicken and egg sort of phenomenon:people aren't really going to use it until a lot of merchants are supportingit, and merchants won't support it until a lot of people are using it. There issome inertia, which we believe we are beginning to overcome. , Onthe other hand, I'm a big believer in banks. Our company believes in workingwith banks to strengthen their future role, because banks have funded what theycall "The Payment System," which is the backbone of the money movingnetwork. It's a very unglamorous but very costly mechanism which many tend totake for granted. , Having control over electronic cash, and being the keyintermediary, may be an important way for banks to segue their consumerrelationships into the cyber world. That's the all-important transition,because retail banking today is based on the bundling of what are notindividually extremely competitive products and building a valuable customerrelationship. ECash requires you to return to the bank's digital branchrelatively frequently to get more, and that gives banks an opportunity topromote their franchise, make the first offer, cross-sell, and generallycultivate the relationship. , Somegovernment will be the first to say something like, "Okay, we're not goingto support this stuff any more, it facilitates all these bad things, it's veryexpensive, and it does not work over the net, so we need another systemanyway--we're going to move to an electronic cash system." , Who's goingto take the lead in electronic commerce is not yet decided. These are earlydays, and those that make the right move will own the future. * , REFERENCES , , , , , , , , NextIssue's Interview:Dan Connolly , , , , ]
[This article appeared in Scientific American, August 1992, p. 96-101. Copyright (c) 1992 by Scientific American, Inc., , Organizations link records from different sources for their own protection. Certainly it is in the interest of a bank looking at a loan application to know that John Doe has defaulted on four similar loans in the past two years. The bank's possession of that information also helps its other customers, to whom the bank passes on the cost of bad loans. In addition, these records permit Jane Roe, whose payment history is impeccable, to establish a charge account at a shop that has never seen her before., That same information in the wrong hands, however, provides neither protection for businesses nor better service for consumers. Thieves routinely use a stolen credit card number to trade on their victims' good payment records; murderers have tracked down their targets by consulting government-maintained address records. On another level, the U.S. Internal Revenue Service has attempted to single out taxpayers for audits based on estimates of household income compiled by mailing-list companies., The growing amounts of information that different organizations collect about a person can be linked because all of them use the same key in the U.S. the social security number to identify the individual in question. This identifier-based approach perforce trades off security against individual liberties. The more information that organizations have (whether the intent is to protect them from fraud or simply to target marketing efforts), the less privacy and control people retain., Over the past eight years, my colleagues and I at CWI (the Dutch nationally funded Center for Mathematics and Computer Science in Amsterdam) have developed a new approach, based on fundamental theoretical and practical advances in cryptography, that makes this trade-off unnecessary. Transactions employing these techniques avoid the possibility of fraud while maintaining the privacy of those who use them., In our system, people would in effect give a different (but definitively verifiable) pseudonym to every organization they do business with and so make dossiers impossible. They could pay for goods in untraceable electronic cash or present digital credentials that serve the function of a banking passbook, driver's license or voter registration card without revealing their identity. At the same time, organizations would benefit from increased security and lower record-keeping costs., Recent innovations in microelectronics make this vision practical by providing personal "representatives" that store and manage their owners' pseudonyms, credentials and cash. Microprocessors capable of carrying out the necessary algorithms have already been embedded in pocket computers the size and thickness of a credit card. Such systems have been tested on a small scale and could be in widespread use by the middle of this decade., , To see how digital signatures can provide all manner of unforgeable credentials and other services, consider how they might be used to provide an electronic replacement for cash. The First Digital Bank would offer electronic bank notes: messages signed using a particular private key. All messages bearing one key might be worth a dollar, all those bearing a different key five dollars, and so on for whatever denominations were needed. These electronic bank notes could be authenticated using the corresponding public key, which the bank has made a matter of record. First Digital would also make public a key to authenticate electronic documents sent from the bank to its customers., To withdraw a dollar from the bank, Alice generates a note number (each note bears a different number, akin to the serial number on a bill); she chooses a 100-digit number at random so that the chance anyone else would generate the same one is negligible. She signs the number with the private key corresponding to her "digital pseudonym" (the public key that she has previously established for use with her account). The bank verifies Alice's signature and removes it from the note number, signs the note number with its worth-one-dollar signature and debits her account. It then returns the signed note along with a digitally signed withdrawal receipt for Alice's records. In practice, the creation, signing and transfer of note numbers would be carried out by Alice's card computer. The power of the cryptographic protocols, however, lies in the fact that they are secure regardless of physical medium: the same transactions could be carried out using only pencil and paper., When Alice wants to pay for a purchase at Bob's shop, she connects her "smart" card with his card reader and transfers one of the signed note numbers the bank has given her. After verifying the bank's digital signature, Bob transmits the note to the bank, much as a merchant verifies a credit card transaction today. The bank reverifies its signature, checks the note against a list of those already spent and credits Bob's account. It then transmits a "deposit slip," once again unforgeably signed with the appropriate key. Bob hands the merchandise to Alice along with his own digitally signed receipt, completing the transaction., This system provides security for all three parties. The signatures at each stage prevent any one from cheating either of the others: the shop cannot deny that it received payment, the bank cannot deny that it issued the notes or that it accepted them from the shop for deposit, and the customer can neither deny withdrawing the notes from her account nor spend them twice., This system is secure, but it has no privacy. If the bank keeps track of note numbers, it can link each shop's deposit to the corresponding withdrawal and so determine precisely where and when Alice (or any other account holder) spends her money. The resulting dossier is far more intrusive than those now being compiled. Furthermore, records based on digital signatures are more vulnerable to abuse than conventional files. Not only are they self-authenticating (even if they are copied, the information they contain can be verified by anyone), but they also permit a person who has a particular kind of information to prove its existence without either giving the information away or revealing its source. For example, someone might be able to prove incontrovertibly that Bob had telephoned Alice on 12 separate occasions without having to reveal the time and place of any of the calls., I have developed an extension of digital signatures, called blind signatures, that can restore privacy. Before sending a note number to the bank for signing, Alice in essence multiplies it by a random factor. Consequently, the bank knows nothing about what it is signing except that it carries Alice's digital signature. After receiving the blinded note signed by the bank, Alice divides out the blinding factor and uses the note as before., The blinded note numbers are "unconditionally untraceable" that is, even if the shop and the bank collude, they cannot determine who spent which notes. Because the bank has no idea of the blinding factor, it has no way of linking the note numbers that Bob deposits with Alice's withdrawals. Whereas the security of digital signatures is dependent on the difficulty of particular computations, the anonymity of blinded notes is limited only by the unpredictability of Alice's random numbers. If she wishes, however, Alice can reveal these numbers and permit the notes to be stopped or traced., Blinded electronic bank notes protect an individual's privacy, but because each note is simply a number, it can be copied easily. To prevent double spending, each note must be checked on-line against a central list when it is spent. Such a verification procedure might be acceptable when large amounts of money are at stake, but it is far too expensive to use when someone is just buying a newspaper. To solve this problem, my colleagues Amos Fiat and Moni Naor and I have proposed a method for generating blinded notes that requires the payer to answer a random numeric query about each note when making a payment. Spending such a note once does not compromise unconditional untraceability, but spending it twice reveals enough information to make the payer's account easily traceable. In fact, it can yield a digitally signed confession that cannot be forged even by the bank., Cards capable of such anonymous payments already exist. Indeed, DigiCash, a company with which I am associated, has installed equipment in two office buildings in Amsterdam that permits copiers, fax machines, cafeteria cash registers and even coffee vending machines to accept digital "bank notes." We have also demonstrated a system for automatic toll collection in which automobiles carry a card that responds to radioed requests for payment even as they are travelling at highway speeds., , Indeed, such computers can act as representatives for their owners in virtually any kind of transaction. Bob can trust his representative and Alice hers because they have each chosen their own machine and can reprogram it at will (or, in principle, build it from scratch). Organizations are protected by the cryptographic protocol and so do not have to trust the representatives., The prototypical representative is a smart credit-card-size computer containing memory and a microprocessor. It also incorporates its own keypad and display so that its owner can control the data that are stored and exchanged. If a shop provided the keypad and display, it could intercept passwords on their way to the card or show one price to the customer and another to the card. Ideally, the card would communicate with terminals in banks and shops by a short-range communications link such as an infrared transceiver and so need never leave its owner's hands., When asked to make a payment, the representative would present a summary of the particulars and await approval before releasing funds. It would also insist on electronic receipts from organizations at each stage of all transactions to substantiate its owner's position in case of dispute. By requiring a password akin to the PIN (personal identifying number) now used for bank cards, the representative could safeguard itself from abuse by thieves. Indeed, most people would probably keep backup copies of their keys, electronic bank notes and other data; they could recover their funds if a representative were lost or stolen., Personal representatives offer excellent protection for individual privacy, but organizations might prefer a mechanism to protect their interests as strongly as possible. For example, a bank might want to prevent double spending of bank notes altogether rather than simply detecting it after the fact. Some organizations might also want to ensure that certain digital signatures are not copied and widely disseminated (even though the copying could be detected afterwards)., Organizations have already begun issuing tamperproof cards (in effect, their own representatives) programmed to prevent undesirable behavior. But these cards can act as "Little Brothers" in everyone's pocket., We have developed a system that satisfies both sides. An observer a tamper-resistant computer chip, issued by some entity that organizations can trust acts like a notary and certifies the behavior of a representative in which it is embedded. Philips Industries has recently introduced a tamperresistant chip that has enough computing power to generate and verify digital signatures. Since then, Siemens, Thomson CSF and Motorola have announced plans for similar circuits, any of which could easily serve as an observer., The central idea behind the protocol for observers is that the observer does not trust the representative in which it resides, nor does the representative trust the observer. Indeed, the representative must be able to control all data passing to or from the observer; otherwise the tamperproof chip might be able to leak information to the world at large., When Alice first acquires an observer, she places it in her smart-card representative and takes it to a validating authority. The observer generates a batch of public and private key pairs from a combination of its own random numbers and numbers supplied by the card. The observer does not reveal its numbers but reveals enough information about them so that the card can later check whether its numbers were in fact used to produce the resulting keys. The card also produces random data that the observer will use to blind each key., Then the observer blinds the public keys, signs them with a special built-in key and gives them to the card. The card verifies the blinding and the signature and checks the keys to make sure they were correctly generated. It passes the blinded, signed keys to the validating authority, which recognizes the observer's built-in signature, removes it and signs the blinded keys with its own key. The authority passes the keys back to the card, which unblinds them. These keys, bearing the signature of the validating authority, serve as digital pseudonyms for future transactions; Alice can draw on them as needed., , Many transactions do not simply require a transfer of money. Instead they involve credentials information about an individual's relationship to some organization. In today's identifier-based world, all of a person's credentials are easily linked. If Alice is deciding whether to sell Bob insurance, for example, she can use his name and date of birth to gain access to his credit status, medical records, motor vehicle file and criminal record, if any., Using a representative, however, Bob would establish relationships with different organizations under different digital pseudonyms. Each of them can recognize him unambiguously, but none of their records can be linked., In order to be of use, a digital credential must serve the same function as a paper-based credential such as a driver's license or a credit report. It must convince someone that the person attached to it stands in a particular relation to some issuing authority. The name, photograph, address, physical description and code number on a driver's license, for example, serve merely to link it to a particular person and to the corresponding record in a data base. Just as a bank can issue unforgeable, untraceable electronic cash, so too could a university issue signed digital diplomas or a credit-reporting bureau issue signatures indicating a person's ability to repay a loan., When the young Bob graduates with honors in medieval literature, for example, the university registrar gives his representative a digitally signed message asserting his academic credentials. When Bob applies to graduate school, however, he does not show the admissions committee that message. Instead his representative asks its observer to sign a statement that he has a B.A. cum laude and that he qualifies for financial aid based on at least one of the university's criteria (but without revealing which ones). The observer, which has verified and stored each of Bob's credentials as they come in, simply checks its memory and signs the statement if it is true., In addition to answering just the right question and being more reliable than paper ones, digital credentials would be both easier for individuals to obtain and to show and cheaper for organizations to issue and to authenticate. People would no longer need to fill out long and revealing forms. Instead their representatives would convince organizations that they meet particular requirements without disclosing any more than the simple fact of qualification. Because such credentials reveal no unnecessary information, people would be willing to use them even in contexts where they would not willingly show identification, thus enhancing security and giving the organization more useful data than it would otherwise acquire., Positive credentials, however, are not the only kind that people acquire. They may also acquire negative credentials, which they would prefer to conceal: felony convictions, license suspensions or statements of pending bankruptcy. In many cases, individuals will give organizations the right to inflict negative credentials on them in return for some service. For instance, when Alice borrows books from a library, her observer would be instructed to register an overdue notice unless it had received a receipt for the books' return within some fixed time., Once the observer has registered a negative credential, an organization can find out about it simply by asking the observer (through the representative) to sign a message attesting to its presence or absence. Although a representative could muzzle the observer, it could not forge an assertion about the state of its credentials. In other cases, organizations might simply take the lack of a positive credential as a negative one. If Bob signs up for skydiving lessons, his instructors may assume that he is medically unfit unless they see a credential to the contrary., For most credentials, the digital signature of an observer is sufficient to convince anyone of its authenticity. Under some circumstances, however, an organization might insist that an observer demonstrate its physical presence. Otherwise, for example, any number of people might be able to gain access to nontransferable credentials (perhaps a health club membership) by using representatives connected by concealed communications links to another representative containing the desired credential., Moreover, the observer must carry out this persuasion while its input and output are under the control of the representative that contains it. When Alice arrives at her gym, the card reader at the door sends her observer a series of single-bit challenges. The observer immediately responds to each challenge with a random bit that is encoded by the card on its way back to the organization. The speed of the observer's response establishes that it is inside the card (since processing a single bit introduces almost no delay compared with the time that signals take to traverse a wire). After a few dozen iterations the card reveals to the observer how it encoded the responses; the observer signs a statement including the challenges and encoded responses only if it has been a party to that challengeresponse sequence. This process convinces the organization of the observer's presence without allowing the observer to leak information., Organizations can also issue credentials using methods that depend on cryptography alone rather than on observers. Although currently practical approaches can handle only relatively simple queries, Gilles Brassard of the University of Montreal, Claude Cripeau of the Icole Normale Supirieure and I have shown how to answer arbitrary combinations of questions about even the most complex credentials while maintaining unconditional unlinkability. The concealment of purely cryptographic negative credentials could be detected by the same kinds of techniques that detect double spending of electronic bank notes. And a combination of these cryptographic methods with observers would offer accountability after the fact even if the observer chip were somehow compromised., , Current tamper-resistant systems such as ATMs and their associated cards typically rely on weak, inflexible security procedures because they must be used by people who are neither highly competent nor overly concerned about security. If people supply their own representatives, they can program them for varying levels of security as they see fit. (Those who wish to trust their assets to a single four-digit code are free to do so, of course.) Bob might use a short PIN (or none at all) to authorize minor transactions and a longer password for major ones. To protect himself from a robber who might force him to give up his passwords at gunpoint, he could use a "duress code" that would cause the card to appear to operate normally while hiding its more important assets or credentials or perhaps alerting the authorities that it had been stolen., A personal representative could also recognize its owner by methods that most people would consider unreasonably intrusive in an identifier-based system; a notebook computer, for example, might verify its owner's voice or even fingerprints. A supermarket checkout scanner capable of recognizing a person's thumbprint and debiting the cost of groceries from their savings account is Orwellian at best. In contrast, a smart credit card that knows its owner's touch and doles out electronic bank notes is both anonymous and safer than cash. In addition, incorporating some essential part of such identification technology into the tamperproof observer would make such a card suitable even for very high security applications., , If the trend toward identifier-based smart cards continues, personal privacy will be increasingly eroded. But in this conflict between organizational security and individual liberty, neither side emerges as a clear winner. Each round of improved identification techniques, sophisticated data analysis or extended linking can be frustrated by widespread noncompliance or even legislated limits, which in turn may engender attempts at further control., Meanwhile, in a system based on representatives and observers, organizations stand to gain competitive and political advantages from increased public confidence (in addition to the lower costs of pseudonymous record-keeping). And individuals, by maintaining their own cryptographically guaranteed records and making only necessary disclosures, will be able to protect their privacy without infringing on the legitimate needs of those with whom they do business., The choice between keeping information in the hands of individuals or of organizations is being made each time any government or business decides to automate another set of transactions. In one direction lies unprecedented scrutiny and control of people's lives, in the other, secure parity between individuals and organizations. The shape of society in the next century may depend on which approach predominates., ]
[Copyright (c) 1994 by DigiCash bv., , Telephone cards used in France and elsewhere are probably the best known prepaid smart cards (though some phone cards use optical or magnetic techniques, which are not considered here). National prepaid systemscombining public transportation, public telephones, merchants, and vendinghave already been announced in a number of countries. And road tolls at full highway speed are not far behind., The systems proposed so far are compared, after a quick look at the card types on which they are based., , , , , , , , Shared-key card systems require a tamper-resistant secured module in each vending machine or other point of payment. The module uses the key it shares with a card to authenticate messages during purchases. This lets the card convince the module that it has reduced its stored value by the correct amount and that it is genuine. A card convinces by using the shared key to encrypt a random challenge issued by the module together with an amount, so that the module can decrypt the transmission and compare the result with the expected challenge and amount. Periodically, the module transmits a similarly authenticated message, via telecommunication or manual collection procedure, back to the system provider, who reimburses the retailer., The secured module in a shared-key system thus needs to store or at least be able to re-create secret keys of all cards, which gives some problems. If the cards of multiple system providers are to be accepted at the same retailers, all the retailers must have secured modules containing keys of every provider. This means either a mutually trusted module containing the keys of multiple providers, which might be hard to achieve, or one module per provider, which becomes impractical as the number of providers grows. Furthermore, in any shared-key system, if a module is penetrated, not only is significant retailer fraud facilitated, but the entire card base may be compromised., Signature-transporting and -creating card types avoid these problems since they do not require secured modules. Cash registers need no secret keys, only public ones, in order to authenticate the signatures, which act like guaranteed checks filled in with all the relevant details. These same signatures can later be verified by the system provider for reimbursement. (Although tamper-resistant modules are not needed for verfication, they can still be used to aggregate transactions.) Both signature-based card types also allow the cards of any number of issuers to be accepted at all retailers; retailers cannot cheat issuers, and issuers cannot cheat each other. These are the only truly open systems., , The reason for identification of shared-key cards is that security is thought to be too low if all cards have the master key. Therefore cards are given unique keys, and the cash register needs the card identity each time to re-create the corresponding unique card key from the master key. , The signature-transporting approach avoids the need for identification, since instead of a single key per card, cards use a different signature per payment. When signatures are made by the system provider on blinded checks that are then unblinded by the card, not even the system provider can trace payments to cards., , Bonding chips into modules, assembling them into cards, and printing can cost about the same for all card types, roughly US$ 0.502.00 (plus the cost of the small fraction of chips that are damaged during production). Nonrefillable cards, however, typically use less durable materials and less costly production techniques., Memory card chips are much smaller, and consequently much less expensive to produce, than those in microcontroller cards. They cost, depending on the type, roughly between US$ 0.100.40 in quantity. Shared-key and signature-transporting cards today use exactly the same chip hardware, only the masked-in software differs. Suitable chips cost about US$ 1.001.20 in quantity. Signature-creating card chips, which need extra circuitry for the co-processor (or a very powerful processor), require more on a chip, are relatively new on the market, and currently cost several times more., , If cards are issued with value on them, as is of course required with nonrefillable memory cards, then they must be transported, stored, and dispensed, using costly security and audit provisions, like those associated with bank notes. Refillable cards can be distributed without value and avoid these costs, but on the other hand require infrastructure for on-line reload transactions with system providers., Retailer equipment costs may be higher than card costs. Typical ratios of cards to points of sale (about 100 to 1 for cash registers and higher with vending, phones, etc.) and even the price of current terminals (about US$ 1501500) suggest that the point-of-sale equipment can be more costly than even a dedicated microcontroller card base. , In the shared-key approach, secured modules trusted by all system providers must be installed in all retailer equipment. In open systems such security modules must be significantly more elaborate and costly than any card, since the security offered by a card is generally considered inadequate to protect the keys of all other cards. But the higher cost of terminals incorporating such modules is at odds with the objective of automating all manner of low value payments, such as in vending. Transaction processing by the system providers also requires tamper-resistant devices. Proper management of keys and auditing of such systems are cumbersome and expensive. If shared-key systems grow, and start to include less trustworthy retailers and more system providers, even the minimum security necessary becomes excessively costly., With either signature card type, suitable softwarenot tamper-resistant modulesis all retailer equipment needs in order to verify payments and later forward the signatures for reimbursement. These can then be verified by any transaction processing computer that has copies of the freely available public keys, thereby reducing exposure while both increasing the quality and reducing the cost of security audit and controls. , , The remaining two card types, shared-key and signature-transporting, can today be based on exactly the same kinds of microcontroller chips, and thus have the same card cost. The system cost with shared-keys, however, is significantly higher than with signature-transporting. The main reason is that shared-keys require tamper-resistant modules at all points of payment and processing sites, while these modules are not needed with signature-transporting. , In addition to cost, there are other reasons to prefer signature-transporting cards for larger systems. Privacy may be an issue in large-scale consumer systems, and the other card types are unable to address this problem, while signature-transporting solves it neatly. When more retailers and system providers are included, as large open systems are built or as closed systems grow and merge, the cost of maintaining even merely acceptable security with shared keys becomes prohibitive. By contrast, signature-transporting maintains a very high level of security while allowing flexible scaling and merging of systems., ]
[--------------- cypherpunks-list #6929 (274 lines) ---------------, Date: Tue Nov 2 12:24:08 1993From: an5877@anon.penet.fi (deadbeat) &lt;an5877/daemon&gt;Subject: Online Cash Checks, -----BEGIN PGP SIGNED MESSAGE-----, Online Cash Checks, David Chaum, Centre for Mathematics and Computer ScienceKruislaan 413 1098SJ Amsterdam, INTRODUCTIONSavings of roughly an order of magnitude in space, storage, and bandwidthover previously published online electronic cash protocols are achieved bythe techniques introduced here. In addition, these techniques can increaseconvenience, make more efficient use of funds, and improve privacy., "Offline" electronic money [CFN 88] is suitable for low valuetransactions where "accountability after the fact" is sufficient to deterabuse; online payment [C 89], however, remains necessary for transactionsthat require "prior restraint" against persons spending beyond theiravailable funds., Three online schemes are presented here. Each relies on the sametechniques for encoding denominations in signatures and for "devaluing"signatures to the exact amount chosen at the time of payment. They differin how the unspent value is returned to the payer. In the first, all change isaccumulated by the payer in a single "cookie jar," which might bedeposited at the bank during the next withdrawal transaction. The secondand third schemes allow change to be distributed among unspent notes,which can themselves later be spent. The second scheme reveals to theshop and bank the maximum amount for which a note can be spent; thethird does not disclose this information., DENOMINATIONS AND DEVALUINGFor simplicity and concreteness, but without loss of generality, aparticular denomination scheme will be used here. It assigns the value of 1cent to public exponent 3 in an RSA system, the value of 2 cents toexponent 5, 4 cents to exponent 7, and so on; each successive power-of-twovalue is represented by the corresponding odd prime public exponent, allwith the same modulus. Much as in [C 89], a third root of an image underthe one-way function f (together with the pre-image modulo the bank'sRSA composite) is worth 1 cent, a 7th root is worth 4 cents, and a 21st root5 cents. In other words, a distinct public prime exponent is associated witheach digit of the binary integer representation of an amount of payment;for a particular amount of payment, the product of all those primeexponents corresponding to 1 's in the binary representation of the amountis the public exponent of the signature., A signature on an image under f is "devalued" by raising it to thepublic powers corresponding to the coin values that should be removed.For instance, a note having a 21st root could be devalued from its 5 centvalue, to 1 cent, simply by raising it to the 7th power., In earlier online payment systems [C 89], the number of separatesignatures needed for a payment was in general the Hamming weight of thebinary representation of the amount. Since online systems would be usedfor higher-value payments (as mentioned above), and extra resolution maybe desired to provide interest for unspent funds [C 89], an average ofroughly an order of magnitude is saved here., COOKIE JAR, In this first scheme the payer periodically withdraws a supply of notesfrom the bank, each with the system-wide maximum value. Consider anexample, shown in Figure 1.1, in which two notes are withdrawn. The nand ri are random. The ri "blind" (from the bank) the images under thepublic, one-way function f. The bank's signature corresponds to taking theh-th root, where h = 3*5*7*11. As in all the figures, the payer sendsmessages from the left and the bank sends from the right., In preparing the first payment, the payer divides r1 out. The signatureis then raised to the 55th power to devalue it from 15 cents to 5 cents.Figure 1.2 shows this first payment. Of course the shop is an intermediarybetween the payer (left) and the bank (right) in every online payment, butthis is not indicated explicitly. Also not shown in the figures are messagesused to agree on the amounts of payment., The first two residues sent in paying, n1 and its signed image under f,are easily verified by the bank to be worth 5 cents. The third residue is ablinded "cookie jar," a blinded image under f of a randomly chosen valuej. This cookie jar is modulo a second RSA composite that is only used forcookie jars. Once the bank verifies the funds received, and that n1 has notbeen spent previously, it signs and returns the blinded cookie jar (underthe cookie jar modulus) with public exponents corresponding to thechange due., The second payment, shown in figure 1.3, is essentially the same as thefirst, except that the amount is 3 cents and the cookie jar now has someroots already on it. If more payments were to be made using the samecookie jar, all resulting signatures for change would accumulate., The cookie jar might conveniently be deposited, as shown in figure1.4, during the withdrawal of the next batch of notes. It is verified by thebank much as a payment note would be: the roots must be present in theclaimed multiplicity and the pre-image under f must not have beendeposited before., The cookie jar approach gives the effect of an online form of "offlinechecks" [C 89], in that notes of a fixed value are withdrawn and the unspentparts later credited to the payer during a refund transaction., DECLARED NOTE VALUE, Figure 2 depicts a somewhat different scheme, which allows change to bespent without an intervening withdrawal transaction. Withdrawals can bejust as in the cookie-jar scheme, but here a single modulus is used foreverything in the system. The products of public exponents representingthe various amounts are as follows: d is the amount paid, g is the notevalue, the "change" c is g/d, and h is again the maximal amount, where d | g| h. A payment (still to the bank through a shop) includes first and secondcomponents that are the same as in the cookie-jar scheme. The thirdcomponent is the amount of change c the payer claims should be returned.The fourth is a (blinded) number m, which could be an image under f usedin a later payment just as n is used in this one., The signature returned contains a "protection" factor (shown insidethe padlock). This factor ensures that the payer actually has the c-th root off(n), by requiring that the payer apply f to it before dividing the result outof the signature. Without such protection, a payer could get the systemwide maximum change, regardless of how much change is actually due;with it, the change claimed can only be recovered if the correspondingroots on n are in fact known to the payer., DISTRIBUTING CHANGEThe change returned in a payment can be divided into parts that fill inmissing denominations in notes not yet spent. Suppose, for example, thatthe last payment is spent with d = 5*11, c = 3*7, and that m is formed bythe payer as shown in the first line of Figure 3.1. Then unblinding afterthe payment yields the a shown in the second line., (Use === for "is equivalent to"), v = 3u div 7, Because overpayment allows change to be returned in any chosendenominations (not shown), the payer has extra flexibility and is able touse all funds held. This also increases convenience by reducing the needfor withdrawals., HIDDEN NOTE VALUEAlthough the combination of the previous two subsections is quiteworkable, it may be desirable for the payer not to have to reveal c to theshop or the bank. Figure 4 shows a system allowing this. The paymentmessage is just as in the declared note value protocol above, except that c isnot sent. The protection factor (shown again in a lock) is also placed underthe signature, but it is missing the extra f and is raised to a random power zchosen by the bank, If z were known to the payer before payment, then the payer could -zcheat by including f(n) in the third component; this would yield the payerthe system-wide maximum change, even if none were due. Consider asingle change exponent q. If z mod q is guessed correctly by a cheatingpayer, then the payer improperly gets the corresponding coin value. Thusthe chance of successful cheating is 1/q. If, however, the divisors of h arechosen sufficiently large, quite practical security can be achieved. Whenthe possibilities of distributing change and refunding are included, thisscheme's privacy surpasses that of a coin system., CONCLUSIONCombining online coins improves efficiency, use of funds, convenience,and privacy., REFERENCES, Chaum, D., "Privacy Protected Payments: Unconditional Payer and/orPayee Anonymity," in Smart Card 2000, North-Holland, 1989, pp. 69-92., Chaum, D., A. Fiat, &amp; M. Naor, "Offline Electronic Cash," Proceedingsof Crypto '88., Brought to you by the Information Liberation Front, and, DEADBEAT &lt;na5877@anon.penet.fi&gt;, -----BEGIN PGP SIGNATURE-----Version: 2.3, iQBFAgUBLNVnzvFZTpBW/B35AQGVAAGAq1L57YI/1zlXVH0LYyHBvbN/2h/RuVeRUf8VSC0gCjvkmy5QnlqXuGM/H2k3R16S=WhD1-----END PGP SIGNATURE-----]
[ , Security without IdentificationCard Computers to make Big Brother Obsolete by David Chaum , You may soon use a personal "card computer" to handle all your payments and other transactions. It can protect your security and privacy in new ways, while benefitting organizations and society at large. , Computerization is robbing individuals of the ability to monitor and control the ways information about them is used. Already, public and private sector organizations acquire extensive personal information and exchange it amongst themselves. Individuals have no way of knowing if this information is inaccurate, outdated, or otherwise inappropriate, and may only find out when they are accused falsely or denied access to services. New and more serious dangers derive from computerized pattern recognition techniques: even a small group using these and tapping into data gathered in everyday consumer transactions could secretly conduct mass surveillance, inferring individuals' lifestyles, activities, and associations. The automation of payment and other consumer transactions is expanding these dangers to an unprecedented extent., Organizations, on the other hand, are attracted to the efficiency and cost-cutting opportunities of such automation. Moreover, they too are vulnerable, as when cash, checks, consumer credit, insurance, or social services are abused by individuals. The obvious solution for organizations is to computerize in ways that use more pervasive and interlinked records, perhaps in combination with national identity cards or even fingerprints. But the resulting potential for misuse of data would have a chilling effect on individuals. Nevertheless, this is essentially the approach of the electronic payment and other automated systems now being tried. Although these systems will require massive investment and years to complete, their underlying architecture is already quietly being decided and their institutional momentum is growing., This momentum is driving us toward a seemingly irreconcilable conflict, between organizations' need for security and the benefits of automation on one side, and individuals' need for ensured privacy and other protections on the other. But this conflict may be avoided by early adoption of a fundamentally different approach to automating transaction systems. This new approach is mutually advantageous: it actually increases organizations' benefits from automating, including improved security, while it frees individuals from the surveillance potential of data linking and other dangers of unchecked record keeping. Its more advanced techniques offer not only wider use at reduced cost, but also greater consumer convenience and protection. In the long run, it holds promise for enhancing economic freedom, the democratic process, and informational rights., Three major differences define the new approach. The first is in the use of identifying information. Currently, many Western countries require citizens to carry documents bearing universal identification numbers. Drivers' licenses are being upgraded to perform a similar function in the United States, and efforts toward machine-readable national identity documents are expanding internationally. Meanwhile, organizations routinely use such essentially identifying data as name, birthday, and birthplace or name and address to match or link their records with those of other organizations., UNIVERSALLY IDENTIFYING NUMBERS or other equivalent identifying information is presented by the individual card holder to each organization---in the current approach. Unrelated generic examples are shown of three kinds of transactions: communation, in which the individual sends an authorizing message and receives a notifying message; payment in which the individual pays an organization or receives a payment; and credential, in which a certification that an individual has some credential is transferred from an organization B to an organization C. The identifying information--845--allows all transactions to be linked together into a dossier on the individual. , Under the new approach, an individual uses a different account number or "digital pseudonym" with each organization. No other identifying information is used. A casual purchase at a shop, for example, might be made under a one-time-use pseudonym; for a series of transactions comprising an ongoing relationship, like a bank account, a single pseudonym would be used repeatedly. Because of the input individuals have into the process by which the pseudonyms are created, they are ensured that their pseudonyms cannot be linked. This input also yields them the exclusive ability to use, and authenticate ownership of, their pseudonyms. Organizations too can protect themselves through their participation in forming the pseudonyms; among other safeguards, they can limit individuals to one pseudonym per organization and ensure that individuals are held accountable for abuses created under any of their pseudonyms., DIFFERENT NUMBERS OR DIGITAL PSEUDONYMS are used with each organization by a personal card computer that the individual completely controls-under the new approach. The credential transfer is no longer just between organizations: it must now go through the card where the pseudonym, 451, used with the issuing organization 3 is transformed to the pseudonym, 314, used with the receiving organization C. Systems using this approach can provide organizations with improved protection against abuses by individuals, and also allow individuals to ensure that pseudonyms cannot be traced across the dashed boundary lines, thereby preventing dossier compilation. , A second difference is in whose mechanism is used to conduct transactions. Today, individuals hold a variety of "tokens" issued to them by organizations. These range from traditional paper documents to plastic cards with magnetic or optical stripes or even embedded microcomputers. Such tokens are usually owned by the issuing organization and contain information that the individual holder can neither decipher nor modify. With the spread of automatic teller and point-of-sale terminals, individuals are being asked to perform more transactions directly using computer-controlled equipment. These terminals, and even the microcomputers in some current tokens, are physically tamper-resistant and contain secret numeric keys that securely code their communication with central computers. Individuals derive little direct benefit from these security provisions, however: in using such a transaction mechanism, they must take on faith the information it displays to them while revealing their own secrets to it., With the new approach, an individual conducts transactions using a personal "card computer. " This might resemble a credit-card-sized calculator and include a character display, a keyboard, and a short-range communication capability (like that of a television remote control). Such computers can be bought or even constructed, just like any other personal computer; they need have no secrets from, or structures unmodifiable by their owners. They can also be as simple to use as automatic teller machines. During a purchase at a shop, for example, equipment at the point of sale transmits a description of the goods and cost to the card, which displays this information to its owner. The card owner allows the transaction simply by entering a secret authorizing number on the card's keyboard. This same number is used by the owner to allow each transaction; without it, a lost or stolen card computer would be of very little use. A lost card's full capabilities, however, could be readily installed in a replacement, using backup data saved in a secure, encoded form at home or elsewhere., The third defining difference is in the kind of security provided. Current systems emphasize the one-sided security of organizations attempting to protect themselves from individuals, while the new approach allows all parties to protect their own interests. It relies both on individuals' card computers withholding secret keys from organizations and on organizations' computers devising other secret keys that are withheld from individuals. During transactions, the parties use these keys to form specially coded confirmations of transaction details, the exchange of which yields evidence sufficient to resolve errors and disputes., The systems presented here for the new approach depend on currently used codes to secure organizations against abuses by individuals. Since these codes are "cryptographic," they can be broken, in principle, by trying enough guessed keys. Such guessing, however, is infeasible because of the enormous number of possible keys. In short, no proofs of security are known for these cryptographic codes. but nor are any feasible attacks. By contrast. the security card computers provide for individuals against the linking of their pseudonyms is "unconditional"- simple mathematical proofs can show that, with appropriate use of the systems, even collusion of all organizations and tapping of all communication lines could not Yield enough information to link the pseudonyms--regardless of how clever the attack or how much computation it uses., In summary, if large scale automated systems or consumer transactions are actually to be built, the new approach offers a far more attractive way to structure them. Its specific advantages to individuals, organizations, and society at large will be argued further in the final section. The intervening three sections expand on its desirability and practicality for a comprehensive set of transaction types: communication, payments, and credentials., Payment systems now being piloted for widespread use with the current approach include tamper-resistant card computers issued by banks and electronic connections between banks and retailers. The same basic mechanisms, however. could be designed to carry out payment transactions under the new approach. This in turn would allow new approach credential transactions to come naturally and gradually into use. with their applicability and benefits growing as computer and telecommunications infrastructures mature. The communication system proposed here would only begin to be practical with the advent of large-scale consumer electronic mail and would allow home use of the payment and credential systems. It is here presented first, however, since it most clearly illustrates some concepts central to the latter more immediately applicable systems., As more messages travel in electromagnetic and digital form, it becomes easier to learn about individuals from their communication. Exposure of message content is one obvious danger, but this is already addressed by well-known coding techniques. A more subtle and difficult problem with current communication systems, however, is the exposure of "tracing information." An important kind of tracing information today is individuals' addresses, which organizations often require and which they commonly sell as mailing lists. The trend is toward greater use of such information. Comprehensive computerized data on who calls whom and when, for instance, are increasingly being collected and maintained by telephone companies. Electronic mail systems, some new telephone systems, and the proposed integrated services networks automatically deliver tracing information with each message. When such information is available on a mass basis, the pattern of each individual's relationships is laid bare. Furthermore, tracing information can be used as an identifier to link together all the records on an individual that are held by organizations with whom that individual communicates. So long as communication systems allow system providers, organizations, or eavesdroppers to obtain tracing information, they are unsuitable for the new approach and, moreover, are a growing threat to individuals' ability to determine how information about themselves is used., The other side of the issue is that current systems offer organizations and society at large inadequate protection against individuals who forge messages or falsely claim not to have sent or received messages. With paper communication, handwritten signatures are easily forged well enough to pass routine checking against signature samples, and they cannot be verified with certainty, even by expert witnesses. Also, paper receipts for delivery are too costly for most transactions, are often based solely on handwritten signatures, and usually do not indicate message content. As computerized systems come into wider use, moreover, the potential for abuse by individuals will increase. Solving these problems under the current approach might be attempted in several obvious ways: by providing recipients with the sender's address, by installing tamper-resistant identity-card readers or the like at every entry point to the communication system, and by keeping records of all messages to allow certification of delivery. But these security measures are all based on tracing information and thus are in fundamental conflict with individuals' ability to monitor and control information about themselves., Both sets of problems are solved under the new approach. The nature of the solution is such that: individuals are able to send or receive messages without releasing any tracing information; receivers can show that messages were in fact sent to them, despite denial by the senders; senders can show that messages were in fact received, despite denial by the receivers; and message content is kept confidential. To make messages untraceable, a person's electronic mail computer conceals, in an unconditionally secure way, which messages it sends and receives. To prevent denial by a sender, each sender cryptographically codes messages in a way that each receiver can check, but that prevents anyone from being able to imitate the sender's coded "signature." These two concepts--untraceability and coded signatures--will recur intertwined in the payment and credential transaction types and are presented in separate subsections below., It is easy, in principle, to prevent a message sent by an organization from being traced to its individual recipient. The organization simply broadcasts all its messages to all individuals, and each individual's electronic mail computer then scans the broadcasts for messages addressed to any of its owner's pseudonyms. Thus only the individual's computer knows which of the broadcast messages its owner obtains., Preventing a message sent to an organization from being traced back to its individual sender, however, requires some novel techniques; since any physical transmission can, in principle, be traced to its source. The concept of these techniques is illustrated by a hypothetical situation. Suppose two of your friends invite you to dine at a restaurant. After dinner, the waiter comes to your table and mentions that one of the three of you has already paid for the dinner--but he does not say which one. If you paid, your friends want to know (since they invited you), but if one of them paid, they do not want you to be able to learn which one of them it was., The problem is solved at the table in the following simple way: Your friends flip a coin behind a menu so that they can see the outcome, but you cannot. It is agreed that each of them will say the outcome aloud, but that if one of them paid, that one will say the opposite of the actual outcome. The uninteresting case is when they both say heads or both say tails: then everyone knows that you paid. If one of them says heads and the other says tails, however, then you know that one of them paid--but you have absolutely no information as to which one. You do know that the one you observed say tails paid if the coin toss was heads, and that the other one paid if the coin toss was tails. But since heads and tails tosses are equally likely, you learn nothing from your two friends' utterances about which one of them paid., The system described allows the friend who paid to send you an unconditionally untraceable message; even though you know who says what, you cannot trace the "I paid" message, no matter how clever or prolonged your analysis., UNCONDITIONALLY UNTRACEABLE MESSAGES are illustrated by a hypothetical situation (see text). The "I paid" message is unconditionally untraceable, since it can not be traced to a particular host---no matter how much computation or what approach is used. , This hypothetical system can be generalized and made practical (as detailed in reference [1]). One such generalization uses additional coins to allow more potential senders at the table, while preventing tracing even by collusion. Another breaks long messages into a sequence of parts, each of which is dealt with in a separate round of coin tosses and utterances. In practical communication systems, each participant's electronic mail computer would share secret numeric keys with other mail computers (just as hosts shared coin tosses behind their menus). Each mail computer then uses these keys to produce transformed sequences of digits (like a sequence of outcomes uttered at the table), which it sends through the mail network. The network combines all these transmissions to recover the original messages, which it broadcasts back to the mail computers (just as messages were audible and understandable to everyone at the table)., UNCONDITIONALLY UNTRACEABLE MESSAGES WITH NUMBERS are sent essentially as with words, except that everything is represented as 0's and 1's. Only the exclusive-or operation is used (defined as l 0=0 1=1 and 00=1 1=0). The 0 or 1 outcome of the coin toss is shown as k. A host wishing to send the "I paid" messages which is represented as 1, transmits k1; a host not wishing to send the message transmits only k. When the guest forms the exclusive-or of the two transmissions, [1] and [2], the result is 1. If one host sent the message and 0 if no host sent it --- because k appears twice and cancels (since kk=0 and 0 j=j). If there are more hosts at the table, each flips a coin and shares the outcome with the host to the left, skipping the guest. Each host then forms a transmission as the exclusive-or of the two outcomes the host shares, exclusive-or'ed with an additional 1 if the host is sending the "I paid" message. Every coin toss appears twice and is cancelled in the exclusive-or that the guest forms from all the transmissions, and the result is again 1 if a host paid and 0 if no host paid. In actual computerized systems, real messages are encoded as sequences of 0's and l's, and the whole protocol is repeated with new k's for each digit to be sent. Senders noticing that their messages are being garbled by collision with other messages, wait randomly-chosen intervals before attempting to resend. , Now consider the problem of preventing senders from later disavowing messages they have sent. The solution is based on the concept of "digital signatures," which was first proposed by Diffie and Hellman [4]. To see how this concept works, imagine an old-fashioned codebook that is divided into two halves, like an English-French and French-English dictionary, except that only English words are used. Thus, if you look up an English word in the front half of the codebook, you find the corresponding (but usually semantically unrelated) English code word; if you then look this code word up in the back half, you find your original English word. Such codebooks are constructed by pairing off words at random: in the front half of the book, the pairs are ordered by their first words, and in the back half by their second words. For instance, if under "spy" the front half shows "why," then under "why" the back half shows "spy.", If you construct such a codebook, you can use it in your communication with an organization. You keep the front half as your private key, and you give the back half to the organization as your digital pseudonym with that organization. Before sending a message to the organization, you translate each word of the message into code using your private key; this encoded form of the message is called a digital signature. When the organization receives the digital signature from you, it translates it back to the original English message using your digital pseudonym., The immensely useful property of such digital signatures is their resistance to forgery. No one--not even the organization that has your digital pseudonym--can easily forge a digital signature of yours. Such forgery would entail creating something that your digital pseudonym decodes to a sensible English message. In the codebook analogy, of course, forgery merely requires searching through (or completely re-sorting by second words) the half of the book that is your digital pseudonym. With actual digital-signature cryptographic techniques currently in use, however, forgery is thought to require so much computation as to be infeasible even for the fastest computers working for millions of years. If an organization cannot forge a digital signature of yours, then it cannot successfully claim that you sent it a message that you in fact did not send. A third-party arbiter would decide in favor of an organization only if the organization could show a digital signature that yields the disputed message when translated with your digital pseudonym. But, because forgery is infeasible, the organization could obtain such a digital signature only if you had "signed" (i.e., encoded) the disputed message using your private key., An organization could create its own private key and corresponding digital pseudonym (its own "codebook"); it would keep the private key (the front half) to itself, while widely disseminating the corresponding digital pseudonym (the back half). It would then use this private key to transform messages into digital signatures before sending them to individuals. The organization, unlike an individual, would create only a single private key and corresponding digital pseudonym, which it would use for all digital signatures it sends. Thus, anyone receiving a signed message from the organization would decode it using the organization's single, publicly disseminated digital pseudonym (commonly called a "public key"). These signatures would allow individuals to convince the organization, or anyone else if necessary, that the message had in fact been sent by the organization. In the payment and credential systems introduced in the following sections, such digital signatures formed by organizations play an important role., DIGITALLY SIGNED MESSAGES are illustrated by a hypothetical use of old-fashioned codebooks (see text). Actual computerized digital signature systems now in use are not unconditionally secure, though the amount of computation required forgery is thought to be unobtainable in practice. , Actual digital signatures are realized using numbers, and can be adapted to keep message content confidential and to certify delivery., Practical, computerized digital-signature techniques work just as in the codebook analogy above, except that everything is done with two hundred-digit numbers. Each private key, and each digital pseudonym, is represented as one such number (rather than as a half codebook); each unsigned message and each signature is also represented as such a number (rather than as a string of English words). A standard, publicly available mathematical procedure lets anyone use a private key to form a corresponding digital signature from a message; a similar procedure allows anyone to recover the original message using the matching digital pseudonym (just as the simple procedure for looking up words in either half of the codebook can be public, so long as the private key is not). Another public mathematical procedure allows anyone to create a private key and corresponding digital pseudonym from a random starting point (just as the two halves of a codebook could be generated from a random pairing of words). Rivest, Shamir, and Adleman [5] proposed such a numeric digital-signature technique, which seems to be highly secure against forgery and could underlie the systems presented here., Messages are kept confidential during transmission by using digital pseudonyms and private keys in a different way: before transmitting a message, the sender first signs it and then encodes the result using the digital pseudonym of the intended recipient. Thus, the signed message can be recovered only by decoding the transmission using the intended recipient's private key., DIGITAL SIGNATURES WITH NUMBERS use special arithmetic systems, in which raising a number to a power scrambles it, and raising to a corresponding power unscrambles it: . (The power acts as the private half codebook, and the other power acts as the corresponding half.) First the message is encoded as a onehundred-digit number, and then the digits are repeated to form a two-hundred-digit number with this special repeated-halves property. Next the signer raises the special number to a private power and makes the result known to others in transmission [1]. Someone receiving this digitally-signed message merely raises it to the corresponding digital-pseudonym power and checks that the result has the special repeated-halves property. If it does, then the recipient knows that the message was signed by the holder of the corresponding private power , One way to protect against recipients falsely claiming not to have received messages is similar to the way paper mail is certified: messages are only given to recipients once they provide digitally signed "receipts" of delivery. Another method holds people responsible for messages that are made a matter of public record, like legal notices in newspapers. Since, under the new approach, messages are broadcast, they can be certified in this way at little additional expense. (A more fundamental advantage of making messages a matter of record is that it becomes easy to disprove false attributions of signatures--even if signatures could somehow be forged.) When this method is used with messages encoded for confidentiality, either party can display the signed message and point to the corresponding doubly encoded transmission in the public record as evidence that the message was available for receipt, since decoding the signed message with the digital pseudonym of the sender yields the message content, and encoding it with the pseudonym of the recipient yields the transmission in the public record., The computerization of payments is giving payment system providers and others easy access to extensive and revealing information about individuals through payments made for purchases from shops, subscriptions, donations, travel, entertainment, professional services, and so on. Today, many paper records of when, how much, from whom, and to whom payment was made are translated into electronic form. The trend is toward capturing this payment data electronically, right at the point of sale. This facilitates the electronic capture of the potentially more revealing details of what was purchased. Moreover, computerization is extending the data capture potential of payment systems in other ways. One is through emerging informational services like pay television and videotex; another is through new systems that directly connect central billing computers to things like electric-utility meters and automobile identification sensors buried in toll roads. Just as, in communication systems, tracing information links all of an individual's records with organizations, payment data containing an account identifier links all of an individual's relationships involving payments., From the other perspective, it is widely held that uncollectible payments made by consumers, such as credit card misuse and checks drawn against insufficient funds, cost society billions of dollars a year. Paper banknotes are vulnerable to counterfeiting and theft, and their lack of auditability makes them convenient for illicit payments such as bribes, extortion, and black-market purchases. Limiting all these abuses while automating seems to call for highly pervasive and interlinked systems that capture and retain account identifiers as well as other payment data--which is in clear conflict with the interests of individuals., The nature of the new approach's solution to these problems ensures that organizations, even colluding with the payment system provider who maintains the accounts, cannot trace the flow of money between accounts. But the system provider does know the balance of each account, and if funds were to be transferred between accounts instantaneously, the simultaneous but opposite changes in balance would make tracing easy. Such tracing is prevented because funds are withdrawn, held, and paid as multidenominational notes, in some ways like "unmarked bills." These notes are unlike paper banknotes, however, in that individuals, but not organizations, can allow transfers to be traced and audited whenever needed; this makes the notes unusable if stolen, and unattractive for many kinds of illicit payments. The fully computerized systems introduced here offer practical yet highly secure replacements for most current and proposed consumer payment systems (as detailed in [2])., The new-approach payment systems are based on an extension of digital signatures, called blind signatures. This concept is illustrated by an analogy to carbon-paper-lined envelopes. If you seal a slip of paper inside such an envelope and a signature mark is later made on the outside, then when you open the envelope, the slip will bear the signature mark's carbon image., Consider how you might use such an envelope to make a payment. Suppose that a bank has a special signature mark that it guarantees to be worth one dollar, in the sense that the bank will pay one dollar for any piece of paper with that mark on it. You take a plain slip of paper sealed in a carbon-lined envelope to the bank and ask to withdraw one dollar from your account. In response, the bank deducts one dollar from your account, makes the signature mark on the outside of your envelope, and returns it to you. You verify that your sealed envelope has been returned with the proper signature mark on it. Later, when you remove the slip from the envelope, it bears the carbon image of the bank's signature mark. You can then buy something for one dollar from a shop, using the signed slip to make payment. The shop verifies the carbon image of the bank's signature on the slip before accepting it., Now consider the position of the bank when the slip is received for deposit from the shop. The bank verifies the signature on the slip submitted for deposit, just as the shop did, and adds a dollar to the shop's account. Because the signature verified, the bank knows that the slip must have been in an envelope that it signed. But naturally the bank uses exactly the same signature mark to sign many such envelopes each day for all of its account holders, and since all slips were "blinded" by envelopes during signing, the bank cannot know which envelope the slip was in. Therefore it cannot learn from which account the funds were withdrawn. More generally, the bank cannot determine which withdrawal corresponds to which deposit--the payments are untraceable., UNTRACEABLE PAYMENTS are illustrated by an analogy to envelopes and carbon paper. The individual (or, in the computerized analogue, the card) seals a blank slip of paper and a facing piece of carbon paper in an envelope, and supplies it to the bank. The bank deducts one dollar from the individual's account, applies a "worth one dollar" signature (stamp) to the outside of the envelope, and returns the unopened envelope to the individual. Upon receiving this, the individual verifies the bank's validating signature. Before making payment sometime later, the individual removes the envelope and carbon, leaving only the signed slip of paper. When the shop receives the slip, it verifies the carbon image of the validating signature on the slip, and supplies it to the bank for deposit. After also verifying the slip's validating signature, the bank honours the deposit, since it knows the slip must have been in an envelope it signed. The bank does not, however, know which of the many envelopes that it signed contained the slip, and thus the bank cannot trace the slip to the lndividual's account. In actual computerized systems, unless the individual allows tracing, withdrawals on one side of the dashed boundary line and payments on the other side of it are unconditionally untraceable to each other-even if the bank and all other organizations collude. , In actual computerized systems, both slips and envelopes are replaced by numbers, the bank's signature mark becomes a digital blind signature, and payments are unconditionally untraceable (as described later in this section). The protocols for transacting withdrawals and payments would of course be carried out automatically by the card computer; its owner would merely have to allow each transaction by entering the secret authorizing number., Using note numbers provides protections similar to those offered by check numbers today. Since the bank is unable to see into the envelopes, nothing is revealed to the bank by a randomly chosen note number written on the slip before it is signed. (Alternatively, the slip's unique, random paperfiber pattern could represent the note number. ) Stolen notes should not be accepted by the bank once the individual who withdrew the funds reports their note numbers. When given these numbers, the bank can also attest to the accounts to which funds have been deposited. Such traceability at the payer's initiative would discourage the use of these systems in bribery, extortion, black market purchases, and other illicit payments: recipients of such payments risk having their accounts traced if they deposit the notes, and being apprehended or just discovering that the notes are worthless if they try to spend them., A variation prevents organizations (even colluding with banks) from tracing the accounts of individuals to whom they pay such things as wages, settlements, refunds, and rebates. The individual places a slip in an envelope as before and gives it to the paying organization, which then supplies this blinded slip to the bank. The bank, without knowing which individual is involved, signs the envelope and charges the paying organization's account Signed but still blinded, the slip is returned by the organization to the individual, who verifies the signature, and later removes the envelope and deposits the slip with the bank., Other extensions to the basic concept offer replacements for today's payment systems attractive to both financial institutions and consumers. Regional clearing and signing centers would handle most of the work and responsibility for banks on a wholesale basis, while the banks could offer their own customized services. Different signatures would be used for different denominations. An adaptation allows routine transactions to be consummated in a way not requiring immediate or online interaction with a bank. Further variations permit the payment system to be used just as credit and debit cards are used today, with interest charges for credit and interest earnings on unspent debit-card balances., Actual payment systems would work very much along the lines of the envelope analogy, except that they use no paper, only numbers. A note number is first created by a true random process within the individual's card computer (used like the random number or fiber pattern on the slip of paper). Next, the card computer transforms the note number into a numeric note that is the equivalent of the message: "This is note number: 59...2" (used like the slip of paper itself). The card computer then blinds this numeric note by combining it with a second random number (like the payer choosing an envelope at random and placing the slip in it). During withdrawal, the bank uses the private key of the desired denomination to form a digital signature on the blinded numeric note (like the signature mark made on the envelope). When the signed but still blinded note is returned, the card computer is able to unblind it by a process that removes the random blinding number from the digital signature while leaving the signature on the note (like the payer removing the envelope). Both the organization receiving payment and the bank use the bank's digital pseudonym to decode the signature; if the result is an appropriate message, this verifies the note's digital signature., UNTRACEABLE PAYMENTS WITH NUMBERS are made much as in the paper analogy. First the individual's card computer chooses half the digits of by a physical random process, and repeats these digits (actually in a scrambled form) to create the note number with this special repeated-halves property (corresponding to choosing a suitable slip of paper at random in the analogy). The card also creates a totally random number (like choosing an envelope and carbon). The card then raises the random number to the bank's "worth one dollar" public power , multiplies this by the note number (like sealing the slip in the envelope), and supplies the result to the bank in transmission [1]. The bank deducts from the account uses the corresponding private power to sign the transmission, and returns the result to the card in [2]. The card verifies that the bank returned exactly the right thing, and obtains the signed note by dividing out the random (like removing the envelope and carbon). When a payment is made, the shop checks that transmission [3] is a signed special number, and then forwards a copy [4] to the bank for deposit. The bank checks the signature just as the shop did, and accepts the deposit if the valid note has not already been deposited. If Individuals do not divulge the random 's their cards create, then the [1]'s are unconditionally untraceable to the [4]'s, since there is exactly one that would make any [2] correspond with any [4]. , A conceivable danger for the bank is that the same numeric note might be deposited more than once. To prevent this, a list of note numbers accepted for deposit is maintained and only note numbers not already on the list are accepted and recorded. The cost of maintaining such a list can be far less per transaction than the transaction cost of current payment systems, since expiration dates built into note numbers allow old numbers to be deleted from the list., Another conceivable danger is that the bank's digital signature could be forged, which would allow counterfeiting. The security against this kind of threat is based on the underlying digital-signature cryptographic technique, which is currently being proposed as an international standard and is already used by banks and even by nuclear agencies. The odds of someone guessing a valid, signed numeric note, or of any two independently chosen note numbers being the same in the foreseeable future, are less than 1 in 10 to the 75th power., The numeric notes are unconditionally untraceable: the bank cannot learn anything from the numbers about the correspondence between withdrawals and deposits. In the hypothetical restaurant situation, both outcomes of each coin toss were equally likely, which meant that every correspondence between senders and messages was equally likely. Similarly, because all suitable numbers are equally likely to be used for the independent blinding of each note, all correspondences between withdrawals and deposits are equally likely., In their relationships with many organizations, there are legitimate needs for individuals to show credentials. The term "credentials" is used here to mean statements concerning an individual that are issued by organizations, and are in general shown to other organizations. In the past, credentials primarily took the form of certificates like passports, driver's licenses, and membership cards. Before computerization, such certificates provided individuals with substantial control over access to their credentials, though the certificates also often revealed unnecessary and identifying information like address, birthdate, and various numbers. Today, such identifying information is being used to link records on certificate holders; it even allows them to be "blacklisted" or denied services because of reports from organizations that may be erroneous, obsolete, or otherwise inappropriate for the decision at hand. Where no substantiating certificate is required to be shown, as with application or tax forms, much similarly unnecessary or overly detailed information is demanded, presumably to allow confirmation. But confirmation itself can link further information and lead back to inappropriate records. The control over credential information that certificates once provided to individuals is thus being circumvented and rendered illusory by computerization., The countervailing problem is that credentials are subject to widespread abuse by individuals, who can easily modify or copy many kinds of paper and plastic certificates with today's technology. This is one reason why certificates are in effect being reduced to the role of providing identifying information, and organizations are maintaining the credentials themselves. To check on unsubstantiated credential information, organizations are also rapidly deploying so-called matching techniques, whereby they use identifying information to link and share records on individuals. Many organizations may also need the ability to blacklist individuals or to determine whether they are already blacklisted. As the number of such organizations grows, certificates or even matching techniques become impractical, hence the creation of large centralized databases on individuals. The use of multiple complete identities by sophisticated criminals is a related problem. As with communication and payments, the obvious countermeasures under the current approach--widespread use of highly secure identity documents linked to centrally maintained credentials--are in direct conflict with individuals' ability to determine how information about themselves is used., With the new approach's solution, an individual can transform a specially coded credential issued under one pseudonym into a similarly coded form of the same credential, which can be shown under the individual's other pseudonyms. Since these coded credentials are maintained and shown only by individuals, they return control similar to that formerly provided by certificates; and since they are convenient to use, they obviate the need for unsubstantiated credentials and for matching. Individuals can also tailor the coded form they show to ensure that only appropriate information is revealed or used to make particular decisions, and can ensure that obsolete information becomes unlinkable to current pseudonyms. Abuses of credentials by individuals, such as forgery and improper modification or sharing, are prevented by the cryptographic coding and the protocols for its use. Since each person is able to have at most one pseudonym with any organization requiring such protection, multiple complete identities are also prevented. Moreover, accountability for abuses perpetrated under any of an individual's pseudonyms can still be assured, without the need for centralized databases., The essential concept is again illustrated by analogy to carbon-lined envelopes, only this time the envelopes have windows. First, you make up numeric pseudonyms at random and write them on a plain slip of paper. When you want to get a credential from an organization, you put the slip in a carbon-lined envelope with a window exposing only the pseudonym you use with that organization. Upon getting the envelope from you, the organization makes a special signature mark in a repeating pattern across the outside of it, and the carbon lining transfers the pattern to the slip. This signature pattern is the credential; the type of pattern corresponds to the kind of credential the issuing organization decides to give you, according to the pseudonym they see through the window. When you get the envelope back from the issuing organization, you verify the credential signature pattern. Before showing the credential to another organization, you place the slip in a different envelope with a window position that exposes only the pseudonym you use with that organization, along with some of the adjacent credential signature pattern. The receiving organization can verify, through the window, the pseudonym you use with it as well as the signature pattern. In this way, you can obtain and show a variety of credentials., An organization can ensure that no individual is able to transact with it under more than one pseudonym. One way an individual could attempt to use more than a single pseudonym with an organization is to use different pseudonyms on the same slip of paper. This is prevented by a standard division of the slip into positional zones, such that each zone is assigned to a particular organization; an envelope is accepted by an organization only if the window position exposes that organization's zone, bearing a single indelibly written pseudonym. A second way of attempting to use more than one pseudonym per organization is to use more than one slip. This is prevented by the establishment of an agency that issues a single "is-a-person" credential signature to each individual. Other organizations accept only envelopes with this signature recognizable through the window. The agency ensures that it issues no more than one signature per person by taking, say, a thumbprint and checking that the print is not already on file before giving the signature. This collection of prints poses little danger to individuals, however, since the prints cannot be linked to anything., UNTRACEABLE CREDENTIAL TRANSFERS BETWEEN PSEUDONYMS are illustrated by an analogy to window envelopes and carbon paper. The individual writes the pseudonyms on a slip and seals it, along with a facing piece of carbon paper, in an envelope the window of which exposes only the pseudonym 523 used with organization X. Then X applies a signature (stamp) on the outside of the envelope received, having chosen C as the repeating pattern that indicates the kind of credential Issued. The individual verifies the signature returned. When the individual later wishes to show the credential to organization Y, the original envelope and carbon are discarded, and the slip is placed in a new envelope the window of which exposes only the pseudonym 965 used by the individual with Y. Now Y verifies the signature through the window of the envelope and knows that 965 has been issued credential C. Organization Y cannot however, learn the other pseudonyms written on the slip. Actual computerized systems maintain the unconditional untraceability of pseudonyms across the dashed boundary line. , The pseudonyms used by individuals are untraceable, in the sense that envelopes give no clue, apart from the signatures shown, about the other randomly chosen pseudonyms they contain. Actual systems based on card computers would provide unconditional untraceability using digital blind signatures on numbers (as detailed in [3])., UNTRACEABLE CREDENTIALS WITH NUMBERS also follow the paper analogy. The so-called "one-way" function is easily computed by a publicly known procedures, but its inverse is thought to be infeasible to compute. Organization X determines the validity of both transmissions it receives, [1.1] and [1.2], by verifying that the first is a signature on the one-way function of the second. Later, X provides the signature for the desired credential on [1.2]. The card verifies the signature received as [2], and replaces by . Organization Y verifies [3.1] and [3.2] just as X did for [1.1] and [1.2]. Upon receiving the credential [3.3], Y verifies that it is a signed copy of [3.2]. Not illustrated is how a special organization Z ensures that the [1.1]'s (and [3.1]'s) are of the proper form, but does not obtain information useful in tracing. First the card supplies many candidates to Z, each of the form , where is the special pseudonym used by the individual with Z, and and ,with and created at random by the card. When the card later learns which candidates have been selected at random for inspection by Z the card supplies the corresponding and for each. This allows Z to verify that . If all inspected candidates verify, then Z supplies the signed form of all uninspected candidates. The card transforms a signed candidate into [1.1], for example, by dividing out . (in one extension, the chance that improper candidates are used successfully can be kept negligibly small by Z returning signatures only on products of candidates. In another, using 's as exponents with bases that are known generators having public signatures allows an unlimited number of signature types .) , You need not show all your credentials to every organization; you can restrict what you show to only what is necessary. Because of the way the credential signature patterns repeat across the slips, a recognizable part of each signature pattern appears adjacent to each pseudonym. To prevent certain credentials from being seen, though, you could simply black out parts of an envelope's window when showing it to an organization. But more flexible restrictions are possible using your card computer. It serves as the single database of all your credentials--and you alone control which queries from organizations it answers., A typical such query might be: "Does the owner of pseudonym 72...4 have credentials sufficient to meet the requirement:...?" Your card can issue a convincing affirmative response only when it does in fact have credential signatures satisfying the requirement. But the card ensures--unconditionally--that organizations cannot learn any more about your credentials from its responses than the affirmations themselves. You might use it to convince an organization that your age, income, and education, for instance, meet their entry requirements in at least one way, without revealing any more than just that fact. Or, when a survey requires credentials for substantiating responses, using a different pseudonym for each response ensures that no more is revealed than the total number of each type of response., Actual queries and responses can be realized as follows: an organization encodes a new credential into the query message itself, in such a way that the credential can be decoded using any one of several qualifying combinations of other credentials as the key. If any qualifying combination is held, then this new credential can be decoded and shown to the organization as the response. It can also be retained for later use, which additionally permits the gradual replacement of older and more detailed credentials by more appropriate summary ones. When such query messages are made public so that everyone can use them, they provide for public and verifiable rules for decisions about individuals., The new approach supports most varieties of credentials used today. Some of these, like educational degrees, are lifelong, while others, like student cards, are valid only for prescribed periods. Still others, like membership cards, usually have long-term validity, but their certificates typically expire at the end of each year, thereby allowing their issuers to effectively revoke the credential by withholding new certificates., A less common but still used kind of credential allows organizations in effect to blacklist individuals, without maintaining a central list of identities. Suppose, for example, that credentials are issued for filing tax forms, so that each adult citizen should get such a credential every year. Organizations might routinely modify their queries to include the requirement that adult citizens have filed tax forms for the last year. This would blacklist those who had not complied by barring them from relationships with organizations., In actual widespread use, where many organizations may occasionally need to blacklist some individuals, such a mechanism is neither practical nor desirable: queries would have to demand vast numbers of credentials, while individuals would be unable to protect themselves against being blacklisted by organizations even with which they have had no contact., These problems of wider use can be solved by techniques that require an organization to obtain, directly from an individual, the authorization to blacklist that individual for a specified reason. Organizations would insist on such authorizations as are appropriate before establishing or extending relationships., The way these techniques work is illustrated by applying the envelope analogy to buying goods on credit. A special row of zones is reserved on each slip for this purpose. You provide the shop where you make the credit purchase with an envelope that has (in addition to any window you may ordinarily use with that shop) a window exposing one of these reserved zones. The shop first broadcasts the numeric pseudonym it sees indelibly written in that reserved zone, so that when no other organization objects, the shop is assured exclusive use of that zone., When you later pay the shop, it gives you a resolution credential signature mark; unlike the credential signature marks previously described, it is made only on the single zone to which it applies. If some of the reserved zones remain unused, you can show them to a "voiding" agency that obtains exclusive use of these unneeded zones in the same way as do shops, and then issues a resolution signature mark on each., Only when you repay by deadline all due loans can you obtain resolution signature marks on each zone of the reserved row. Then you can demonstrate that you are not blacklisted, without revealing more, just by showing that all of your reserved zones have their resolution signatures. You do this by presenting an envelope that has a slit-shaped window positioned over the reserved row. It exposes only a narrow band of each reserved zone's resolution credential signature, while concealing the pseudonym-bearing parts of the zones that were shown separately to lenders or the voiding agency. In actual systems, card computers would obtain and show digital signatures for this purpose as part of their general management of the reserved row., The mechanisms of the new approach can both guarantee individuals time to review credential information before it is required, and unconditionally ensure them the ability to shed such information once it is outdated., If individuals can expect to receive their resolution credentials some "cooling-off" interval before they are needed, instead of at the last minute, then there may be time to resolve errors or disputes before any unnecessary consequences occur. Organizations may not wish to increase the maximum delay before blacklisting takes effect, but some cooling-off interval can always be provided without doing so. For example, when a different resolution credential is valid for each calendar month and organizations provide them just before the beginning of the month, then the maximum delay before blacklisting takes effect is one month and there is no cooling-off interval. But this same maximum delay can be maintained while providing cooling-off intervals half a month long: twice a month, organizations issue credentials that expire a month after their issue date, so that a credential remains valid for a half-month interval following the scheduled issue of its successor., If individuals change pseudonyms periodically, they cannot be linked to obsolete information. The initial information associated with new pseudonyms would be provided through the transfer of credentials from previous pseudonyms. The changeovers could be staggered to allow time for completion of pending business., There are additional benefits to changing pseudonyms beyond the weeding-out of obsolete information. For one thing, the periodic reduction to essentials prevents organizations from gradually accumulating information that might ultimately be used to link pseudonyms. Moreover, for individuals to be able to transfer all the initial information for a period, they must know each organization's information demands, they must know where each piece of information comes from, and they must consent to each such transfer. Information linkable by each organization is thus known to and agreed on by individuals--that is, individuals can monitor and control it., As the public becomes more aware of the extent and possibilities of emerging information technology, there should be a growing demand for the kinds of systems described here. Compared to the current approach, individuals stand to gain increased convenience and reliability; improved protection against abuses by other individuals and by organizations; monitorability and control; and full access to transaction systems., Increased convenience derives from the freedom of individuals to obtain their card computers from any source. to use whatever hardware or software they choose, and to interface with communication systems wherever they please. This permits card computers to be adapted to the requirements of sophisticated, naive, and handicapped users alike. The systems need be no more complicated to use than under the current approach. people might choose never to actually see their pseudonyms or to be concerned with other implementation details., The individual is ensured reliable system access by a numeric key with which the card computer encodes backup copies of its contents, and which allows a replacement card to recover these contents. Since this key should be 40 or more digits in size. it might be impractical for its owner to remember. Known techniques allow the key to be divided into parts. each of which can be given to a different trustee. This provides certain subsets of the trustees with the ability to recover the key, while insufficient subsets would be unable to learn anything about it. Still other subsets, given parts of the owner's secret authorizing number, would be able to take over the owner's affairs when needed. These provisions are an example of how an individual's power to designate proxies, a power now enjoyed by organizations, is ensured., Abuse of a lost or stolen card computer by another individual would be very difficult without the owner's secret authorizing number as asserted earlier. This is because the card would require the authorizing number. which might typically be about six digits long, before allowing transactions. A reasonably tamper-resistant device within the card computer could: read fingerprints or the like to prevent use by anyone but the card owner; accept a special authorizing number that the owner could use in case of duress to trigger a prearranged protective strategy; and permit only the current owner to reset the card for a new owner. to prevent its use as a replacement by a thief. Even if sophisticated criminals were to extract the cards information content and the owner were not to cancel in time using backup data, a great many guesses at the authorizing number might have to be tried with organizations before the actual number could be determined. This would make such attacks very likely to be detected and to fail., The new approach protects individuals unconditionally from abuses by organizations, such as the false attribution of messages, and from organizations blacklisting without advance warning. Moreover, individuals are provided with secure relationships without ever having to sacrifice the protection of their pseudonyms by revealing linking information--but they can always do so if they choose. While it is relatively easy for individuals to provide convincing evidence only of their role in particular transactions, it is even possible for them to provide evidence that they were not involved in certain other transactions For example, in communication transactions, individuals could show that their physical entry to the system was not used to send a particular message; in payment transactions, they could show that a payment did not involve their account; and in credential transactions, they could show that a pseudonym was not among the set obtainable under their thumbprint., The primary way that individuals gain monitorability and control is through their ability to prevent linking. Some linking of separate relationships might occur if, for instance, a consumer actually wanted to be recognized, or as part of an investigation or other exceptional situation. But the linking of some relationships does not, in general, allow others to be linked, and the regular changing of pseudonyms allows linkings to be shed over time. In addition, the scope of an individual's separate, unlinkable relationships need not depend on the legal or administrative structure of the organizations involved; an individual might use the same pseudonym with different organizations or, when allowed, different pseudonyms with the same organization. Naturally, the scope of relationships, along with such things as the level of detail in credentials and the frequency of pseudonym changeover, must be adjusted to provide the desired degree of protection against inference by statistical or pattern recognition techniques. Such protections would likely create a widespread expectation of control over information; thus, as similar expectations have done in the past, it might also engender commensurate legal safeguards., Individuals would have the same access to systems as organizations, in addition to enjoying the same protections; such parity is precluded under the current approach in efforts to protect the security of organizations. A new-approach payment, for example, could be made between two friends using their card computers. A small business would even be able to handle all customer transactions, using only a card computer., Organizations have an interest in cultivating the goodwill of individuals. But they gain further direct benefits from the advantages to individuals described earlier, since in making their own transactions, they have many of the same concerns as individuals. Moreover, the new approach offers them reductions in cost; reductions in the quantity and sensitivity of necessary data; and improved security against detectable, undetectable, and extrasystemic abuses., The systems described here would be less costly for organizations than comparable systems based on the logical extension of the current approach. This is primarily because the latter requires widely trusted, tamper-resistant devices at all points of entry to transaction systems. Such a requirement implies substantial initial agreement, outlay, and commitment to design, and can be expected to result in technology that is outdated when systems come into widespread use. Furthermore, the tamper resistance techniques currently contemplated require significant compromise in security, even at high cost. The new-approach system provider need not supply user organizations with tamper-resistant terminal equipment for each entry point, any more than than it need supply card computers to individuals. Thus, user organizations can supply their own terminal equipment wherever they please and take advantage of the latest technology. Although these cards and terminals make more sophisticated use of cryptographic techniques than does equipment envisioned under the current approach, this difference between the two is just a fraction of a chip in the technologies of the near future., The new approach reduces the sensitivity and the quantity of consumer data in the hands of organizations; by the same token, it reduces their exposure to incidents that might incur legal liability or hurt their public images. Reductions in data could also streamline operations, and the increased appropriateness of the remaining data could provide a better basis for decision making. As electronic mail replaces paper mail, individuals' computers may routinely reject unsolicited commercial messages and instead seek out only desired information. Thus, data for targeting such messages might become superfluous even under the current approach. The new approach's protections, however, may compensate by making individuals less reluctant to provide information for surveys and the like., Under either approach, if an automated transaction system detects sufficiently serious abuse or default by an individual, the best it can do is to lock that individual out. This is because the individual can always step outside such a system's controls by "going underground." The new-approach systems can lock individuals out, but can also have a cooling-off interval built in to allow matters to be resolved before lockout is needed. The approach also reduces the need for such measures, however, since its mechanisms allow organizations or society at large the flexibility to set policy that establishes a desired balance between prior restraint, as in the basic payment system, and accountability after the fact, as with credit or other authorized blacklisting functions., Undetectable abuse by individuals acting alone seems to be precluded by the systems of the new approach. But no transaction system is able to detect an individual who obtains something through legitimate use of the system and then transfers it to another person by some means outside the system. Transferring the ability to use a communication system to others is an instance of the proxy power already mentioned, which could be inhibited under the current approach. In the context of the payment system, such transfers can be treated as illicit payments, which are deterred by the use of note numbers. The credential system directly prevents the transfer of credentials from the pseudonyms of one person to those of another. Currently, "in-person" proxy is prevented by certificates bearing photos. Such photo tokens could still be used with the new approach, if and when needed; but they might include only a photo. an indication of the kind of credential, and possibly a digital pseudonym., Meanwhile, it is too easy to step outside current transaction systems by using coin phones, sending anonymous letters, dealing in cash, and using false credentials. Significantly improved security, particularly against more sophisticated abuse, can only be obtained with comprehensive automated systems. But such systems under the current approach may meet with broad-based resistance from individuals--especially once they become aware of the alternatives posed by the new approach., Large-scale automated transaction systems are imminent. As the initial choice for their architecture gathers economic and social momentum, it becomes increasingly difficult to reverse. Whichever approach prevails, it will likely have a profound and enduring impact on economic freedom, democracy, and our informational rights., Restrictions on economic freedom may be furthered under the current approach. Markets are often manipulable by parties with special access to information about other participants' transactions. Information service providers and other major interests, for example, could retain control over various information and media distribution channels while synergistically consolidating their position with sophisticated marketing techniques that rely on gathering far-reaching information about consumers. Computerization has already allowed these and other organizations to grow to unprecedented size and influence; if continued along current lines, such domination might be increased. But the computerization of information gathering and dissemination need not lead to centralization: integrating the payment system presented here with communication systems can give individuals and small organizations equal and unrestricted access to information distribution channels. Moreover, when information about the transactions of individuals and organizations is partitioned into separate, unlinkable relationships, the trend toward large-scale gathering of such information, with its potential for manipulation and domination of markets, can be reversed., Attempts to computerize under the current approach threaten democracy as well. They are, as mentioned, likely to engender widespread opposition; the resulting stalemate would yield security mechanisms incapable of providing adequate prior restraint, thus requiring heavy surveillance, based on record linking, for security. This surveillance might significantly chill individual participation and expression in group and public life. The inadequate security and the accumulation of personally identifiable records, moreover, pose national vulnerabilities. Additionally, the same sophisticated data acquisition and analysis techniques used in marketing are being applied to manipulating public opinion and elections as well. The opportunity exists, however, not only to reverse all these trends, by providing acceptable security without increased surveillance, but also to strengthen democracy. Voting, polling, and surveys, for example, could be conveniently conducted via the new systems; respondents could show relevant credentials pseudonymously, and centralized coordination would not be needed., The new approach provides a practical basis for two new informational human rights that is unobtainable under the current approach. One is the right of individuals to parity with organizations in transaction system use. This is established in practice by individuals' parity in protecting themselves against abuses, resolving disputes, conferring proxy, and offering services. The other is the right of individuals to disclose only the minimum information necessary: in accessing information sources and distribution channels, in transactions with organizations, and--more fundamentally--in all the interactions that comprise an individual's informational life., Advances in information technology have always been accompanied by major changes in society: the transition from tribal to larger hierarchical forms, for example, was accompanied by written language, and printing technology helped to foster the emergence of large-scale democracies. Coupling computers with telecommunications creates what has been called the ultimate medium--it is certainly a big step up from paper. One might then ask: To what forms of society could this new technology lead? The two approaches appear to hold quite different answers., Acknowledgements. The author is pleased to thank Jan-Hendrik Evertse, Wiebren de Jonge, and Ronald L. Rivest for discussions during the early development of some of the ideas herein presented, as well as everyone who showed interest in and commented on this work., 1. Chaum, D. The dining cryptographers problem: Unconditional sender and recipient untraceability. Available from the author., 2. Chaum, D. Privacy protected payments: Unconditional payer and/or payee untraceability. Available from the author., 3. Chaum, D. Showing credentials without identification: Transferring signatures between unconditionally unlinkable pseudonyms. Available from the author., 4. Diffie, W., and Hellman, M.E. New directions in cryptography. IEEE Trans. Inf: Theory, IT-22, (November 1976), 644-654., 5. Rivest, R., Shamir, A. and Adleman, L. A method for obtaining digital signatures and public-key cryptosystems. Communications of the ACM, 21, 2, (February 1978), 120-126., Copyright 1987 by David Chaum. (A related earlier work appeared in Communications of the ACM, 28, 10, Oct. 1985; ACM is acknowledged.) Copies not made or distributed for direct commercial advantage that include this notice are permitted without fee. To copy otherwise or republish requires specific written permission.]
[ , Prepaid Smart Card TechniquesA Brief Introduction and Comparison , by David Chaum, , A prepaid smart card contains stored value which the person holding it can spend atretailers. After accepting stored value from cards, retailers are periodically reimbursedwith actual money by system providers. A system provider receives money in advance frompeople and stores corresponding value onto their cards. During each of these three kindsof transactions, secured data representing value is exchanged for actual money or forgoods and services., Telephone cards used in France and elsewhere are probably the best known prepaid smartcards (though some phone cards use optical or magnetic techniques, which are notconsidered here). National prepaid systems combining public transportation, publictelephones, merchants, and vending have already been announced in a number of countries.And road tolls at full highway speed are not far behind., The systems proposed so far are compared, after a quick look at the card types on whichthey are based., There are in essence only four types of microcircuit card that have been suggested foruse in prepaid applications, each based on a particular kind of chip. They are listed herein historical order:, Security and cost are the fundamental criteria used here for comparing prepaid cardtechniques, but the best choice of technology depends on the situation. Security suitablefor an in-house company card, for instance, may be wholly inadequate for a national orinternational card which may require protection of many system providers from each otheras well as protection of personal privacy. Also depending on the setting, higher cardcosts can lead to lower system costs., Memory cards are suitable only for closed systems where a single company issues thecards and accepts them as payment for goods and services, or for systems with very lowfraud incentive. The reason is that defrauding such systems requires only a small computerinterposed between an actual card and a cash register. The computer merely has to recordthe secrets communicated during an initial transaction and can then, as often as desired,be used to play the role of a card having the initial balance. , Shared-key card systems require a tamper-resistant secured module in each vendingmachine or other point of payment. The module uses the key it shares with a card toauthenticate messages during purchases. This lets the card convince the module that it hasreduced its stored value by the correct amount and that it is genuine. A card convinces byusing the shared key to encrypt a random challenge issued by the module together with anamount, so that the module can decrypt the transmission and compare the result with theexpected challenge and amount. Periodically, the module transmits a similarlyauthenticated message, via telecommunication or manual collection procedure, back to thesystem provider, who reimburses the retailer., The secured module in a shared-key system thus needs to store or at least be able tore-create secret keys of all cards, which gives some problems. If the cards of multiplesystem providers are to be accepted at the same retailers, all the retailers must havesecured modules containing keys of every provider. This means either a mutually trustedmodule containing the keys of multiple providers, which might be hard to achieve, or onemodule per provider, which becomes impractical as the number of providers grows.Furthermore, in any shared-key system, if a module is penetrated, not only is significantretailer fraud facilitated, but the entire card base may be compromised. , Signature-transporting and -creating card types avoid these problems since they do notrequire secured modules. Cash registers need no secret keys, only public ones, in order toauthenticate the signatures, which act like guaranteed checks filled in with all therelevant details. These same signatures can later be verified by the system provider forreimbursement. (Although tamper-resistant modules are not needed for verification, theycan still be used to aggregate transactions.) Both signature -based card types also allowthe cards of any number of issuers to be accepted at all retailers; retailers cannot cheatissuers, and issuers cannot cheat each other. These are the only truly open systems., All cards, except the signature-transporting type, uniquely identify themselves in eachtransaction. This means that even if the card does not reveal the persons identity, allpayments a person makes are linked together by the card identity. As a consequence, if areload or any one of the payments made by a person is traced to that person, then they allare., The reason for identification of shared-key cards is that security is thought to be toolow if all cards have the master key. Therefore cards are given unique keys, and the cashregister needs the card identity each time to re-create the corresponding unique card keyfrom the master key., The signature-transporting approach avoids the need for identification, since insteadof a single key per card, cards use a different signature per payment. When signatures aremade by the system provider on blinded checks that are then unblindedby the card, not even the system provider can trace payments to cards., The overall cost of cards for a system is determined not only by how much each cardcosts, but also by how long cards last and how much of each card is needed. Nonrefillablememory cards have a very limited card lifetime and are suitable only for a single purpose.But microcontroller cards can last years and are flexible enough to handle a variety ofthings, not limited to stored value, thereby allowing sharing of card cost among multipleapplications., Bonding chips into modules, assembling them into cards, and printing can cost about thesame for all card types, roughly US$ 0.50-2.00 (plus the cost of the small fraction ofchips that are damaged during production). Nonrefillable cards, however, typically useless durable materials and less costly production techniques., Memory card chips are much smaller, and consequently much less expensive to produce,than those in microcontroller cards. They cost, depending on the type, roughly between US$0.10-0.40 in quantity. Shared-key and signature-transporting cards today use exactly thesame chip hardware, only the masked-in software differs. Suitable chips cost about US$1.00-1.20 in quantity. Signature-creating card chips, which need extra circuitry for theco -processor (or a very powerful processor), require more on a chip, are relatively newon the market, and currently cost several times more., Apart from cards themselves, the other main system costs are card issuing andrefilling, retailer equipment, and system provider processing and security measures., If cards are issued with value on them, as is of course required with nonrefillablememory cards, then they must be transported, stored, and dispensed, using costly securityand audit provisions, like those associated with bank notes. Refillable cards can bedistributed without value and avoid these costs, but on the other hand requireinfrastructure for on-line reload transactions with system providers., Retailer equipment costs may be higher than card costs. Typical ratios of cards topoints of sale (about 100 to 1 for cash registers and higher with vending, phones, etc.)and even the price of current terminals (about US$ 150-1500) suggest that thepoint-of-sale equipment can be more costly than even a dedicated microcontroller cardbase., In the shared-key approach, secured modules trusted by all system providers must beinstalled in all retailer equipment. In open systems such security modules must besignificantly more elaborate and costly than any card, since the security offered by acard is generally considered inadequate to protect the keys of all other cards. But thehigher cost of terminals incorporating such modules is at odds with the objective ofautomating all manner of low value payments, such as in vending. Transaction processing bythe system providers also requires tamper-resistant devices. Proper management of keys andauditing of such systems are cumbersome and expensive. If shared-key systems grow, andstart to include less trustworthy retailers and more system providers, even the minimumsecurity necessary becomes excessively costly. , With either signature card type, suitable software not tamper-resistant modulesis all retailer equipment needs in order to verify payments and later forward thesignatures for reimbursement. These can then be verified by any transaction processingcomputer that has copies of the freely available public keys, thereby reducing exposurewhile both increasing the quality and reducing the cost of security audit and controls., The simplest of the four card types, the memory card, is well suited for closed systemswhere there is little incentive for fraud by persons or retailers. The low card cost makesthis approach attractive, but the low security makes it unsuitable for more general use.The most expensive type, the signature-creating card, seems to offer little fundamentaladvantage over less expensive cards and, incidentally, is far too slow in signing forhighway speed road-tolls and even some telephones., The remaining two card types, shared-key and signature-transporting, can today be basedon exactly the same kinds of microcontroller chips, and thus have the same card cost. Thesystem cost with shared-keys, however, is significantly higher than withsignature-transporting. The main reason is that shared-keys require tamper-resistantmodules at all points of payment and processing sites, while these modules are not neededwith signature- transporting., In addition to cost, there are other reasons to prefer signature-transporting cards forlarger systems. Privacy may be an issue in large-scale consumer systems, and the othercard types are unable to address this problem, while signature-transporting solves itneatly. When more retailers and system providers are included, as large open systems arebuilt or as closed systems grow and merge, the cost of maintaining even merely acceptablesecurity with shared keys becomes prohibitive. By contrast, signature-transportingmaintains a very high level of security while allowing flexible scaling and merging ofsystems.]
[ , Online Cash Checks by David Chaum, , Savings of roughly an order of magnitude in space, storage, and bandwidth over previously published online electronic cash protocols are achieved by the techniques introduced here. In addition, these techniques can increase convenience, make more efficient use of funds, and improve privacy. , "Offline" electronic money [CFN 88] is suitable for low value transactions where "accountability after the fact" is sufficient to deter abuse; online payment [C 89], however, remains necessary for transactions that require "prior restraint" against persons spending beyond their available funds. , Three online schemes are presented here. Each relies on the same techniques for encoding denominations in signatures and for "devaluing" signatures to the exact amount chosen at the time of payment. They differ in how the unspent value is returned to the payer. In the first, all change is accumulated by the payer in a single "cookie jar," which might be deposited at the bank during the next withdrawal transaction. The second and third schemes allow change to be distributed among unspent notes, which can themselves later be spent. The second scheme reveals to the shop and bank the maximum amount for which a note can be spent; the third does not disclose this information. , For simplicity and concreteness, but without loss of generality, a particular denomination scheme will be used here. It assigns the value of 1 cent to public exponent 3 in an RSA system, the value of 2 cents to exponent 5, 4 cents to exponent 7, and so on; each successive power-of-two value is represented by the corresponding odd prime public exponent, all with the same modulus. Much as in [C 89], a third root of an image under the one-way function f (together with the pre-image modulo the bank's RSA composite) is worth 1 cent, a 7th root is worth 4 cents, and a 21st root 5 cents. In other words, a distinct public prime exponent is associated with each digit of the binary integer representation of an amount of payment; for a particular amount of payment, the product of all those prime exponents corresponding to 1 's in the binary representation of the amount is the public exponent of the signature. , A signature on an image under f is "devalued" by raising it to the public powers corresponding to the coin values that should be removed. For instance, a note having a 21st root could be devalued from its 5 cent value, to 1 cent, simply by raising it to the 7th power. , In earlier online payment systems [C 89], the number of separate signatures needed for a payment was in general the Hamming weight of the binary representation of the amount. Since online systems would be used for higher-value payments (as mentioned above), and extra resolution may be desired to provide interest for unspent funds [C 89], an average of roughly an order of magnitude is saved here. , In this first scheme the payer periodically withdraws a supply of notes from the bank, each with the system-wide maximum value. Consider an example, shown in Figure 1.1, in which two notes are withdrawn. The n and ri are random. The ri "blind" (from the bank) the images under the public, one-way function f. The bank's signature corresponds to taking the h-th root, where h = 3*5*7*11. As in all the figures, the payer sends messages from the left and the bank sends from the right. , In preparing the first payment, the payer divides r1 out. The signature is then raised to the 55th power to devalue it from 15 cents to 5 cents. Figure 1.2 shows this first payment. Of course the shop is an intermediary between the payer (left) and the bank (right) in every online payment, but this is not indicated explicitly. Also not shown in the figures are messages used to agree on the amounts of payment. , The first two residues sent in paying, n1 and its signed image under f, are easily verified by the bank to be worth 5 cents. The third residue is a blinded "cookie jar," a blinded image under f of a randomly chosen value j. This cookie jar is modulo a second RSA composite that is only used for cookie jars. Once the bank verifies the funds received, and that n1 has not been spent previously, it signs and returns the blinded cookie jar (under the cookie jar modulus) with public exponents corresponding to the change due. , The second payment, shown in figure 1.3, is essentially the same as the first, except that the amount is 3 cents and the cookie jar now has some roots already on it. If more payments were to be made using the same cookie jar, all resulting signatures for change would accumulate. , The cookie jar might conveniently be deposited, as shown in figure 1.4, during the withdrawal of the next batch of notes. It is verified by the bank much as a payment note would be: the roots must be present in the claimed multiplicity and the pre-image under f must not have been deposited before. , The cookie jar approach gives the effect of an online form of "offline checks" [C 89], in that notes of a fixed value are withdrawn and the unspent parts later credited to the payer during a refund transaction. , Figure 2 depicts a somewhat different scheme, which allows change to be spent without an intervening withdrawal transaction. Withdrawals can be just as in the cookie-jar scheme, but here a single modulus is used for everything in the system. The products of public exponents representing the various amounts are as follows: d is the amount paid, g is the note value, the "change" c is g/d, and h is again the maximal amount, where d | g | h. A payment (still to the bank through a shop) includes first and second components that are the same as in the cookie-jar scheme. The third component is the amount of change c the payer claims should be returned. The fourth is a (blinded) number m, which could be an image under f used in a later payment just as n is used in this one. , The signature returned contains a "protection" factor (shown inside the padlock). This factor ensures that the payer actually has the c-th root of f(n), by requiring that the payer apply f to it before dividing the result out of the signature. Without such protection, a payer could get the systemwide maximum change, regardless of how much change is actually due; with it, the change claimed can only be recovered if the corresponding roots on n are in fact known to the payer. , The change returned in a payment can be divided into parts that fill in missing denominations in notes not yet spent. Suppose, for example, that the last payment is spent with d = 5*11, c = 3*7, and that m is formed by the payer as shown in the first line of Figure 3.1. Then unblinding after the payment yields the a shown in the second line. , (Use === for "is equivalent to") , From a, the two roots shown in the last two lines of Figure 3.2 are readily computed. (This technique is easily extended to include any number of separate roots.) Thus the values unused in the last payment fill in roots missing in notes n1 and n2., Because overpayment allows change to be returned in any chosen denominations (not shown), the payer has extra flexibility and is able to use all funds held. This also increases convenience by reducing the need for withdrawals. , Although the combination of the previous two subsections is quite workable, it may be desirable for the payer not to have to reveal c to the shop or the bank. Figure 4 shows a system allowing this. The payment message is just as in the declared note value protocol above, except that c is not sent. The protection factor (shown again in a lock) is also placed under the signature, but it is missing the extra f and is raised to a random power z chosen by the bank , If z were known to the payer before payment, then the payer could -z cheat by including f(n) in the third component; this would yield the payer the system-wide maximum change, even if none were due. Consider a single change exponent q. If z mod q is guessed correctly by a cheating payer, then the payer improperly gets the corresponding coin value. Thus the chance of successful cheating is 1/q. If, however, the divisors of h are chosen sufficiently large, quite practical security can be achieved. When the possibilities of distributing change and refunding are included, this scheme's privacy surpasses that of a coin system. , Combining online coins improves efficiency, use of funds, convenience, and privacy. , Chaum, D., "Privacy Protected Payments: Unconditional Payer and/or Payee Anonymity," in Smart Card 2000, North-Holland, 1989, pp. 69-92. , Chaum, D., A. Fiat, &amp; M. Naor, "Offline Electronic Cash," Proceedings of Crypto '88. ]
[ , , by David Chaum , (This article appeared in Scientific American, August 1992, p. 96-101. Copyright © 1992 by Scientific American, Inc.), A cryptographic invention known as a blind signature permits numbers to serve as electronic cash or to replace conventional identification. The author hopes it may return control of personal information to the individual. , , Every time you make a telephone call, purchase goods using a credit card, subscribe to a magazine or pay your taxes, that information goes into a data base somewhere. Furthermore, all these records can be linked so that they constitute in effect a single dossier on your life not only your medical and financial history but also what you buy, where you travel and whom you communicate with. It is almost impossible to learn the full extent of the files that various organizations keep on you, much less to assure their accuracy or to control who may gain access to them., Organizations link records from different sources for their own protection. Certainly it is in the interest of a bank looking at a loan application to know that John Doe has defaulted on four similar loans in the past two years. The bank's possession of that information also helps its other customers, to whom the bank passes on the cost of bad loans. In addition, these records permit Jane Roe, whose payment history is impeccable, to establish a charge account at a shop that has never seen her before., That same information in the wrong hands, however, provides neither protection for businesses nor better service for consumers. Thieves routinely use a stolen credit card number to trade on their victims' good payment records; murderers have tracked down their targets by consulting government-maintained address records. On another level, the U.S. Internal Revenue Service has attempted to single out taxpayers for audits based on estimates of household income compiled by mailing-list companies., The growing amounts of information that different organizations collect about a person can be linked because all of them use the same key (in the U.S. the social security number) to identify the individual in question. This identifier-based approach perforce trades off security against individual liberties. The more information that organizations have (whether the intent is to protect them from fraud or simply to target marketing efforts), the less privacy and control people retain., Over the past eight years, my colleagues and I at CWI (the Dutch nationally funded Center for Mathematics and Computer Science in Amsterdam) have developed a new approach, based on fundamental theoretical and practical advances in cryptography, that makes this trade-off unnecessary. Transactions employing these techniques avoid the possibility of fraud while maintaining the privacy of those who use them., In our system, people would in effect give a different (but definitively verifiable) pseudonym to every organization they do business with and so make dossiers impossible. They could pay for goods in untraceable electronic cash or present digital credentials that serve the function of a banking passbook, driver's license or voter registration card without revealing their identity. At the same time, organizations would benefit from increased security and lower record-keeping costs., Recent innovations in microelectronics make this vision practical by providing personal "representatives" that store and manage their owners' pseudonyms, credentials and cash. Microprocessors capable of carrying out the necessary algorithms have already been embedded in pocket computers the size and thickness of a credit card. Such systems have been tested on a small scale and could be in widespread use by the middle of this decade., The starting point for this approach is the digital signature, first proposed in 1976 by Whitfield Diffie, then at Stanford University. A digital signature transforms the message that is signed so that anyone who reads it can be sure of who sent it [see "The Mathematics of Public-Key Cryptography", by Martin E. Hellman; Scientific American, August 1979]. These signatures employ a secret key used to sign messages and a public one used to verify them. Only a message signed with the private key can be verified by means of the public one. Thus, if Alice wants to send a signed message to Bob (these two are the cryptographic community's favorite hypothetical characters), she transforms it using her private key, and he applies her public key to make sure that it was she who sent it. The best methods known for producing forged signatures would require many years, even using computers billions of times faster than those now available., To see how digital signatures can provide all manner of unforgeable credentials and other services, consider how they might be used to provide an electronic replacement for cash. The First Digital Bank would offer electronic bank notes: messages signed using a particular private key. All messages bearing one key might be worth a dollar, all those bearing a different key five dollars, and so on for whatever denominations were needed. These electronic bank notes could be authenticated using the corresponding public key, which the bank has made a matter of record. First Digital would also make public a key to authenticate electronic documents sent from the bank to its customers., To withdraw a dollar from the bank, Alice generates a note number (each note bears a different number, akin to the serial number on a bill); she chooses a 100-digit number at random so that the chance anyone else would generate the same one is negligible. She signs the number with the private key corresponding to her "digital pseudonym" (the public key that she has previously established for use with her account). The bank verifies Alice's signature and removes it from the note number, signs the note number with its worth-one-dollar signature and debits her account. It then returns the signed note along with a digitally signed withdrawal receipt for Alice's records. In practice, the creation, signing and transfer of note numbers would be carried out by Alice's card computer. The power of the cryptographic protocols, however, lies in the fact that they are secure regardless of physical medium: the same transactions could be carried out using only pencil and paper., When Alice wants to pay for a purchase at Bob's shop, she connects her "smart" card with his card reader and transfers one of the signed note numbers the bank has given her. After verifying the bank's digital signature, Bob transmits the note to the bank, much as a merchant verifies a credit card transaction today. The bank reverifies its signature, checks the note against a list of those already spent and credits Bob's account. It then transmits a "deposit slip," once again unforgeably signed with the appropriate key. Bob hands the merchandise to Alice along with his own digitally signed receipt, completing the transaction., This system provides security for all three parties. The signatures at each stage prevent any one from cheating either of the others: the shop cannot deny that it received payment, the bank cannot deny that it issued the notes or that it accepted them from the shop for deposit, and the customer can neither deny withdrawing the notes from her account nor spend them twice., This system is secure, but it has no privacy. If the bank keeps track of note numbers, it can link each shop's deposit to the corresponding withdrawal and so determine precisely where and when Alice (or any other account holder) spends her money. The resulting dossier is far more intrusive than those now being compiled. Furthermore, records based on digital signatures are more vulnerable to abuse than conventional files. Not only are they self-authenticating (even if they are copied, the information they contain can be verified by anyone), but they also permit a person who has a particular kind of information to prove its existence without either giving the information away or revealing its source. For example, someone might be able to prove incontrovertibly that Bob had telephoned Alice on 12 separate occasions without having to reveal the time and place of any of the calls., I have developed an extension of digital signatures, called blind signatures, that can restore privacy. Before sending a note number to the bank for signing, Alice in essence multiplies it by a random factor. Consequently, the bank knows nothing about what it is signing except that it carries Alice's digital signature. After receiving the blinded note signed by the bank, Alice divides out the blinding factor and uses the note as before., The blinded note numbers are "unconditionally untraceable" that is, even if the shop and the bank collude, they cannot determine who spent which notes. Because the bank has no idea of the blinding factor, it has no way of linking the note numbers that Bob deposits with Alice's withdrawals. Whereas the security of digital signatures is dependent on the difficulty of particular computations, the anonymity of blinded notes is limited only by the unpredictability of Alice's random numbers. If she wishes, however, Alice can reveal these numbers and permit the notes to be stopped or traced., Blinded electronic bank notes protect an individual's privacy, but because each note is simply a number, it can be copied easily. To prevent double spending, each note must be checked on-line against a central list when it is spent. Such a verification procedure might be acceptable when large amounts of money are at stake, but it is far too expensive to use when someone is just buying a newspaper. To solve this problem, my colleagues Amos Fiat and Moni Naor and I have proposed a method for generating blinded notes that requires the payer to answer a random numeric query about each note when making a payment. Spending such a note once does not compromise unconditional untraceability, but spending it twice reveals enough information to make the payer's account easily traceable. In fact, it can yield a digitally signed confession that cannot be forged even by the bank., Cards capable of such anonymous payments already exist. Indeed, DigiCash, a company with which I am associated, has installed equipment in two office buildings in Amsterdam that permits copiers, fax machines, cafeteria cash registers and even coffee vending machines to accept digital "bank notes." We have also demonstrated a system for automatic toll collection in which automobiles carry a card that responds to radioed requests for payment even as they are traveling at highway speeds., My colleagues and I call a computer that handles such cryptographic transactions a "representative." A person might use different computers as representatives depending on which was convenient: Bob might purchase software (transmitted to him over a network) by using his home computer to produce the requisite digital signatures, go shopping with a "palm-top" personal computer and carry a smart credit card to the beach to pay for a drink or crab cakes. Any of these machines could represent Bob in a transaction as long as the digital signatures each generates are under his control., Indeed, such computers can act as representatives for their owners in virtually any kind of transaction. Bob can trust his representative and Alice hers because they have each chosen their own machine and can reprogram it at will (or, in principle, build it from scratch). Organizations are protected by the cryptographic protocol and so do not have to trust the representatives., The prototypical representative is a smart credit-card-size computer containing memory and a microprocessor. It also incorporates its own keypad and display so that its owner can control the data that are stored and exchanged. If a shop provided the keypad and display, it could intercept passwords on their way to the card or show one price to the customer and another to the card. Ideally, the card would communicate with terminals in banks and shops by a short-range communications link such as an infrared transceiver and so need never leave its owner's hands., When asked to make a payment, the representative would present a summary of the particulars and await approval before releasing funds. It would also insist on electronic receipts from organizations at each stage of all transactions to substantiate its owner's position in case of dispute. By requiring a password akin to the PIN (personal identifying number) now used for bank cards, the representative could safeguard itself from abuse by thieves. Indeed, most people would probably keep backup copies of their keys, electronic bank notes and other data; they could recover their funds if a representative were lost or stolen., Personal representatives offer excellent protection for individual privacy, but organizations might prefer a mechanism to protect their interests as strongly as possible. For example, a bank might want to prevent double spending of bank notes altogether rather than simply detecting it after the fact. Some organizations might also want to ensure that certain digital signatures are not copied and widely disseminated (even though the copying could be detected afterwards)., Organizations have already begun issuing tamperproof cards (in effect, their own representatives) programmed to prevent undesirable behavior. But these cards can act as "Little Brothers" in everyone's pocket., We have developed a system that satisfies both sides. An observer a tamper-resistant computer chip, issued by some entity that organizations can trust acts like a notary and certifies the behavior of a representative in which it is embedded. Philips Industries has recently introduced a tamperresistant chip that has enough computing power to generate and verify digital signatures. Since then, Siemens, Thomson CSF and Motorola have announced plans for similar circuits, any of which could easily serve as an observer., The central idea behind the protocol for observers is that the observer does not trust the representative in which it resides, nor does the representative trust the observer. Indeed, the representative must be able to control all data passing to or from the observer; otherwise the tamperproof chip might be able to leak information to the world at large., When Alice first acquires an observer, she places it in her smart-card representative and takes it to a validating authority. The observer generates a batch of public and private key pairs from a combination of its own random numbers and numbers supplied by the card. The observer does not reveal its numbers but reveals enough information about them so that the card can later check whether its numbers were in fact used to produce the resulting keys. The card also produces random data that the observer will use to blind each key., Then the observer blinds the public keys, signs them with a special built-in key and gives them to the card. The card verifies the blinding and the signature and checks the keys to make sure they were correctly generated. It passes the blinded, signed keys to the validating authority, which recognizes the observer's built-in signature, removes it and signs the blinded keys with its own key. The authority passes the keys back to the card, which unblinds them. These keys, bearing the signature of the validating authority, serve as digital pseudonyms for future transactions; Alice can draw on them as needed., An observer could easily prevent (rather than merely detect) double spending of electronic bank notes. When Alice withdraws money from her bank, the observer witnesses the process and so knows what notes she received. At Bob's shop, when Alice hands over a note from the bank, she also hands over a digital pseudonym (which she need use only once) signed by the validating authority. Then the observer, using the secret key corresponding to the validated pseudonym, signs a statement certifying that the note will be spent only once, at Bob's shop and at this particular time and date. Alice's card verifies the signed statement to make sure that the observer does not leak any information and passes it to Bob. The observer is programmed to sign only one such statement for any given note., Many transactions do not simply require a transfer of money. Instead they involve credentials information about an individual's relationship to some organization. In today's identifier-based world, all of a person's credentials are easily linked. If Alice is deciding whether to sell Bob insurance, for example, she can use his name and date of birth to gain access to his credit status, medical records, motor vehicle file and criminal record, if any., Using a representative, however, Bob would establish relationships with different organizations under different digital pseudonyms. Each of them can recognize him unambiguously, but none of their records can be linked., In order to be of use, a digital credential must serve the same function as a paper-based credential such as a driver's license or a credit report. It must convince someone that the person attached to it stands in a particular relation to some issuing authority. The name, photograph, address, physical description and code number on a driver's license, for example, serve merely to link it to a particular person and to the corresponding record in a data base. Just as a bank can issue unforgeable, untraceable electronic cash, so too could a university issue signed digital diplomas or a credit-reporting bureau issue signatures indicating a person's ability to repay a loan., When the young Bob graduates with honors in medieval literature, for example, the university registrar gives his representative a digitally signed message asserting his academic credentials. When Bob applies to graduate school, however, he does not show the admissions committee that message. Instead his representative asks its observer to sign a statement that he has a B.A. cum laude and that he qualifies for financial aid based on at least one of the university's criteria (but without revealing which ones). The observer, which has verified and stored each of Bob's credentials as they come in, simply checks its memory and signs the statement if it is true., In addition to answering just the right question and being more reliable than paper ones, digital credentials would be both easier for individuals to obtain and to show and cheaper for organizations to issue and to authenticate. People would no longer need to fill out long and revealing forms. Instead their representatives would convince organizations that they meet particular requirements without disclosing any more than the simple fact of qualification. Because such credentials reveal no unnecessary information, people would be willing to use them even in contexts where they would not willingly show identification, thus enhancing security and giving the organization more useful data than it would otherwise acquire., Positive credentials, however, are not the only kind that people acquire. They may also acquire negative credentials, which they would prefer to conceal: felony convictions, license suspensions or statements of pending bankruptcy. In many cases, individuals will give organizations the right to inflict negative credentials on them in return for some service. For instance, when Alice borrows books from a library, her observer would be instructed to register an overdue notice unless it had received a receipt for the books' return within some fixed time., Once the observer has registered a negative credential, an organization can find out about it simply by asking the observer (through the representative) to sign a message attesting to its presence or absence. Although a representative could muzzle the observer, it could not forge an assertion about the state of its credentials. In other cases, organizations might simply take the lack of a positive credential as a negative one. If Bob signs up for skydiving lessons, his instructors may assume that he is medically unfit unless they see a credential to the contrary., For most credentials, the digital signature of an observer is sufficient to convince anyone of its authenticity. Under some circumstances, however, an organization might insist that an observer demonstrate its physical presence. Otherwise, for example, any number of people might be able to gain access to nontransferable credentials (perhaps a health club membership) by using representatives connected by concealed communications links to another representative containing the desired credential., Moreover, the observer must carry out this persuasion while its input and output are under the control of the representative that contains it. When Alice arrives at her gym, the card reader at the door sends her observer a series of single-bit challenges. The observer immediately responds to each challenge with a random bit that is encoded by the card on its way back to the organization. The speed of the observer's response establishes that it is inside the card (since processing a single bit introduces almost no delay compared with the time that signals take to traverse a wire). After a few dozen iterations the card reveals to the observer how it encoded the responses; the observer signs a statement including the challenges and encoded responses only if it has been a party to that challengeresponse sequence. This process convinces the organization of the observer's presence without allowing the observer to leak information., Organizations can also issue credentials using methods that depend on cryptography alone rather than on observers. Although currently practical approaches can handle only relatively simple queries, Gilles Brassard of the University of Montreal, Claude Cripeau of the Ecole Normale Supirieure and I have shown how to answer arbitrary combinations of questions about even the most complex credentials while maintaining unconditional unlinkability. The concealment of purely cryptographic negative credentials could be detected by the same kinds of techniques that detect double spending of electronic bank notes. And a combination of these cryptographic methods with observers would offer accountability after the fact even if the observer chip were somehow compromised. , The improved security and privacy of digital pseudonyms exact a price: responsibility. At present, for example, people can disavow credit card purchases made over the telephone or cash withdrawals from an automatic teller machine (ATM). The burden of proof is on the bank to show that no one else could have made the purchase or withdrawal. If computerized representatives become widespread, owners will establish all their own passwords and so control access to their representatives. They will be unable to disavow a representative's actions., Current tamper-resistant systems such as ATMs and their associated cards typically rely on weak, inflexible security procedures because they must be used by people who are neither highly competent nor overly concerned about security. If people supply their own representatives, they can program them for varying levels of security as they see fit. (Those who wish to trust their assets to a single four-digit code are free to do so, of course.) Bob might use a short PIN (or none at all) to authorize minor transactions and a longer password for major ones. To protect himself from a robber who might force him to give up his passwords at gunpoint, he could use a "duress code" that would cause the card to appear to operate normally while hiding its more important assets or credentials or perhaps alerting the authorities that it had been stolen., A personal representative could also recognize its owner by methods that most people would consider unreasonably intrusive in an identifier-based system; a notebook computer, for example, might verify its owner's voice or even fingerprints. A supermarket checkout scanner capable of recognizing a person's thumbprint and debiting the cost of groceries from their savings account is Orwellian at best. In contrast, a smart credit card that knows its owner's touch and doles out electronic bank notes is both anonymous and safer than cash. In addition, incorporating some essential part of such identification technology into the tamperproof observer would make such a card suitable even for very high security applications. , Computerized transactions of all kinds are becoming ever more pervasive. More than half a dozen countries have developed or are testing chip cards that would replace cash. In Denmark, a consortium of banking, utility and transport companies has announced a card that would replace coins and small bills; in France, the telecommunications authorities have proposed general use of the smart cards now used at pay telephones. The government of Singapore has requested bids for a system that would communicate with cars and charge their smart cards as they pass various points on a road (as opposed to the simple vehicle identification systems already in use in the U.S. and elsewhere). And cable and satellite broadcasters are experimenting with smart cards for delivering pay-per-view television. All these systems, however, are based on cards that identify themselves during every transaction., If the trend toward identifier-based smart cards continues, personal privacy will be increasingly eroded. But in this conflict between organizational security and individual liberty, neither side emerges as a clear winner. Each round of improved identification techniques, sophisticated data analysis or extended linking can be frustrated by widespread noncompliance or even legislated limits, which in turn may engender attempts at further control., Meanwhile, in a system based on representatives and observers, organizations stand to gain competitive and political advantages from increased public confidence (in addition to the lower costs of pseudonymous record-keeping). And individuals, by maintaining their own cryptographically guaranteed records and making only necessary disclosures, will be able to protect their privacy without infringing on the legitimate needs of those with whom they do business., The choice between keeping information in the hands of individuals or of organizations is being made each time any government or business decides to automate another set of transactions. In one direction lies unprecedented scrutiny and control of people's lives, in the other, secure parity between individuals and organizations. The shape of society in the next century may depend on which approach predominates.]
J. Cryptology (1988) 1:65-75Journal of Cryptology9 1988 International Association forCryptologic ResearchThe Dining Cryptographers Problem:Unconditional Sender and Recipient UntraceabilityDavid C h a u mCentre for Mathematics and Computer Science, Kruislan 413, 1098SJ Amsterdam,The NetherlandsAbstract. Keeping confidential who sends which messages, in a world whereany physical transmission can be traced to its origin, seems impossible.The solution presented here is unconditionally or cryptographicallysecure, depending onwhether it is based on one-time-usekeys or on public keys, respectively.It can beadapted to address efficientlya wide variety of practical considerations.Key words. Untraceability, Unconditional Security, Pseudonymity.IntroductionThree cryptographers are sitting down to dinner at their favorite three-star restaurant. Their waiter informs them that arrangements have been made with themaitre d'h6tel for the bill to be paid anonymously. One of the cryptographers mightbe paying for the dinner, or it might have been NSA (U.S. National Security Agency).The three cryptographers respect each other's right to make an anonymous payment, but they wonder if NSA is paying. They resolve their uncertainty fairly bycarrying out the following protocol:Each cryptographer flips an unbiased coin behind his menu, between him andthe cryptographer on his right, so that only the two of them can see the outcome.Each cryptographer then states aloud whether the two coins he can s e e - - t h e onehe flipped and the one his left-hand neighbor flipped--fell on the same side or ondifferent sides. If one of the cryptographers is the payer, he states the opposite ofwhat he sees. An odd number of differences uttered at the table indicates that acryptographer is paying; an even number indicates that NSA is paying (assumingthat the dinner was paid for only once). Yet if a cryptographer is paying, neither ofthe other two learns anything from the utterances about which cryptographer it is.To see why the protocol is unconditionally secure if carried out faithfully, considerthe dilemma of a cryptographer who is not the payer and wishes to find out whichcryptographer is. (IfNSA pays, there is no anonymity problem.) There are two cases.In case (1) the two coins he sees are the same, one of the other cryptographers said"different," and the other one said "same." If the hidden outcome was the same asthe two outcomes he sees, the cryptographer who said "different" is the payer; if theoutcome was different, the one who said "same" is the payer. But since the hiddencoin is fair, both possibilities are equally likely. In case (2) the coins he sees are65 66D. Chaumdifferent; if both other cryptographers said "different," then the payer is closest tothe coin that is the same as the hidden coin; if both said "same," then the payer isclosest to the coin that differs from the hidden coin. Thus, in each subcase, anonpaying cryptographer learns nothing about which of the other two is paying.The cryptographers become intrigued with the ability to make messages publicuntraceably. They devise a way to do this at the table for a statement of arbitrarylength: the basic protocol is repeated over and over; when one cryptographer wishesto make a message public, he merely begins inverting his statements in those roundscorresponding to l's in a binary coded version of his message. If he notices that hismessage would collide with some other message, he may for example wait a numberof rounds chosen at random from a suitable distribution before trying to transmitagain.1. Generalizing the ApproachDuring dinner, the cryptographers also consider how any number of participantsgreater than one can carry out a version of the protocol. (With two participants,only nonparticipant listeners are unable to distinguish between the two potentialsenders.) Each participant has a secret key bit in common with, say, every otherparticipant. Each participant outputs the sum, modulo two, of all the key bits heshares, and if he wishes to transmit, he inverts his output. If no participant transmits,the modulo two sum of the outputs must be zero, since every key bit enters exactlytwice; if one participant transmits, the sum must be one. (In fact, any even numberof transmitting participants yields zero, and any odd number yields one.) For jrounds, each participant could have a j-bit key in common with every otherparticipant, and the ith bit of each such key would be used only in the ith round.Detected collision of messages leads to attempted retransmission as describedabove; undetected collision results only from an odd number of synchronizedidentical message segments. (Generalization to fields other than GF(2) is possible,but seems to offer little practical advantage.)Other generalizations are also considered during dinner. The underlying assumptions are first made explicit, including modeling key-sharing arrangements asgraphs. Next, the model is illustrated with some simple examples. The potential forcooperations of participants to violate the security of others is then looked at.Finally, a proof of security based on systems of linear equations is given.1.1. ModelEach participant is assumed to have two kinds of secret: (a) the keys shared withother participants for each round; and (b) the inversion used in each round (i.e., a 1if the participant inverts in that round and a 0 if not). Some or all of a participant'ssecrets may be given to other participants in various forms of collusion, discussionof which is postponed until Section 1.3. (For simplicity in exposition, the possibilityof secrets being stolen is ignored throughout.)The remaining information about the system may be described as: (a) who shareskeys with whom; and (b) w h a t each participant outputs during each round (the The DiningCryptographersProblem67modulo two sum of that participant's keys and inversion). This information neednot be secret to ensure untraceability. If it is publicly known and agreed, it allowsvarious extensions discussed in Sections 2.5 and 2.6. The sum of all the outputs will,of course, usually become known to all participants.In the terminology of graphs, each participant corresponds to a vertex and eachkey corresponds to an edge. An edge is incident on the vertices corresponding tothe pair of participants that shares the corresponding key. From here on, the graphand dinner-table terminologies will be used interchangeably. Also, without loss ofgenerality, it will be assumed that the graph is connected (i.e., that a path existsbetween every pair of vertices), since each connected component (i.e., each maximalconnected subgraph) could be considered a separate untraceable-sender system.An anonymity set seen by a set of keys is the set of vertices in a connectedcomponent of the graph formed from the original graph by removing the edgesconcerned. Thus a set of keys sees one anonymity set for each connected partitioninduced by removing the keys. The main theorem of Section 1.4 is essentially thatthose having only the public information and a set of keys seeing some anonymityset can learn nothing about the members of that anonymity set except the overallparity of their inversions. Thus, for example, any two participants connected by atleast one chain of keys unknown to an observer are both in the same anonymityset seen by the observer's keys, and the observer gains nothing that would helpdistinguish between their messages.1.2. Some ExamplesA few simple consequences of the above model may be illustrative. The anonymityset seen by the empty set (i.e., by a nonparticipant observer) is the set of all vertices,since the graph is assumed connected and remains so after zero edges are removed.Also, the anonymity sets seen by the full set of edges are all singleton sets, since eachvertex's inversion is just the sum of its output and the corresponding key bits.If all other participants cooperate fully against one, of course no protocol cankeep that singleton's messages untraceable, since untraceability exists only amonga set of possible actors, and if the set has only one member, its messages are traceable.For similar reasons, if a participant believes that some subset of other participantswill fully cooperate against him, there is no need for him to have keys in commonwith them.A biconnected graph (i.e., a graph with at least two vertex-disjoint paths betweenevery pair of vertices) has no cut-vertices (i.e., a single vertex whose removalpartitions the graph into disjoint subgraphs). In such a graph, the set of edgesincident on a vertex v sees (apart from v) one anonymity set containing all othervertices, since there is a path not containing v between every pair of vertices, andthus they form a connected subgraph excluding v; each participant acting alonelearns nothing about the contribution of other participants.1.3. Collusion of ParticipantsSome participants may cooperate by pooling their keys in efforts to trace themessages of others; such cooperation will be called collusion. For simplicity, the 68D. Chaumpossibilities for multiple collusions or for pooling of information other than fulledges will be ignored. Colluders who lie to each other are only touched on briefly,in Section 2.6.Consider collusion in a complete graph. A vertex is only seen as a singletonanonymity set by the collection of all edges incident on it; all other participantsmust supply the key they share with a participant in order to determine thatparticipant's inversions. But since a collusion of all but one participant can alwaystrace that participant merely by pooling its members' inversions as already mentioned, it gains nothing more by pooling its keys. The nonsingleton anonymity setseen by all edges incident on a colluding set of vertices in a complete graph is theset of all other vertices; again, a collusion yields nothing more from pooling all itskeys than from pooling all its inversions.Now consider noncomplete graphs. A full collusion is a subset of participantspooling all of their keys. The pooled keys see each colluder as a singleton anonymityset; the colluders completely sacrifice the untraceability of their own messages. If afull collusion includes a cut-set of vertices (i.e., one whose removal partitions thegraph), the collusion becomes nontrivial because it can learn something about theorigin of messages originating outside the collusion; the noncolluding vertices arepartitioned into disjoint subgraphs, which are the anonymity sets seen by the pooledkeys.Members of a partial collusion pool some but not all of their keys. Unlike themembers of a full collusion, each member of a partial collusion in general has adifferent set of keys. For it to be nontrivial, a partial collusion's pooled keys mustinclude the bridges or separating edges of a segregation or splitting of the graph(i.e., those edges whose removal would partition the graph). Settings are easilyconstructed in which the pooled keys see anonymity sets that partition the graphand yet leave each colluder in a nonsingleton partition seen by any other participant.Thus, coUuders can join a collusion without having to make themselves completelytraceable to the collusion's other members.1.4. Proof of SecurityConsider, without loss of generality, a single round in which say some full collusionknows some set of keys. Remove the edges known to the collusion from thekey-sharing graph and consider any particular connected component C of theremaining graph. The vertices of C thus form an anonymity set seen by the pooledkeys.Informally, what remains to be shown is that the only thing the collusion learnsabout the members of C is the parity sum of their inversions. This is intuitivelyapparent, since the inversions of the members of C are each in effect hidden fromthe collusion by one or more unknown key bits, and only the parity of the sum ofthese key bits is known (to be zero). Thus the inversions are hidden by a one-timepad, and only their parity is revealed, because only the parity of the pad is known.The setting is formalized as follows: the connected component C is comprised ofm vertices and n edges. The incidence matrix M of C is defined as usual, with thevertices labeling the rows and the edges labeling the columns. Let K, I, and A bestochastic variables defined on GF(2) n, GF(2) m, and GF(2) m, respectively, such that The Dining CryptographersProblem69K is uniformly distributed over GF(2) ", K and I are mutually independent, andA = (MK) @ I. In terms of the protocol, K comprises the keys corresponding to theedges, I consists of the inversions corresponding to the vertices, and A is formed bythe outputs of the vertices. Notice that the parity of A (i.e., the modulo two sum ofits components) is always equal to the parity of I, since the columns of M each havezero parity. The desired result is essentially that A reveals no more informationabout I than the parity of I. More formally:Theorem.Let a be in GF(2) n. For each i in GF(2)", which is assumed by I withnonzero probability and which has the same parity as a, the conditional probabilitythat A = a given that I = i is 2 l-re. Hence, the conditional probability that I = i giventhat A = a is the a priori probability that I = i.Proof. Let i e GF(2)" have the same parity as a. Consider the system of linearequations (MK) G i = a, in k e GF(2) n. Since the columns of M each have evenparity, as mentioned above, its rows are linearly dependent over GF(2) m. But as aconsequence of the connectedness of the graph, every proper subset of rows of Mis linearly independent. Thus, the rank of M is m - 1, and so each vector with zeroparity can be written as a linear combination of the columns of M. This implies thatthe system is solvable because i ~ a has even parity. Since the set of n column vectorsof M has rank m - 1, the system has exactly 2 "-m+l solutions.Together with the fact that K and I are mutually independent and that K isuniformly distributed, the theorem follows easily.[]2. Some Practical ConsiderationsAfter dinner, while discussing how they can continue to make untraceable statements from this respective homes, the cryptographers take up a variety of othertopics. In particular, they consider different ways to establish the needed keys;debate adapting the approach to various kinds of communication networks;examine the traditional problems of secrecy and authentication in the context of asystem that can provide essentially optimal untraceability; address denial of servicecaused by malicious and devious participants; and propose means to discouragesocially undesirable messages from being sent.2.1. Establishing K e y sOne way to provide the keys needed for longer messages is for one member of eachpair to toss many coins in advance. Two identical copies of the resulting bits aremade, say each on a separate optical disk. Supplying one such disk (which todaycan hold on the order of 10 l~ bits) to a partner provides enough key bits to allowpeople to type messages at full speed for years. If participants are not transmittingall the time, the keys can be made to last even longer by using a substantially slowerrate when no message is being sent; the full rate would be invoked automaticallyonly when a 1 bit indicated the beginning of a message. (This can also reduce thebandwidth requirements discussed in Section 2.2.) 70D. ChaumAnother possibility is for a pair to establish a short key and use a cryptographicpseudorandom-sequence generator to expand it as needed. Of course this systemmight be broken if the generator were broken. Cryptanalysis may be made moredifficult, however, by lack of access to the output of individual generators. Evenwhen the cryptographers do not exchange keys at dinner, they can safely do so laterusing a public-key distribution system (first proposed by [4] and [3]).2.2 Underlying Communication TechniquesA variety of underlying communication networks can be used, and their topologyneed not be related to that of the key-sharing graph.Communication systems based on simple cycles, called rings, are common in localarea networks. In a typical ring, each node receives each bit and passes it roundrobin to the next node. This technology is readily adapted to the present protocols.Consider a single-bit message like the "I paid" message originally sent at the dinnertable. Each participant exclusive-or's the bit he receives with his own output beforeforwarding it to the next participant. When the bit has traveled full circle, it is theexclusive-or sum of all the participants' outputs, which is the desired result of theprotocol. To provide these messages to all participants, each bit is sent around asecond time by the participant at the end of the loop.Such an adapted ring requires, on average, a fourfold increase in bandwidth overthe obvious traceable protocols in which messages travel only halfway around onaverage before being taken off the ring by their recipients. Rings differ from thedinner table in that several bit-transmission delays may be required before all theoutputs of a particular round are known to all participants; collisions are detectedonly after such delays.Efficient use of many other practical communication techniques requires participants to group output bits into blocks. For example, in high-capacity broadcastsystems, such as those based on coaxial cable, surface radio, or satellites, moreefficient use of channel capacity is obtained by grouping a participant's contributioninto a block about the size of a single message (see, e.g., [5]). Use of such communication techniques could require an increase in bandwidth on the order of thenumber of participants.In a network with one message per block, the well-known contention protocolscan be used: time is divided evenly into frames; a participant transmits a blockduring one frame; if the block was garbled by collision (presumably with anothertransmitted block), the participant waits a number of frames chosen at random fromsome distribution before attempting to retransmit; the participants' waiting intervals may be adjusted on the basis of the collision rate and possibly of other heuristics[5].In a network with many messages per block, a first block may be used by variousanonymous senders to request a "slot reservation" in a second block. A simplescheme would be for each anonymous sender to invert one randomly selected bitin the first block for each slot they wish to reserve in the second block. After theresult of the first block becomes known, the participant who caused the ith 1 bit inthe first block sends in the ith slot of the second block. The DiningCryptographersProblem712.3. Example Key-Sharing GraphsIn large systems it may be desirable to use fewer than the m(m - 1)/2 keys requiredby a complete graph. If the graph is merely a cycle, then individuals acting alonelearn nothing, but any two colluders can partition the graph, perhaps fully compromising a participant immediately between them. Such a topology might nevertheless be adequate in an application in which nearby participants are not likely tocollude against one another.A different topology assumes the existence of a subset of participants who eachpartidpant believes are sufficiently unlikely to collude, such as participants withconflicting interests. This subset constitutes a fully connected subgraph, and theother participants each share a key with every member of it. Every participant isthen untraceable among all the others, unless all members of the completely connected subset cooperate. (Such a situation is mentioned again in Section 3.)If many people wish to participate in an untraceable communication system,hierarchical arrangements may offer further economy of keys. Consider an examplein which a representative from each local fully connected subgraph is also a memberof the fully connected central subgraph. The nonrepresentative members of a localsubgraph provide the sum of their outputs to their representative. Representativeswould then add their own contributions before providing the sum to the centralsubgraph. Only a local subgraph's representative, or a collusion of representativesfrom all other local subgraphs, can recognize messages as coming from the localsubgraph. A collusion comprising the representative and all but one nonrepresentative member of a local subgraph is needed for messages to be recognized as comingfrom the remaining member.2.4. Secrecy and AuthenticationWhat about the usual cryptologic problems of secrecy and authentication?A cryptographer can ensure the secrecy of an anonymous message by encryptingthe message with the intended recipient's public key. (The message should includea hundred or so random bits to foil attempts to confirm a guess at its content [1].)The sender can even keep the identity of the intended recipient secret by leaving itto each recipient to try to decrypt every message. Alternatively, a prearranged prefixcould be attached to each message so that the recipient need only decrypt messageswith recognized prefixes. To keep even the multiplicity of a prefix's use frombeing revealed, a different prefix might be used each time. New prefixes could beagreed in advance, generated cryptographically as needed, or supplied in earliermessages.Authentication is also quite useful in systems without identification. Even thoughthe messages are untraceable, they might still bear digital signatures correspondingto public-key "digital pseudonyms" Ill; only the untraceable owner of such apseudonym would be able to sign subsequent messages with it. Secure paymentprotocols have elsewhere been proposed in which the payer and/or the payee mightbe untraceable [2]. Other protocols have been proposed that allow individualsknown only by pseudonyms to transfer securely information about themselvesbetween organizations [2]. All these systems require solutions to the sender untrace- 72D. Chaumability problem, such as the solution presented here, if they are to protect theunlinkability of pseudonyms used to conduct transactions from home.2.5. DisruptionAnother question is how to stop participants who, accidentally or even intentionally, disrupt the system by preventing others from sending messages. In a sense,this problem has no solution, since any participant can send messages continuously,thereby clogging the channel. But nondisupters can ultimately stop disruption in asystem meeting the following requirements: (1) the key-sharing graph is publiclyagreed on; (2) each participant's outputs are publicly agreed on in such a way thatparticipants cannot change their output for a round on the basis of other participants' outputs for that round; and (3) some rounds contain inversions that wouldnot compromise the untraceability of any nondisrupter.The first requirement has already been mentioned in Section 1.1, where it wassaid that this information need not be secret; now it is required that this informationactually be made known to all participants and that the participants agree on it.The second requirement is in part that disrupters be unable (at least with somesignificant probability) to change their output after hearing other participants'outputs. Some actual channels would automatically ensure this, such as broadcastsystems in which all broadcasts are made simultaneously on different frequencies.The remainder of the second requirement, that the outputs be publicly agreed on,might also be met by broadcasting. Having only channels that do not provide itautomatically, an effective way to meet the full second requirement would be forparticipants to "commit" to their outputs before making them. One way to do thisis for participants to make public and agree on some (possibly compressing andhierarchical, see Section 2.6) one-way function of their outputs, before the outputsare made public.The third requirement is that at least some rounds can be contested (i.e., that allinversions can be made public) without compromising the untraceability of nondisrupting senders. The feasibility of this will be demonstrated here by a simpleexample protocol based on the slot reservation technique already described inSection 2.2.Suppose that each participant is always to make a single reservation in eachreserving block, whether or not he actually intends to send a message. (Notice that,because of the "birthday paradox," the number of bits per reserving block must bequadratic in the number of participants.) A disrupted reserving block would thenwith very high probability have Hamming weight unequal to the number of participants. All bits of such a disrupted reserving block could be contested without lossof untraceability for nondisrupters.The reserved blocks can also be made to have such safely contestable bits ifparticipants send trap messages. To lay a trap, a participant first chooses the indexof a bit in some reserving block, a random message, and a secret key. Then thetrapper makes public an encryption, using the secret key, of both the bit index andthe random message. Later, the trapper reserves by inverting in the round corresponding to the bit index, and sends the random message in the resulting reserved The Dining CryptographersProblem73slot. If a disrupter is unlucky enough to have damaged a trap message, then releaseof the secret key by the trapper would cause at least one bit of the reserved slot tobe contested.With the three requirements satisfied, it remains to be shown how if enoughdisrupted rounds are contested, the disrupters will be excluded from the network.Consider first the case of a single participant's mail computer disrupting thenetwork. If it tells the truth about contested key bits it shares (or lies about an evennumber of bits), the disrupter implicates itself, because its contribution to the sumis unequal to the sum of these bits (apart from any allowed inversion). If, on theother hand, the single disrupter lies about some odd number of shared bits, thevalues it claims will differ from those claimed for the same shared bits by the otherparticipants sharing them. The disrupter thereby casts suspicion on all participants,including itself, that share the disputed bits. (It may be difficult for a disrupter tocast substantial suspicion on a large set of participants, since all the disputed bitswill be in common with the disrupter.) Notice, however, that participants who havebeen falsely accused will know that they have been--and by w h o m - - a n d shouldat least refuse to share bits with the disrupter in the future.Even with colluding multiple disrupters, at least one inversion must be revealedas illegitimate or at least one key bit disputed, since the parity of the outputs doesnot correspond to the number of legitimate inversions. The result of such a contestedround will be the removal of at least one edge or at least one vertex from the agreedgraph. Thus, if every disruptive action has a nonzero probability of being contested,only a bounded amount of disruption is possible before the disrupters share no keyswith anyone in the network, or before they are revealed, and are in either caseexcluded from the network.The extension presented next can demonstrate the true value of disputed bits,and hence allows direct incrimination of disrupters.2.6. Tracin9 by ConsentAntisocial use of a network can be deterred if the cooperation of most participantsmakes it possible, albeit expensive, to trace any message. If, for example, a threatening message is sent, a court might order all participants to reveal their shared keybits for a round of the message. The sender of the offending message might try tospread the blame, however, by lying about some odd number of shared bits. Digitalsignatures can be used to stop such blame-spreading altogether. In principle, eachparty sharing a key could insist on a signature, made by the other party sharing,for the value of each shared bit.Such signatures would allow for contested rounds to be fully resolved, foraccused senders to exonerate themselves, and even for colluders to convince eachother that they are pooling true keys. Unfortunately, cooperating participants ableto trace a message to its sender could convince others of the message's origin byrevealing the sender's own signatures. A variation can prevent a participant'ssignatures from being used against him in this way: instead of each member of apair of participants signing the same shared key bit, each signs a separate bit, suchthat the sum of the signed bits is the actual shared key bit. Signatures on such "split" 74D. Chaumkey bits would still be useful in resolving contested rounds, since if one contester ofa bit shows a signature made by the second contester, then the second would haveto reveal the corresponding signature made by the first or be thought to be adisrupter.In many applications it may be impractical to obtain a separate signature onevery key bit or split key bit. The overhead involved could be greatly reduced,however, by digitally signing cryptographic compressions of large numbers of keybits. This might of course require that a whole block of key bits be exposed inshowing a signature, but such blocks could be padded with cryptographicallygenerated pseudorandom (or truly random) bits, to allow the exposure of fewer bitsper signature. The number of bits and amount of time required to verify a signaturefor a single bit can be reduced further by using a rooted tree in which each node isthe one-way compression function of all its direct descendants; only a digitalsignature of each participant's root need be agreed on before use of the keyscomprising the leaves.3. Relation to Previous WorkThere is another multiparty-secure sender-untraceability protocol in the literature[1]. To facilitate comparison, it will be called a mix-net here, while the protocol ofthe present work is called a dc-net. The mix-net approach relies on the security ofa true public-key system (and possibly also of a conventional cryptosystem), and isthus at best computationally secure; the dc-net approach can use unconditionalsecrecy channels to provide an unconditionally secure untraceable-sender system,or can use public-key distribution to provide a computationally secure system (asdescribed in Section 2.1).Under some trust assumptions and channel limitations, however, mix-nets canoperate where dc-nets cannot. Suppose that a subset of participants is trusted byevery other participant not to collude and that the bandwidth of at least someparticipants' channels to the trusted subset is incapable of handling the totalmessage traffic. Then mix-nets may operate quite satisfactorily, but dc-nets will beunable to protect fully each participant's untraceability. Mix-nets can also providerecipient untraceability in this communication environment, even though there isinsufficient bandwidth for use of the broadcast approach (mentioned in Section 2.4).If optimal protection against collusion is to be provided and the crypto-securityof mix-nets is acceptable, a choice between mix-nets and dc-nets may depend onthe nature of the traffic. With a mail-like system that requires only periodic deliveries, and where the average number of messages per interval is relatively large,mix-nets may be suitable. When messages must be delivered continually and thereis no time for batching large numbers of them, dc-nets appear preferable.4. ConclusionThis solution to the dining cryptographers problem demonstrates that unconditional secrecy channels can be used to construct an unconditional sender-untraceability channel. It also shows that a public-key distribution system can be used to The Dining Cryptographers Problem75construct a computationally secure sender-untraceability channel. The approachappears able to satisfy a wide range of practical concerns.AcknowledgmentsI am pleased to thank Jurjen Bos, Gilles Brassard, Jan-Hendrik Evertse, and theuntraceable referees for all their help in revising this article. It is also a pleasure tothank, as in the original version that was distributed at Crypto 84, Whitfield Dime,Ron Rivest, and Gus Simmons for some stimulating dinner-table conversations.ReferencesI-1] Chaum, D., Untraceable Electronic Mail, Return Addresses, and Digital Pseudonyms, Communications of the ACM, vol. 24, no. 2, February 1981, pp. 84-88.I-2] Chaum, D., Security Without Identification: Transaction Systems to Make Big Brother Obsolete,Communications of the ACM, vol. 28, no. 10, October 1985, pp. 1030-1044.1-3] Diffie, W., and Hellman, M. E., New Directions in Cryptography, IEEE Transactions on InformationTheory, vol. 22, no. 6, November 1976, pp. 644-654.1-4] Merkle, R. C., Secure Communication over Insecure Channels, Communications of the ACM, vol.21, no. 4, 1978, pp. 294-299.1-5] Tanenbaum, A. S., Computer Networks, Prentice Hall, Englewood Cliffs, New Jersey, 1981.
Technical NoteProgramming Techniquesand Data StructuresR. RivestEditorUntraceable Electronic Mail,Return Addresses, andDigital PseudonymsDavid L. ChaumUniversity of California, BerkeleyA technique based on public key cryptography ispresented that allows an electronic mail system to hidewho a participant communicates with as well as thecontent of the communication--in spite of an unsecuredunderlying telecommunication system. The techniquedoes not require a universally trusted authority. Onecorrespondent can remain anonymous to a second, whileallowing the second to respond via an untraceble returnaddress.The technique can also be used to form rosters ofuntraceable digital pseudonyms from selected applications. Applicants retain the exclusive ability to formdigital signatures corresponding to their pseudonyms.Elections in which any interested party can verify thatthe ballots have been properly counted are possible ifanonymously mailed ballots are signed with pseudonymsfrom a roster of registered voters. Another use allows anindividual to correspond with a record-keeping organization under a unique pseudonym which appears in aroster of acceptable clients.Key Words and Phrases: electronic mail, public keycryptosystems, digital signatures, traffic analysis, security, privacyCR Categories: 2.12, 3.81IntroductionCryptology is the science of secret communication.Cryptographic techniques have been providing secrecyPermission to copy without fee all or part of this material isgranted provided that the copies are not made or distributed for directcommercial advantage, the ACM copyright notice and the title of thepublication and its date appear, and notice is given that copying is bypermission of the Association for Computing Machinery. To copyotherwise, or to republish, requires a fee and/or specific permission.This work was partially supported by the National Science Foundation under Grant MCS 75-23739 and by the Air Force Office ofScientific Research under Contract F49620-79-CO 173.Author's present address: Computer Science Division, ElectricalEngineering and Computer Sciences Department, University of California, Berkeley, California 94720. (415) 642-1024.© 1981 ACM 0001-0782/81/0200--0084 $00.75.84of message content for thousands of years [3]. Recently,some new solutions to the "key distribution problem"(the problem of providing each communicant with asecret key) have been suggested [2, 4], under the name ofpublic key cryptography. Another cryptographic problem, "the traffic analysis problem" (the problem of keeping confidential who converses with whom, and whenthey converse), will become increasingly important withthe growth of electronic mail. This paper presents asolution to the traffic analysis problem that is based onpublic key cryptography. Baran has solved the trafficanalysis problem for networks [1], but requires eachparticipant to trust a common authority. In contrast,systems based on the solution advanced here can becompromised only by subversion or conspiracy of all ofa set of authorities. Ideally, each participant is an authority.The following two sections introduce the notationand assumptions. Then the basic concepts are introducedfor some special cases involving a series of one or moreauthorities. The final section covers general purpose mailnetworks.NotationSomeone becomes a user of a public key cryptosystem(like that of Rivest, Shamir, and Adleman [5]) by creatinga pair of keys K and K -1 from a suitable randomlygenerated seed. The public key K is made known to theother users or anyone else who cares to know it; theprivate key K -~ is never divulged. The encryption of Xwith key K will be denoted K(X), and is just the imageof X under the mapping implemented by the cryptographic algorithm using key K. The increased utility ofthese algorithms over conventional algorithms resultsbecause the two keys are inverses of each other, in thesense thatK - I ( K ( X ) ) = K ( K - ~ ( X ) ) = X.A message X is sealed with a public key K so that onlythe holder of the private key K-1 can discover its content.If X is simply encrypted with K, then anyone could verifya guess that Y = X by checking whether K(Y) = K ( X ) .This threat can be eliminated by attaching a large stringof random bits R to X before encrypting. The sealing ofX with K is then denoted K(R, X). A user signs somematerial X by prepending a large constant C (all zeros,for example) and then encrypting with its private key,denoted K-~(C, X) -- Y. Anyone can verify that Y hasbeen signed by the holder of K -a and determine thesigned matter X, by forming K(Y) = C, X, and checkingfor C.AssumptionsThe approach taken here is based on two importantassumptions:Communicationsofthe ACMFebruary 1981Volume 24Number 2 (1)(2)No one can determine anything about the correspondences between a set of sealed items and thecorresponding set of unsealed items, or create forgeries without the appropriate random string orprivate key.Anyone may learn the origin, destination(s), andrepresentation of all messages in the underlyingtelecommunication system and anyone may inject,remove, or modify messages.Mail SystemThe users of the cryptosystem will include not onlythe correspondents but a computer called a mix that willprocess each item of mail before it is delivered. A participant prepares a message M for delivery to a participantat address A by sealing it with the addressee's pubfic keyKa, appending the address A, and then sealing the resultwith the mix's public key K1. The left-hand side of thefollowing expression denotes this item which is input tothe mix:stantial evidence that the mix failed to output an itemproperly. Only a wronged participant can supply thereceipt Y (=Ka-~(C, K~(Ri, Ka(Ro, M), A ))), the missingoutput X (=Ka(R0, M), A), and the retained string R1,such that K~(Y) = C, KI(R1, S). Because a mix will signeach output batch as a whole, the absence of an item Xfrom a batch can be substantiated by a copy of the signedbatch.The use of a cascade, or series of mixes, offers theadvantage that any single constituent mix is able toprovide the secrecy of the correspondence between theinputs and the outputs of the entire cascade. Incrimination of a particular mix of a cascade that failed toproperly process an item is accomplished as with a singlemix, but only requires a receipt from the first mix of thecascade, since a mix can use the signed output of itspredecessor to show the absence of an item from its owninput. An item is prepared for a cascade of n mixes thesame as for a single mix. It is then successively sealed foreach succeeding mix:Kn( Rn, Kn-i( Rn-1 . . . . .K2(R2, KI(R1, Ka(Ro, M), A)) . . . )) ..-~.Ki(R1, K~(Ro, M), .4) ~ Ka(Ro, M), A.The ~ denotes the transformation of the input by themix into the output shown on the right-hand side. Themix decrypts its input with its private key, throws awaythe random string R1, and outputs the remainder. Onemight imagine a mechanism that forwards the sealedmessages Ka(Ro, M) of the output to the addressees whothen decrypt them with their own private keys.The purpose of a mix is to hide the correspondencesbetween the items in its input and those in its output.The order of arrival is hidden by outputting the uniformly sized items in lexicographically ordered batches.By assumption (1) above, there need be no concern abouta cryptoanalytic attack yielding the correspondence between the sealed items of a mix's input and its unsealedo u t p u t - - i f items are not repeated. However, if just oneitem is repeated in the input and is allowed to be repeatedin the output, then the correspondence is revealed forthat item.Thus, an important function of a mix is to ensurethat no item is processed more than once. This functioncan be readily achieved by a mix for a particular batchby removing redundant copies before outputting thebatch. If a single mix is used for multiple batches, thenone way that repeats aross batches can be detected is forthe mix to maintain a record of items used in previousbatches. (Records can be discarded once a mix changesits public key by, for example, announcing the new keyin a statement signed with its old private key.) A mixneed not retain previous batches if part of each randomstring Ra contains something--such as a time-stamp-that is only valid for a particular batch.If a participant gets signed receipts for messages itsubmits to a mix, then the participant can provide sub85The first mix yields a lexicographically ordered batch ofitems, each of the formgn-l( Rn-1 . . . . . K2(R2, Ki(Ra, ga( Ro, M), A )) . . . ) ").The items in the final output batch of a cascade are ofthe form K,,(Ro, M), A, the same as those of a single mix.Return AddressesThe techniques just described allow participant x tosend anonymous messages to participant y. What isneeded now is a way for y to respond to x while stillkeeping the identity of x secret from y. A solution is forx to form an untraceable return address Ki(R1, Ax), Kx,where A x is its own real address, Kx is a public keychosen for the occasion, and R1 is a key that will also actas a random string for purposes of sealing. Then, x cansend this return address to y as part of a message sent bythe techniques already described. (In general, two participants can exchange return addresses through a chain ofother participants, where at least one member of eachadjacent pair knows the identity of the other member ofthe pair.) The following indicates how y uses this untraceable return address to form a response to x, via a newkind of mix:Ki(Ri, Ax), Kx(e0, M) -.~ A,,, R~( K,,( Ro, M)).This mix uses the string of bits R1 that it finds afterdecrypting the address part Ki(R1, Ax) as a key to re-encrypt the message part Kx(Ro, M). Only the addressee xcan decrypt the resulting output because x created bothCommunicationsofthe ACMFebruary t981Volume 24Number 2 R~ and Kx. The mix must not allow address parts to berepeated--for the same reason that items of regular mailmust not be repeated. This means that x must supply ywith a return address for each item of mail x wishes toreceive. Also notice that conventional as opposed topublic key cryptography could be used for both encryptions of M.With a cascade of mixes, the message part is preparedthe same as for a single mix, and the address part is asshown in the following input:Ki(R1, K2(R2. . . . . Kn-1, (Rn-1, Kn(Rn, Ax))...)),Kx(Ro, M) .--.)..The result of the first mix isK2(R2,..., Kn-l( Rn-1, Kn( Rn, Ax))-..),RffKI( Ro, M)) .-.-),and the final result of the remaining n - 1 mixes isA~, Rn(R,_~ ... R2(Ra(K,,(Ro, M))) ...).Untraceable return addresses allow the possibility ofcertified mail: They can provide the sender of an anonymous letter with a receipt attesting to the fact that theletter appeared intact in the final output batch. Theaddress A that is incorporated in a certified letter isexpanded to include not only the usual address of therecipient, but also an untraceable return address for thesender. When this return address appears in the outputbatch of the final mix, it is used to mail the sender asigned receipt which includes the message as well as theaddress to which it was delivered. The receipt might besigned by each mix.Digital PseudonymsA digital pseudonym is a public key used to verifysignatures made by the anonymous holder of the corresponding private key. A roster, or list of pseudonyms, iscreated by an authority that decides which applicationsfor pseudonyms to accept, but is unable to trace thepseudonyms in the completed roster. The applicationsmay be sent to the authority anonymously, by untraceable mail, for example, or they may be provided in someother way.Each application received by the authority containsall the information required for the acceptance decisionand a special unaddressed digital letter (whose messageis the public key K, the applicant's proposed pseudonym). In the case of a single mix, these letters are of theform Ki(Rx, K). For a cascade of n mixes, they are of theform Kn(R . . . . . . K2(R2, Ki(R~, K)) ...). The authoritywill form an input batch containing only those unad-86dressed letters from the applications it accepts. This inputbatch will be supplied to a special cascade whose finaloutput batch will be publically available. Since eachentry in the final output batch of the cascade is a publickey K from an accepted applicant, the signed output ofthe final mix is a roster of digital pseudonyms.Notification of applicants can be accomplished byalso forming a roster for unaccepted applications andthen using the technique of certified mail to return asingle batch of receipts to both sets of applicants. Ofcourse, repeats must not be allowed within or acrossbatches.If only registered voters are accepted for a particularroster, then it can be used to carry out an election. Fora single mix, each voter submits a ballot of the formKI(RI, K, K-i(C, V)), where K is the voter's pseudonymand V is the actual vote. For a cascade of mixes, ballotsare of the form K,(Rn . . . . . K2(R2, Ki(Ri, K, K -1(C, V))) . . . ) . The ballots must be processed as a singlebatch, as were the letters used to form rosters. Items inthe final lexicographicaUy ordered output batch are ofthe form K, K-I(C, V). Since the roster of registered voters is also ordered on K, it is easy for anyone tocount the votes by making a single pass through bothbatches at once. Each ballot is counted only after checking that the pseudonym K which forms its prefix, is alsocontained in the roster and that the pseudonym properlydecrypts the signed vote KAn individual might be known to an organizationonly by a pseudonym that appears in a roster of acceptable clients. Clients can correspond with the organizationvia untraceable mail and the organization can correspond with the clients using untraceable return addresses.If applicants identify themselves in their applications, orif they sign applications with pseudonyms that appear ina roster issued by an authority that requires identification, then the organization is assured that the same clientcannot come to it under different pseudonyms. Underspecial circumstances, such as default of payment, aparticular pseudonym could be shown to correspond toa particular application (without revealing any othercorrespondences) if each mix in turn supplied the appropriate Ri.General Purpose Mail SystemsOne way to construct a general purpose, untraceablemail system is to require that every message pass througha cascade. Of course, mixes can operate continuously orperiodically, and long messages will be encrypted firstand then split into multiple items. In order to hide thenumber of messages sent, each participant supplies thesame number of messages to each batch (some of whichmight be randomly addressed dummies). In order to hidethe number of messages received, each participant privately searches the entire output for messages directedto it.Communicationsofthe ACMFebruary 1981Volume 24Number 2 Such a system may prove too costly for some participants. One way to reduce the cost is to allow mail to beaddressed to subsets of participants, such as a local net.Participants that take advantage of such arrangementsneed search only the mail addressed to a particularsubset. Another way to economize is for a participant tosend for each batch only the number of dummy messagessuggested by a random value (chosen from some suitabledistribution), as opposed to always sending the maximalnumber of messages. This can substantially reduce message traffic and consequently, the size of output batches.While these techniques may open the door to some kindsof statistical attack, the system size that necessitated themmay reduce the effectiveness of such attacks.In a large, general purpose mail system with manymixes, it may be impractical for every message to passthrough every mix. In such a case, a sequence of mixeswill be selected for each message, perhaps on the basisof network topology or trust. Notice that if a participantcan choose mixes it trusts with its traffic volume data asearly members of its sequences, then these mixes candiscard dummies they receive from the participant andderiver small, fixed-sized batches (padded with dummies)directly to the participant.A new kind of mix will be presented here that allowsa sequence of mixes to be selected for each message. Italso (a) hides the number and identity of the mixes amessage must pass through, (b) allows incrimination ofa mix that does not properly forward items, and (c)makes no distinction between regular mail and mail sentby untraceable return address. It is based on the ideathat every item of mail is composed of the same numberof fixed-sized blocks.The operations performed by this new kind o f mixare always the same. First it removes the first block andadds a random block J of junk to the end, to maintainthe item's length of l blocks. Then, using its private key,the mix decrypts the block removed during the first step.This yields a key R, which the mix uses to encrypt eachof the l blocks o f the item (using either pubric key orconventional cryptography). It also yields the address A(either of a recipient or of another mix) to which the itemwill be forwarded.The left-hand side of the following shows how anitem is prepared to pass through a single mix:A 1: [KA,(RA,, A 2 ) ] , [RA~(KA2(RA2, A 3 ) ) ] . . . . .[R]~(R~. . . R]~_,(KA.(RA,, A ) ) . . - ) ] ,[R]~(R]~... R]](M1) ...] . . . . .[ R A--1i ( R A--12 ' ' °Raln(ml_tt),)] ,.,,,,,,,,..~...The result leaving A 1 isA2: [ KA2( J~A2, A3)], [ RA~( KA3( RA 3, ..44))] . . . . .[ R ] ~ ( R ] ] . . . RA]_,(KA,(RAn, A )) - - - ) ] ,[Ra~(Ra] ... R]a,(M~) ...)] . . . . .[ R]~( R]~ ... Rib(Mr-n) ...)], [ RA,( JA~)] -'~,and the final result leaving An isA: [M1], [M2] . . . . .[MI-n],[RA.(RA._, ' ' ' RAi(JA,) "" ")] . . . ., [RA,,(JA.)].An intermediate mix always knows which mix it receivedits input f r o m - - b y assumption (2)--but if a mix broadcasts copies of its fixed:sized output batches, then onlyindividual recipient mixes need be able to recognize theirown input in a broadcast batch.The untraceable return address x sends to y containsthe key K,~ that y uses to encrypt the message part. Italso includes, in the case of a single mix, what y will useas the first block of the item it submits to the mix:Ai: [KA,(RA,, Ax)], [Ma] . . . . , [Ml-1]Ax: [RAi(M1)] . . . . . [RA,(Mi-1)], [RA,(JA,)],where K,,(Ro, M) = M1, M2 . . . . . Ml-n. Only x candecrypt the item it receives since it created RA t and Kx.When a message is to pass through n mixes, the untraceable return address contains the first n blocks:Ai: [KA,(RA,, A2)], [R~(KA2(RAs, Aa))] . . . . .[R]~(R]~ . . . R]]_,(KA.(RA,, A~)) ...)],[M1], [M2], • • . , [Ml-n] "-}.After being operated on by mix A 1 it will have the formA2: [KA~(RA~, A3)] . . . . .[ R A ~ ( R A ] • ' ' RA~lm(KA.(RA., A x ) ) . . . ) ] ,[RAi(M2)] . . . .[RA,(M1)],, [ R A , ( g t - n ) ] , [RAi(JA,) ] -->,and the final result leaving An isA~: [KA,(RA,, A)], [R~:(M~)], [R]:(M2)] . . . . .[R]~(Mi-1)] ~ A: [M1] . . . . . [Ml-1], [RAi(JAi)],where square brackets show the extent of each block,and the sealed message Ka(Ro, M) is divided into piecesMi, such that Ka(Ro, M) = M1, M2. . . . . ml-n. The Ai:indicates that the left-hand side is delivered to mix A,,while the A: means that the right-hand side is deliveredto address A. Items with the same first block should beregarded as repeats.A message prepared to be passed through mixes A1through An has the form871hx: [RA.(RA._, ' ' ' RA,(M~) . . - ) ] . . . . .[RA°(RA°_,.-" RAAMz-.)"" ")],[RA.(RA._, . ' ' RA,(JA1) "" " ) ] . . . . . [RA.(JA.)].Summary and ConclusionA solution to the traffic analysis problem has beenpresented that allows any single intermediary to providesecurity for those messages passing through it. In addiCommunicationsofthe ACMFebruary 1981Volume 24Number 2 tion, the solution allows messages to be sent or receivedanonymously. Through the notion of a roster of pseudonyms, it also provides some new and interesting kindsof limited anonymity.Acknowledgments. I owe a great deal to R. Fabry'soutstanding and multifaceted support. Special thanks aredue C. S6quin, who has read my work with great careand provided many stimulating discussions. I would alsolike to thank D. Gusfield, B. Mont-Reynaud, A. Moose,and S. Wecker for their comments and encouragement.The referees have been very helpful.Technical NoteOperations andManagementH. MorganEditorOn Uniformly Inserting OneData Structure into AnotherArnold L. RosenbergIBM Thomas J. Watson Research CenterReceived 2/79; accepted 4/80; revised 10/80References1. Baran,P. On distributed communications:IX securitysecrecyand tamper-freeconsiderations. Memo RM-3765-PR, Rand Corp.,Santa Monica, CA, Aug. 1964.2. Diffie,W.and Hellman, M.E. New directions in cryptography.IEEE Trans. Information Theory 1T-22, 6 (Nov. 1976),644-654.3. Kahn,D. The Code Breakers, The Story of Secret Writing.Macmillan, New York, 1967.4. Merkle, R.C. Securecommunicationsover insecure channels.Comm. ACM 21, 4 (Apt. 1978),294-299.5. Rivest, R.L., Shamir, A., and Adleman, L. A method forobtaining digital signatures and public-keycryptosystems.Comm.ACM 21, 2 (Feb. 1977), 120-126.Two recent papers (131 and l i d def'me the operationof uniform insertion of one data structure in another, asa step toward a structured methodology for definingdata structures. This note repairs a flaw in thedefinition of this operation that occurs in both of thecited papers.Key Words and Phrases: data structures, uniforminsertion, uniform substitutionCR Category: 4.34Shneiderman and Scheuermann [3] have defined anoperation uniform insertion on a pair of data structureswhereby an instance of one of the structures is appendedfrom each data node of the other. Hollander [I] hasnoted a potential inconsistency in the ShneidermanScheuermann definition of uniform insertion and hasproposed an addendum to the definition which precludesthe inconsistency. However, all three authors seem tohave missed a fundamental flaw in the original definitionof uniform insertion, a flaw which persists in Hollander'smodified definition. Before exposing and repairing theflawed definition, the notion of a structured data structurefrom [1, 3] is paraphrased.Definition 1.A structured data structure (sds, forshort) is a systemZ = (e, D, L, F)which specifies a connected edge-labelled directed graphin the following way:(a) {e} O D is the set of nodes of the graph;(b) L is the set of edge labels of the graph;(c) F : ((e} U D) X L ~ D is the (not necessarily total)edge-specification function. Note in particular thatthe entry node e has indegree 0.Corrigendum. Technical Note, Graphics and Image ProcessingM.L.V. Pitteway and D.J. Watkinson, "Bresenham's Algorithm with Grey Scale," Comm. A C M 23, 11 (Nov.1980), 625-626.The figure on p. 626 has been printed erroneously. Thecorrect figure should have the black portions on top andbe reversed as per the description in the figure caption.88Permission to copy without fee all or part of this material isgranted provided that the copies are not made or distributed for directcommercial advantage, the ACM copyright notice and the title of thepublication and its date appear, and notice is given that copying is bypermission of the Association for Computing Machinery. To copyotherwise, or to republish, requires a fee and/or specific permission.Author's present address: Arnold L. Rosenberg, MathematicalSciences Department, IBM Thomas J. Watson Research Center, Yorktown Heights, New York 10598.ACM wishes to extend an apology to the author for the extraordinarily long delay in the publication of this note, which was due tono fault of his own.© 1981 ACM 0001-0782/81/0200-0088 $00.75.Communicationsofthe ACMFebruary 1981Volume 24Number 2
ARTICLESSECURITY WITHOUT IDENTIFICATION:TRANSACTION SYSTEMS TO MAKEBIG BROTHER OBSOLETEThe large-scale automated transaction systems of the near future can bedesigned to protect the privacy and maintain the security of both individualsand organizations.DAVID CHAUMComputerizationis robbing individualsof the abilityto monitor and control the ways informationaboutthem is used. As organizations in both the private andthe public sectors routinely exchange such information, individ.uals have no way of knowing if theinformationis inaccurate, obsolete, or otherwise inappropriate. The foundation is being laid for a dossiersociety, in which computers could be used to inferindividuals’life-styles, habits, whereabouts, and associations from data collected in ordinary consumertransactions. Uncertaintyabout whether data will remain secure against abuse by those maintainingortapping it can have a “chilling effect,” causing peopleto alter their observable activities. As computerizationbecomes mclre pervasive, the potential for these problems will grow dramatically.On the other hand, organizationsare vulnerable toabuses by individuals.Everyone pays inldirectly whencash, checks, consumer credit, insurance, and socialservices are misused. The obvious solution for organizations is to devise more pervasive, efficient, andinterlinkedcomputerizedrecord-keepingsystems,perhaps in combinationwith national identity cardsor even fingerprints.However, this would exacerbatethe problem of individuals’loss of monitoribilityandcontrol, and would likely be unacceptable to many.The new approach presented here offers an effective and practical solution to these problems.The New Approach and How It DiffersThree major differences define the new approach. Firstis the way identifying information is used. Currently,many Weste.rn countries require citizens to carry documents bearing universal identificationnumbers. Driver’s licenses are being upgraded to perform a similarfunction in the United States, and internationalefforts01985 ACM 000;.0782/85/1000-1030Communications of the ACM75cfor machine-readablenational identity documents aregaining momentum. But organizations already use suchessentially identifying data as name, date, and place ofbirth or name and address to match or link their records on individuals with those maintained by other or.ganizations.With the new approach, an individual uses a different account number or “digital pseudonym” with eachorganization. Individuals will create all such pseudonyms by a special random process. Information furtheridentifying the individual is not used. A purchase at ashop, for example, might be made under a one-time-usepseudonym; for a series of transactions comprising anongoing relationship, such as a bank account, a singlepseudonym could be used repeatedly. Although thepseudonyms cannot be linked, organizations will beable to ensure that the pseudonyms are not used improperly by such measures as limiting individuals toone pseudonym per organization and ensuring that individuals are held accountable for abuses created underany of their pseudonyms. Individuals will be able toauthenticate ownership of their pseudonyms and usethem while ensuring that they are not improperly usedby others.A second difference is in who provides the mechanisms used to conduct transactions. Today, individualshold a variety of “tokens” issued them by organizations,such as paper documents and plastic cards with magnetic or optical stripes or even embedded microcomputers. These tokens are usually owned by the issuingorganization and contain information inscrutable to andunmodifiable by the individual holding them. Increasingly, individuals are being asked to perform transactions directly using computer-controlledequipment,such as automatic teller and point-of-sale terminals.Such equipment and chip cards are tamper resistantand contain secret numeric keys to allow secure communication with central computer facilities. Individua1.sOctober 1985Volume 28Number 70 Articlesderive little direct benefit from these security provisions, however, since they must reveal their own secrets to the organization-providedmechanism and takethe information provided to them by that mechanismon faith.Individuals conduct transactions under the new approach using personal card computers that might take aform similar to a credit-card-sizedcalculator, and include a character display, keyboard, and a limited distance communicationcapability (like that of a television remote control). Such card computers could bepurchased or constructed just like any other personalcomputer, and would have no secrets from or structures unmodifiable by their owners. They would be assimple to use as automatic teller machines. During apurchase at a shop, for example, a description of thegoods and cost would be communicated to the cardcomputer, which would display this information to thecard owner, who would allow each transaction by entering a secret authorizing number on the card computer’s keyboard. The same authorizing number originally programmed into the card computer by its owneris used to allow all transactions. Without this number, alost or stolen card computer would be of very little use.However, the full capabilities of a lost card computercould be readily installed in a replacement card computer using backup data saved at home or elsewhere.The saved data would be in a safely encoded form thatcould only be decoded by a replacement card computeronce the owner or some trustees supplied other sufficient secret numbers. These card computers are already technically feasible.The nature of the security provided under the newapproach also differs substantially: Current systems emphasize the one-sided security of organizations attempting to protect themselves from individuals; the newapproach allows all parties to protect their own interests. The new approach relies on individuals keepingsecret keys from organizations and organizations devising other secret keys that are kept from individuals.During transactions, parties use these keys to provideeach other with specially coded confirmation of thetransaction details, which can be used as evidence ofimproper actions sufficient to resolve disputes.The systems presented in the new approach rely oncurrently used coding techniques to provide organizations with security against abuses by individuals. Consequently, if the underlying codes could be broken, individuals could breach the security of the systems.These codes are “cryptographic”and can be broken, inprinciple, by trying enough guessed keys, though suchguessing is infeasible because of the enormous numberof possible keys. No feasible attack or any proofs ofsecurity are known for these codes. In contrast, thesecurity provided for individuals against organizationsbeing able to link the pseudonyms in the systems presented here is “unconditional”:Simple mathematicalproofs show that, with appropriate use of the systems,even conspiracy of all organizations and tapping of allcommunicationlines cannot yield enough informationto link the pseudonyms-regardlessof how clever theOctober 1985Volume 28Number 10approach is or how much computation is expended.The feasibility of the new approach can be demonstrated for a comprehensive set of three kinds of consumer transactions: communication,payment, andcredential. Each of these kinds of transactions raises itsown special problems.COMMUNICATIONTRANSACTIONSAs more communicationtravels in electromagneticanddigital form, it becomes easier to learn more about individuals from their communication.Exposure of message content is one obvious danger that is already addressed by well-known cryptographic coding techniques. A more subtle and difficult problem with current communicationsystems, however, is the exposureof “tracing information.”Individuals’ addresses, whichare often required by organizations and are commonlysold freely by them as mailing lists, are one kind oftracing information. The trend is toward greater use ofsuch information. Comprehensive and computerizedinformation on who telephones whom and when, forinstance, is increasingly being collected and maintainedby phone companies. Emerging electronic mail systems,other computer networks, and even some new phonesystems automaticallydeliver tracing information witheach message. When this information is available on amass basis, associations, their structure, and even theirrelation to events are laid bare. Furthermore, tracinginformation can be used to link together all the recordsrelated to an individual that are held by organizationswith whom the individual communicates. So long ascommunicationsystems allow system providers, organizations, or eavesdroppers to obtain tracing information,they are a growing threat to individuals’ ability to determine how information about themselves is used.They are also unsuitable for the new approach.The other side of the issue is that current systemsprovide inadequate protection against individuals whoforge messages, or falsely disavow having sent or received messages. With paper communication,handwritten signatures are easily forged well enough to passroutine checking against signature samples and cannotbe verified with certainty, even by expert witnesses.Also, paper receipts for delivery are too costly for mosttransactions, are often based only on handwritten signatures, and usually do not indicate message content.Emerging electronic mail and similar systems addressthese problems under the current approach in severalobvious ways: by attempting to guarantee recipients thecorrect address from which each message is sent: byinstalling tamper-resistantidentity card readers or thelike at public points of entry to the communicationsystem; and by keeping records of messages delivered,to provide certification of delivery. As computerizedsystems come into wider use, potential for such abuseby individuals will increase, but such solutions underthe current approach rely on tracing information andthus are in fundamental conflict with individuals’ ability to control access to information about themselves.The nature of the solution is such that messages areuntraceable, except for the recipient’s ability to authen-Communications of the ACM1031 Articlesagreed that each of them will say aloud which side thecoin falls on, but that if one of them paid that oneshould say the opposite side. The uninteresting case iswhen they both say heads or both say tails: Theneveryone knows you paid. If one of them says headsand the other says tails, however, then you know thatone of the two of them paid-butyou have absolutelyno information as to which one. You do know that theone you heard say tails paid if the coin was heads, ant1that the other one paid if the coin was tails. But sinceeach outcome of the coin toss is equally likely, youlearn nothing from their utterances about which of thetwo of them has paid.The system described allows the friend who paid tosend you an unconditionallyuntraceable message; eventhough you know who says what, you cannot trace the“I paid” message, no matter how clever or time consuming your analysis.Converting this two-sender single-recipientsystem toa more general system requires several extensions (presented and fully detailed in [2]). Increasing the numberticate them as having been sent by the owner of aparticular pseudonym. The concepts of untraceabilityand pseudonymous authentication,presented separately in the following, are intertwined in the paymentand credential transaction systems to be presented.UnconditionalUntraceabilityThe problem of preventing messages from being tracedto the sender is now considered. The essential conceptof the solution can be illustrated by a hypothetical situation. Suppose you were invited to dine at a restaurantby two of your friends. After dinner, the waiter comesto your table and mentions that one of the three of youhas already paid for the dinner-buthe does not saywhich one. If you paid, your friends want to knowsince they invited you, but if one of them paid, they donot want you to be able to learn whic:h of the two ofthem has paid.The probl’em is solved at the table in the followingsimple way: Your friends flip a coin behind a menu sothat they ca:n see the outcome, but you cannot. It is\Anotmes 845:&7I*-7‘\I II organizationrtifies 845:-q) organtation1JIUniversally identifying numbers or other equivalent identifyinginformation is presented by the individual cardholder to eachorganization-inthe current approach. Unrelated generic examples are shown of three kinds of transactions: communication, in which the individual sends an authonzing messageand receives a notifying message; payment, in which the1032Conlmunications of the ACMindividual pays an organization or receives a payment; andcredential, in which a certification that an individual has somecredential is transferred from an organization 6 to an organization C. The identifying information-845-allowsall transaction records to be linked and collected together into adossier on the individual.October 1985Volunw 28 Number 10 Articles,’//’451 pays B $-451Bee ----ddxzrtifies314:-&3p C pays 314 $-Different numbers or digital pseudonyms are used with eachorganization by a personal card computer held and trustedonly by the individual-underthe new approach. The credential transfer is no longer just between organizations: It mustnow go through the card where the pseudonym-451used with the issuing organization B is transformed to theof potential senders beyond two can prevent even cooperating subsets of potential senders from tracing transmissions to particular senders. Just as many other people may overhear the statements made at the table;actual systems would, in effect, broadcast each transmission to all participants, preventing anyone fromknowing who receives which message. Because realmessages are digitally coded, further coding (detailedlater) can prevent all but the intended recipient fromdecoding confidential messages.Digital SignaturesNow consider the problem of preventing senders ofmessages from later disavowing their messages. The solution is based on the concept of digital signatures, firstproposed by Diffie and Hellman [5]. To see how thisconcept works, consider an old-fashioned codebook divided into two halves, like an English-FrenchandFrench-Englishdictionary, except that only Englishwords are used. Thus, if you look up an English wordin the front half of the codebook, you find the corre-October 1985Volume 28Number 10pseudonym-314-usedwith the receiving organization C.Systems using this approach can provide organizations withimproved protection against abuses by individuals, and alsoallow individuals to ensure that pseudonyms cannot betraced across the dashed boundary lines, thereby preventingdossier compilation.sponding (but usually semantically unrelated) Englishcode word: if you then look this code word up in theback half, you find your original English word. Codebooks are constructed by pairing off words at random:In the front half of the book, the pairs are orderedby their first words, and in the back half by theirsecond words.If you construct such a codebook, you can use it inyour communicationwith an organization. You keepthe front half as your private key, and you give the backhalf to the organization as your digital pseudonym withthat organization. Before sending a message to the organization, you encode the message by translating eachword into code using your private key; this encodedmessage is called a digital signature. When the organization receives the digital signature from you, it translates it back to the original English message using yourdigital pseudonym.The immensely useful property of digital signaturesis their resistance to “forgery.” No one-noteven theorganization that has your digital pseudonym-caneas-Comnrunications of the ACM1033 ArticlesI will digitally signThe digitally signed form ofmy message is ‘pages cat:>1,.,ina syndrome’ is aralid digital signature, and1034Unconditionally untraceable messages are illustrated by a hypothetical situation (see text). The “I paid” message is unconditionally untraceable, since the guest (right) cannot trace itto a particular host-nomatter how much computation orwhich approach is used.Digitally signed messages are also illustrated by a hypothetical situation (see text). Actual computerized digital signature systems now in use are not unconditionally secure, although the amount of computation required for forgety isthought to be unobtainable in practice.ily forge a dlgital signature of yours. Such forgerywould entail! creating something that dec’odesto a sensible English, message using your digital pseudonym. Inthe codebook analogy, forgery, of course, merely requires searching through or completely inverting thehalf of the bfook that is your digital pseudonym, butwith actual digital-signature cryptographi.c techniquescurrently in use, forgery is thought to require so muchcomputation as to be infeasible even for the fastestcomputers working for millions of years. If an organization cannot forge a digital signature of yours, then itcannot successfully claim that you sent it a messagethat you in fact did not send. A third-party arbiterwould decide in favor of the organization only if thatorganization could show a digital signature that yieldedthe disputed message when translated with your digitalpseudonym. But, because forgery is infeasible, the organization can only show such a message if you createdit. Naturally, organizations would save copies of all digital signatures in anticipation of such disputes.An organization could create its own private key/digital-pseudonym pair, and widely disse:minate thedigital pseud.onym while keeping the corresponding private key to itself. It would use this private key to formdigital signalures on all messagesbefore sending themto individuals. The organization, however, would create only a single pair, which it would use for all digitalsignatures it issues. Anyone getting a message from theorganization would first decode it using t:he organization’s disseminated digital pseudonym. This would allow individuals to convince the organization, or anyoneelse if necessary, that the message had in fact been sentby the organization. In the payment and credential systems introdu.ced in the following two sect.ions, suchdigital signatures, as issued by organizations, play animportant role.Actual digital signatures are realized using numbers,and can be extended to ensure confidentiality of message content and provide certification of delivery.Practical computerized digital-signature techniqueswork like the codebook analogy above, except thateverything is done with numbers. Private keys and digital pseudonyms are represented as two-hundred-digitnumbers, instead of as halves of codebooks; messagesand signatures are also represented as two-hundreddigit numbers, instead of as strings of English words. A.standard public mathematical procedure allows anyonewith a private key to form a corresponding digital signature from a message, and a similar procedure allowsrecovery of the original message using the corresponding digital pseudonym (just as the simple procedure fo:rlooking words up in either half of the codebook can bepublic, so long as the private key is not). Another public mathematical procedure allows anyone to create aprivate-key/digital-pseudonympair from a randomstarting point (just as a simple procedure allowed thetwo halves of a codebook to be generated from a random pairing of words). Rivest, Shamir, and Adleman [e]proposed such a numeric digital-signature technique,which seems to be highly secure against forgery.Message confidentiality during transmission is obtained by using digital pseudonyms and private keys ina different way: After signing a message, but beforetransmitting it, the sender encodes it using the digitalpseudonym of the intended recipient. Thus, the signedmessagecan be recovered only by decoding the transmission using the intended recipient’s private key.Currently, there are two strategies for preventingfalse disavowal of message receipt. Both of these strategies can be adapted for digital signatures. One imitatesthe approach currently used to certify paper mail: Mes-Communications of the ACMDigitalSignaturesin PracticeOctober 1985Volume 28 Number :!O Articlessagesare only given to the recipient if the recipientprovides a digitally signed receipt of delivery. Theother holds all potential recipients responsible for messagesmade available as a matter of public record. Thisallows either party to present the signed message andpoint to the corresponding doubly encoded transmission in the public record as evidence that the messagewas available for receipt, since decoding the signedmessagewith the digital pseudonym of the senderyields the messagecontent, and encoding it with thepseudonym of the recipient yields the transmission inthe public record.PAYMENTTRANSACTIONSAutomation of payment systems is giving the providersof these systems and others easy access to revealing andextensive information about individuals through payments for things like travel, entertainment, purchasesfrom shops, subscriptions, donations, etc. Today, manypaper transaction records of when, how much, and towhom payment was made are translated into electronicform. The trend is toward initial capture of paymentdata in electronic form, such as at the point of sale,facilitating the electronic capture of the potentiallymore revealing details of what was purchased. Computerization is extending the data capture potential of payment systems in other ways, such as by the variety ofemerging informational services proper, like pay television and videotex, and also by new systems that directly connect central billing computers to things likeelectric-utility meters and automobile-identificationsensors buried in toll roads. Just as tracing data in communication systems allows all of an individual’s recordswith organizations to be linked because they all use thesame address, payment data allow linking of recordsthat involve payments with the same account.F------Tspecial-m0 n[l]+8Unconditionally untraceable messages with numbers are sentessentially as with words, except that everything is represented as zeros and ones. Only the exclusive-or operation 8isused(definedas180=081=l andO@O=l@l=0). The 0 or 1 outcome of the coin toss is shown as k. Ahost wishing to send the “I paid” message, which is represented as 1, transmits k 8 1; a host not wishing to send themessage transmits only k. When the guest forms the exclusive-or of the two transmissions, [l] and [2], the result is 1 ifone host sent the message and 0 if no host sent it-becausek appears twkx? and cancels (since k CT9k = 0 and 0 8 m =m). If there are more hosts at the table, each flips a coin andshares the outcome with the host to the left, skipping theguest. Each host then forms a transmission as the exclusiveor of the two outcomes he or she shares, exclusive-oredwith an additional 1 if the “I paid” message is being sent.Every coin toss appears twice and is canceled in theexclusive-or that the guest forms from all the transmissions,and the result is again 1 if a host paid and 0 if no host paid.In actual computerized systems, real messages are encodedas sequences of zeros and ones, and the whole protocol isrepeated with new ks for each digit to be sent. Sendersnoticing that their messages are being garbled by collisionwith other messages wait a randomly chosen interval beforeattempting to resend.October 1985Volume 28Number 10( check([Ix) )mxPIDigital signatures with numbers use special arithmetic systems, in which raising a number to a power scrambles it, andraising it to a corresponding power unscrambles it. (Onepower acts as the private half of the codebook, and the otherpower as the corresponding half, called a digital pseudonym.)First the message is encoded as a one-hundreddigitnumber, and then the digits are repeated to form a two-hundreddigit number with this special repeated halves property. Nextthe signer raises the special number to a private power P andmakes the result known to others in transmission [l]. Someone obtaining this digitally signed message merely raises it tothe corresponding digital pseudonym power x and checksthat the result has the special repeated halves property. If itdoes, then the recipient knows that the message was signedby the holder of the private power.Communications of the ACM1035 ArticlesUntraceable payments are illustrated by an analogy to envelopes and carbon paper. The individual (actually the card inthe computerized analog) seals a blank slip of paper and afacing piece of carbon paper in an envelope, and supplies itto the bank. The bank deducts one dollar from the individual’s account, applies a “worth one dollar” signature (stamp)on the outside of the envelope, and returns the unopenedenvelope to the individual. Upon receiving this, the individualverifies the b.ank’s validating signature. Before making payment some time later. the individual removes the envelopeand carbon, leaving only the signed slip of paper. When theshop receives the slip, it verifies the carbon image of theAbuses of payment systems by individuals, as well asabuses facilitated by payment systems, aria also substantial and growing problems. Uncollectiblepaymentsmade by consumers. such as checks drawn against insufficient funds and credit-card misuse, cost society billions of dollars each year. Paper-currency-basedsystems are vu1 nerable to such things as counterfeitingand theft. Lack of auditabilityalso allows paper currency to be convenientlyused for illicit payments suchas bribes, extortion, and black-market purchases. Protecting against these various kinds of abuse while computerizing under the current approach seems to call forhighly perva:sive and interlinked systems capturing andretaining account identifiers as well as other paymentdata, which is naturally in conflict with the interests ofindividuals.These problems are solved with the new systemssince no organization, not even the payment systemprovider who maintains the accounts, is able to tracethe flow of money between accounts. The system provider naturally knows the balance of each\ account, andvalidating signature on it and supplies it to the bank fordeposit. After also verifying the slip’s validating signature, thebank honors the deposit since it knows the slip must havebeen in an envelope that it signed. The bank does not, however, know which of the many envelopes that it signed contained the note, and thus cannot trace it to the individual’saccount. In actual computerized systems, unless the individual allows tracing, withdrawals on one side of the dashedboundary and payments on the other side are unconditionallyuntraceable to each other-evenif the bank and all otherorganizations cooperate.if funds were to transfer between accounts instantaneously, the simultaneous but opposite changes in balance would make tracing easy. The new system prevents such tracing in practice by allowing funds to bewithdrawn and held as multidenominationnotes, insome ways like “unmarked bills,” before they are deposited to other accounts. The systems differ from paper currency, however, in part because individuals, butnot organizations, can allow transfers to be traced andaudited whenever needed, making stolen funds unusable and these systems unattractive for many kinds ofillicit payments. The fully computerized systems introduced here offer practical yet highly secure replacements for most current and proposed consumer payment systems (as detailed in [a]).Blind Signatures for Untraceable PaymentsThe payment system introduced is based on an extension of digital signatures known as blind signatures. Thisconcept is easily understood by an analogy to carbonpaper-lined envelopes. If you put a piece of paper insideOctober 1985Volume 28Number 113 Articlessuch an envelope and a signature mark is later made onthe outside of the envelope, the carbon paper in theenvelope transfers the signature onto the slip.Consider how you might use such envelopes to makepayments. Suppose a bank had a special signature markthat it guaranteed to be worth one dollar, in the sensethat the bank would pay one dollar for any piece ofpaper with that mark on it. You take a carbon-linedenvelope containing a plain slip of paper to the bankand ask to withdraw one dollar from your account. Thebank then deducts one dollar from your account, makesthe signature mark on the outside of your envelope,and returns it to ydu. The signature is “blind” since thebank cannot see the slip through the envelope. Upongetting the unopened envelope back, you verify thatthe proper signature mark has been made on it. Whenyou remove the slip from the envelope, it bears thecarbon image of the bank’s signature mark. You canthen go out and buy something for one dollar from ashop, using the signed slip to make payment. The shopverifies the carbon image of the bank’s signature on theslip before accepting it as payment.Now consider the position of the bank when a slip isreceived for deposit from a shop. The bank verifies thesignature on the slip submitted for deposit, just as theshop did, and puts a dollar on the shop’s account. Because the signature checked out, the bank knows thatthe slip must have been in an envelope that it signed.But of course the bank uses exactly the same signaturemark to sign many such envelopes each day for all itsaccount holders, and since all slips were hidden in envelopes during signing, the bank cannot know whichenvelope,the slip was in. Therefore it cannot learnwhich account the funds were withdrawn from. Moregenerally, the bank cannot determine which withdrawal corresponds with which deposit-thepaymentsare untraceable.In actual computerized systems, the envelopes andslips of paper are replaced by numbers, the bank’s signature mark by a digital blind signature, and paymentsare unconditionallyuntraceable (as detailed in Leavingthe Analogy, below). The protocol for transacting a,-’check ([4])bIt~dL n.'/( .(.n -..Cw+--[w8 *.:131= f@Untraceable payments with numb&s are made much as inthe paper analogy. First the individual’s card computerchooses half the digits of n by a physical random process,and repeats these digits to form the note number n with thisspecial repeated halves property (which is equivalent tochoosing a suitable slip of paper at random in the analogy).The card also forms a totally random number r (which iserjuivalent to choosing an envelope and carbon). The cardthen raises the random number r to the bank’s “worth onedollar” public power b, multiplies ihis by the note number n(which is equivalent to sealing the slip in the envelope), andsupplies the result to the bank in transmission [l]. The bankdeducts from the account, uses the corresponding privateOctober 1985Volume 28$ieck ([$bNumber 10[4]c[3]2power 6 ;o sign the transmission, and returns the result tothe card in [2]. The card verifies that the bank returnedexactly the right thing, and obtains the signed note by dividing out the random r (which is equivalent to removing theenvelope and carbon). When a payment is made, the shopchecks that transmission [3] is a signed special number, andthen forwards a copy [4] to the bank for deposit. The bankchecks the signature just as the shop did, and accepts thedeposit if the particular note has not already been deposited.If individuals do not divulge the random rs that their cardscreate, the [l]s can be unconditionally untraceable to the[4]s because there is exactly one r that would make any [l]correspond with any [4].Communicationsofthe ACM1037 Articleswithdrawalfrom a bank or making a payment would ofcourse be carried out automaticallyby the card computer; the card computer’s owner would (only have toallow transactions by entering the sec:ret authorizingnumber.Extending the Envelope AnalogyNote number:; can provide much the same kind of protection as check numbers do today. Since the bank isunable to look into the envelopes, nothing is revealedto the bank by a random number written on the slipbefore it is s:gned. (In fact, each slip has a unique random paper fiber pattern that might serve as just such anote number.) Stolen notes should not be accepted bythe bank if t he individual who withdrew the fundsreports the note numbers. Also, the bank can attest tothe account to which funds have been deposited if theindividual payer provides th’e note number. Such traceability by the payer would discourage use of these systems for payment of bribes, extortion, and other illicitpayments: RI3ceivers of such payments risk having theiraccounts traced if they deposit the notes, and beingapprehendecl or just finding that what they have isworthless if i hey try to spend them.A variation on this system prevents organizations(even in cooperation with banks) from tracing the accounts of individuals to whom they pay such things aswages, refunds, settlements, and rebates. The individual places the slip in the envelope as before. Thisblinded slip js then provided to the payer organization(instead of the bank), which then supplies the blindedslip to the bank for signing and withdrawalfrom itsown account. The signed but still blinded slip is thenreturned by the organization to the individual, whoverifies the signature, removes the envelope, and laterprovides the contained slip to the bank for deposit.Other extensions to the basic concept, not consideredhere, can offer replacements for today’s payment systems attractive to both financial institutions and consumers. Different signatures would be used for differentdenominations. Clearing centers could handle most ofthe work and responsibility,while allowing banks tooffer their own customized services with reduced investment and risk. Further variations allow the payment system to be used just as credit and debit cardsare used today, with interest charges for u.se of creditand interest earnings on unspent funds. Generic receipts indicating only the denominations and type ofexpense could be used for tax reporting and the like.(When using credential systems presented in the nextsection, such receipts obtained under pseudonyms ofone individual cannot be shown on pseudonyms ofother individuals.)Leaving the AnalogyActual payment systems would work very much alongthe lines of the paper analogy, except that they woulduse numbers (as detailed more fully in the figure onpage 1037). A note number is first created by a physicalrandom process within the individual’scard computer(like the note number chosen at random and written on1038Communications of the ACMthe slip of paper by the payer). Next, the card computertransforms this note number into the numeric equivalent of the message “this is note number: 416 . . . .” Thecard computer then “blinds” this numeric note by combining it with a second random number (correspondingto the payer choosing an envelope at random and placing the slip in it). During withdrawal,the bank uses theprivate key of the desired denomination to form a digital signature on the numeric note (like the signaturemark formed on envelopes by the bank). When thesigned blinded note is ultimately returned, the cardcomputer is able to unblind the note by a process thatremoves the random blinding number from the digitalsignature while leaving the signature on the note (likethe payer removing the envelope). The organization receiving paymeni uses the digital pseudonym of thebank to decode the signature and verify that the numeric note contains an appropriate message and is thusa valid digital signature.There might seem to be danger in that numbers, unlike paper, can be copied easily and exactly. Banksmust be sure that the same numeric notes cannot bedeposited more than once. A solution is for the bank tomaintain a list of note numbers accepted, and to consult the list before accepting a note for deposit. The costof maintaining such a list can be far less per transactionthan the actual transaction cost of current payment systems, especially since expiration dates in note number.;can allow old numbers to be discarded.Another conceivable danger is that the bank’s digita.signature could be forged, which would allow counterfeiting. The security against this kind of threat derivesfrom the underlying digital-signaturecryptographictechnique, which is currently being proposed as an international standard and being used by banks and evento protect nuclear materials. The odds of someoneguessing a valid signed numeric note or of any twoindependentlychosen two-hundred-digitnote numbersbeing the same are on the order of 1 in 10 to the 75thpower.The numeric notes are unconditionallyuntraceable:The correspondence between withdrawalsand deposit:3cannot be learned by the bank from the numbers. Inthe untraceable communicationsystem described inthe last section, the possible outcomes of the coin tosseswere both equally likely, which meant that every correspondence between senders and messages wasequally likely. Similarly, because all suitable numbersare equally likely to be used for the independent blinding of each note, all correspondences between withdrawals and deposits are equally likely. More specifically, a unique random blinding number is implied bythe correspondence between any particular blindednote and any particular signed note.CREDENTIALTRANSACTIONSThere are legitimate needs for individuals to show credentials in relationships with many organizations.Problems arise when unnecessary data are revealed inthe process. As used here, “credentials” are statementsbased on an individual’srelationship with organiza-October 198.5 Volume 28 Number 10 Articlestions that are, in general, provided to other organizations. Some credentials, such as passports, drivers’ licenses, and membership cards, are commonly shownby individuals in the form of certificates. Individualscontrol access to these certificates, but not to the irrelevant or unnecessary information-suchas address, dateof birth, and universally identifying numbers-thatthey usually also contain. Individuals are also oftenasked to provide credential information without substantiating certificates, as when they fill out applications or tax forms. Even when the credential needed issimple, such forms often request much unnecessary orunnecessarily detailed data, presumably to allow confirmation. But confirmation can link irrelevant information and ultimately link back to information too oldto be appropriate. The trend today is toward takingmonitorabilityand control of the credentials processcompletely away from individuals by allowing organizations to be the repositories of all credential data. Individuals would merely provide the identifying information that allows linking to their own credentials.The countervailingproblem is that credential systems are subject to widespread abuse by individuals,such as the modification and the copying of many kindsof paper and plastic certificates that are made easy bytoday’s technology. This is one reason why certificatesare falling into disuse and organizations are maintaining credentials themselves. Information provided without substantiating documents is, of course, the easiestkind to falsify, which may account for the rapid deployment of so-called matching techniques that allow organizations to use identifying information to link andshare records. Special problems are raised by credentials that an individual might not care to show; thesewill be called “negative” credentials. Assuring the absence of negative credentials is often impractical withcertificates or eveh matching. Today, this problem isaddressed by centralized information maintainers whoattempt to collect reports of negative credentials fromall possible issuers. Use of multiple complete identitiesby sophisticated criminals is a related problem. As withcommunicationand payments, the obvious measuresunder the current approach for preventing abuse of credentials by individuals-widespreaduse of highly secure identity documents providing links to centrallymaintained credentials-areantithetical to the abilityof individuals to determine how information aboutthemselves is used.The solution is based on an individual’s ability totake a specially coded credential issued under onepseudonym and to transform it into a similarly codedform of the same credential that can be shown underthe individual’s other pseudonyms. Since thesecoded credentials are maintained and shown only byindividuals, they provide control similar to that provided by certificates. Individuals can also tailor thecoded form shown so that it provides only the necessary information and can ensure that obsolete information becomes unlinkable to current pseudonyms.Abuses by individuals, such as forgery, improper modification, and sharing, are prevented by the crypto-October 1985Volume 28Number 10graphic coding and by the protocols for such coding.Because these coded credentials are convenientlyissued and shown, they can be widely used, obviatingthe need for unsubstantiatedcredentials and matching.Centralized maintainers can still determine and issuecredentials on the absence of negative credentials, butcannot link to other information. Each person is able touse at most one pseudonym with any organization requiring such protection, thereby effectively preventinguse of multiple complete identities. Extensions ensureaccountabilityfor abuses created under any of an individual’s pseudonyms.The Basic Credential SystemThe essential concept again is presented by analogy tocarbon-lined envelopes, only this time the envelopeswould have windows. First, you make up your pseudonyms at random and write them on a plain slip ofpaper. When you want to get a credential from an organization, you put the slip of paper in a carbon-linedenvelope with a window exposing only the part of theslip bearing the pseudonym you will use with that organization. Upon receiving the envelope from you, theorganization makes a special signature in a repeatingpattern across the outside of the envelope. The kind ofsignature pattern indicates the kind of credential theissuing organization decides to give the person whosepseudonym they see through the window; the signaturepattern serves as the credential. When you get the envelope back from the issuing organization, you verifythe signature pattern. Before showing the credential toan organization, you place the slip in an envelope witha window position exposing only the pseudonym youuse with that organization and some of the adjacentcredential signature pattern. The receiving organizationchecks that the appropriate pseudonym and credentialsignature pattern are recognizable through the window.This approach naturally allows a variety of credentialsto be obtained and shown.You need not show all of your credentials to everyorganization: You can restrict that which is revealed toonly what is necessary. Because of the way the signature patterns repeat across the slip, a recognizable partof every signature pattern appears adjacent to eachpseudonym. In providing an envelope to an organization, though, you can limit the view through the window so that only necessary signatures are visible. Thecredentials visible could simply be limited by blackingout parts of the window, but more flexible restriction ispossible in actual systems. You might have a credentialthat represents your income, for instance. You couldtransform this credential into a more limited credentialindicating only that your income falls within a particular range. An even more powerful kind of restrictionallows an organization only to verify that a combination of credentials meeting some requirement is held,without revealing anything to the organization aboutwhich sufficient combination is actually held.An organization can ensure that no individual is ableto transact with it under more than one pseudonym.One way an individual could attempt to use more thanCommunications of the ACM1039 ArticlesUntraceable (credential transfers between pseuldonymi areillustrated by an analogy to window envelopes and carbonpaper. The individual (actually the card in the computerizedanalog) writes the pseudonyms on a slip and s,eals it, alongwith a facing piece of carbon paper, in an envelope thewindow of which exposes only the pseudonym--523-u&with organization X. Organization X then applies a signature(stamp) on the outside of the envelope received, with thechoice of “C” as the repeating pattern that indlicates the kindof credential issued. The individual verifies the signature re-one pseudonym with an organization is to use differentpseudonyms on the same slip of paper. This is prevented by a standard division of the slip into zones,where each zone is assigned to a particular organization; envelopes are accepted by an organization only ifthe window exposes the organization’s zone, whichbears a single indelibly written pseudonym. A secondway of attempting to use more than one pseudonym perorganization is t.o use more than one slip. ‘This is prevented by the establishment of an “is-a-person” organization that restricts each person to at most one is-aperson signature. Other organizations only accept envelopes with this signature recognizable through the windows. This is-a-person organization might ensure that itissues no more than one signature per per.son by takinga thumbprint and checking before giving a signaturethat the print is not already on file. The collection ofthumbprintsposes little danger to individuals, since theis-a-person organization cannot link the prints withanything.The pseudonyms used by individuals are untraceable, in the sense that envelopes give no clue, apart fromthe signatures shown, about the other randomly chosen1040Communication:; of the ACMturned. When the individual later wishes to show the credential to organization Y. the original envelope and carbon arediscarded, and the slip is placed in a new envelope thewindow of which exposes only the pseudonym-965-usedby the individual with Y. Now Y verifies the signature throughthe window of the envelope and knows that 965 has beenissued credential C. Organization Y cannot, however, learnthe other pseudonyms written on the slip. Actual computerized systems maintain the unconditional untraceability ofpseudonyms across the dashed boundary lines.pseudonyms they contain. Of course, the computerization of these systems would provide unconditionaluntraceability using digital blind signatures on numbers.(More complete details on such systems are presentedin [4].)Credential ClearinghousesWhen individuals have similar relationships with marqorganizations, there is often need for the centralizedcontrol provided by a credential clearinghouse, an organization that develops credential information about individuals’ relationships with its member organizationsand provides this information to these organizations. Incurrent practice, clearinghouse functions are performedby such major organizations as credit agencies, bankassociations, insurance industry associations, nationalcriminal information systems, and tax authorities.Member organizations typically exchange informationwith clearinghouses during initiations and terminationsof relationships.For concreteness, consider how a credit clearinghouse might control the use of consumer credit usingan extended form of the credential system. The clear-October 1985Volume 28Number 10 Articlesinghouse gives you a number of enabling credentialsthat in effect say “This person is authorized for $100worth of credit. If no resolution credential is returnedto us within a year, we will assume that the individualhas not repaid.” You could provide one such credentialto a shop, which then gives you credit worth up to$100. When you settle your account with the shopsome time later, they give you the corresponding resolution credential, which you ultimately return to theclearinghouse. An important property of this approachis that the clearinghouse and shops cannot link thecredentials; the clearinghouse with the cooperation ofall the shops cannot learn which shop you went to, anymore than the shop can learn your pseudonym with theclearinghouse, since the enabling and resolution credentials are unconditionally untraceable.Security against abuse by individuals requires thatthe enabling credential be prevented from being shownto more than one shop. Otherwise someone could obtain too much credit from a single enabling credential.Similarly, it should not be possible to show a singleresolution credential more than once to the clearinghouse, since otherwise someone could convince theUntraceable credentials with numbers also follow the paperanalogy. The way transmissions [l .l] and [1.2] are developed is detailed below. The so-called one-way function f iseasily computed by a publicly known technique, but its inverse is thought to be infeasible to compute. Organization Xdetermines the validity of both transmissions received byverifying that the first is a signature on the one-way functionof the second. Later, X provides the signature for the desiredcredential on [1.2]. The card verifies the signature and replaces s, by s,. Organization Y verifies [3.1] and [3.2] just asX did. When the credential [3.3] is received by Y, it is verifiedas a signed copy of [3.2]. A special organization 2 ensuresthat the [l .l]s (and the [3.1]s) are of the proper form, butOctober 1985Volume 28Number 10clearinghouse that more debt had been repaid than wasin fact repaid.Now consider how the credentials in the creditagency example might be handled in terms of the envelope analogy. First, you get an open padlock from theshop you want credit from, lock it through a holepunched in your slip, and provide the locked slip, inthe appropriate window envelope, to the clearinghouse.The clearinghouse checks the envelope from the outside to assure that a padlock is locked through the slipand that the window exposes part of a slip bearing yourcredit-worthy pseudonym, makes the enabling signature on the envelope, and returns the envelope to you.When you provide the slip to the shop in the appropriate envelope, the shop is able to see its padlock throughthe window (the clearinghouse’s window did not allowthe padlock to be seen, but only allowed the fact thatthe padlock was locked through the slip to be felt) andcan extend you the credit. Upon settling your account,the shop gives you the key to their padlock. In effect,the key is the resolution credential. It allows you toremove the padlock and return the slip to the clearinghouse in the appropriate envelope. The clearinghousedoes not obtain information useful in tracing. First the cardsupplies many candidates to Z, each of the form qn =f(u . SE) . t;, where u is the special pseudonym used by theindividual with Z, and sn = f(s;) and r” = f(tA), with .sA and t;created at random by the card. When the card later learnswhich candidates qn have been selected at random for inspection by Z, the card supplies the corresponding s; and t;lfor each. This allows Z to verify that qn = f(u . f(s;)c) . f(t;)l.If all inspected candidates verify, then Z supplies the signedform of all uninspected candidates. (Extensions further reduce the chance of an improper candidate being signed.) Thecard transforms a signed candidate into [l .1] by dividing outL.Communications of the ACM1041 Articleschecks that the intact slip is returned without the lockand thus knows that you repaid, though it cannot determine wh:ich shop was involved.StructuringClearinghousesFurther restrictions on the information available toclearinghouses, as well as better control of abuses byindividuals, can be achieved by a partially hierarchicalstructuring of clearinghouses. There might be clearinghouses fa’r each of the dozen or two major areas ofconsumer interaction with organizations--areas such ascredit, education, social services, tax, insurance, voterregistration, licenses, employment, criminal, and evenmilitary service. Each such clearinghouse might have anumber of subclearinghouses below it. An educationclearinghouse, for example, might have subclearinghouses below it for primary, secondary, university, andprofessional education. An organization interacts withorganizations immediately below it in such a hierarchyjust as a clealringhouse interacts with its member organizations. Only an initial enabling and final resolution credential were transferred in the previous example of credit clearinghouses, but more generally credentials can be transferred between an organization andthe organization hierarchically below it in either direction and at any point during a relationship. Subclearinghouses reduce the amount of detail obtainable by clearinghouses, which reduces the information that can belinked by the combined structure of clearinghouses andsubclearinghouses.Hierarchical structuring can also be used to enforcesanctions against individuals perpetrating abuses witheven a single organization. Within a hiera.rchy of clearinghouses, each would expect to learn of serious abusesagainst organizations below it by a lack of special periodic “no serious abuse” credentials (or by a lack ofresolution credentials); if a clearinghouse receives acomplete set of such credentials, it also periodicallyissues a “no iserious abuse” credential. Someone lackingsuch a credential from the highest level clearinghousesmight be refused service by member organizations. Amore practical variation allows the same .transfers ofcredentials to be conducted only once in advance, witheach organization attaching, in terms of the envelopeanalogy, a locked padlock. Only when the individualreceives the corresponding key to the lock from everyorganization that attached a lock can all the locks beremoved and! the credential be shown in the requiredform without locks. If the keys were requ:ired to bemade available by organizations at a set interval beforethe credential1 is required, time might be provided forclearing up errors and misunderstandings, or even formore formal grievance procedures if needed.Preventingthe Use of Obsolete InformationIf individuals, change pseudonyms periodically, theycannot be linked to obsolete information. Pseudonymsmight be changed on a yearly basis. The initial information associated with new pseudonyms would be provided through the transfer of credentials from previouspseudonyms. The changeovers might be staggered to1042Communications of the ACMallow time for completion of pending business.There are additional benefits to changing pseudonyms aside from the weeding out of obsolete information. The periodic reduction to essential informationalso prevents organizations from gradually accumulating information that might ultimately be used to linkpseudonyms. Another consequence of individualstransferring all the initial information for a period isthat they must then know the requirements for information by each organization, must know where eachpiece of information comes from, and must consent toeach such transfer. Thus, such arrangements ensurethat information linkable by each organization isknown to and agreed on-that is, that it can be monitored and controlled by individuals.BROADERISSUESAdvantagesto IndividualsAs the public becomes more aware of and familiar withthe extent and possibilities of emerging informationtechnology, there should be a growing demand for thekinds of systems described here. Individuals stand togain in increased convenience and reliability, improvedprotection against abuses by individuals and organizations, a kind of equal parity with organizations, and, ofcourse, monitorability and control over how information about themselves is used.Individuals will be free to obtain their card computers from any source, to use whatever other hardware or software they choose, and to interface into thecommunication system wherever they please.The techniques already touched on for saving encoded backup copies of a card computer’s data are relevant in terms of advantages to individuals. The cardcomputer would create a key to encode the backupcopies it issues. A replacement card computer needsonly this key and a backup copy to obtain the fullcapabilities of the original card. The key might be impractical for an owner to remember, since it should beat least 40 digits long. A convenient and reliable arrangement for maintaining the key involves dividing itinto parts and giving different parts to various trustees.Unconditionally secure techniques allow various designated subsets of trustees to completely recover the key;other insufficient subsets would thus be unable to learnanything about the key. A sufficient subset of trusteescould provide the key to its owner, if so requested.Other subsets might be sufficient to recover the key,the backup data, and the owner’s secret authorizingnumber, enabling the trustees in such subsets to takeover the owner’s affairs when needed. More generally,such an approach illustrates how an individual’s rightto designate proxies, a right that is of course enjoyed byorganizations, is ensured.It has been stated that a lost or stolen card computeris of very little use to anyone other than its owner. Thisis because only the owner need know the secret authorizing number that the card computer requires before allowing a transaction. This number might typically be about six digits long. A reasonably tamper-October 1985Volume 28Number 10 Articlesresistant part of a card computer might make the carduseless as a replacement for a thief’s own card andcould even make use of physical identification techniques such as fingerprints to prevent anyone but itsowner from using it to conduct transactions. Even assuming that sophisticated criminals could extract theinformation content of tamper-resistant parts of thecard, a great many actual trial uses of guessed authorizing numbers with organizations might still be requiredbefore the actual number could be determined, makingsuch attacks quite likely to be detected and to fail.Individuals can always sacrifice their protection byrevealing linking information. Of course, the systemsdiscussed here can provide secure relationships without requiring such disclosures. It is even possible underexceptional circumstances for persons accused ofabuses under pseudonyms to demonstrate that thepseudonyms are not theirs, without revealing linkinginformation. For example, in communication transactions, people could show that their physical entry to thesystem was not used for a particular message; in payment transactions, they could show that a payment didnot involve their account; and in credential transactions, they could show that a pseudonym was notamong the set obtainable under their thumbprint.Pseudonyms would be used only for the computerized part of ordinary consumer transactions, in a waythat would provide acceptable protection against linking. Pseudonym use might be transparent to anyoneconducting transactions: People never need to actuallysee pseudonyms and could usually forget that thkywere being used. Of course, the scope of the separatedrelationships enjoyed by individuals need not dependon the actual legal or administrative structure of organizations. But some linking of separate relationshipsmight occur, for example, in the case of a consumerwho actually wanted to be recognized, as part of aninvestigation, or in other exceptional situations. Butlinking of some relationships does not, in general, allowothers to be linked, and the regular changing of pseudonyms already described allows linkings to be shedover time. Naturally, the scope of relationships, as wellas such things as the granularity and timing requirements of the transaction systems, must be adjusted toprovide the desired kind of separation.Security under the new approach need not restrictindividuals from enjoying the same protections as organizations, and an equal opportunity to use the systems. A payment, for example, could be made betweentwo friends using their card computers without involving any other computer system. A small business wouldeven be able to handle all customer transactions with acard computer.Advantagesto OrganizationsOrganizations also have much to gain: Transaction systems under the new approach will bring all the advantages of advanced computerization, improve security,and he a force for improved goodwill from the public.Not only do organizations generally have an interest inOctober 1985Volume 28NTmber 10maintaining good relations with individuals-inmaking transactions, they have many of the same interestsand concerns as individuals. Thus, the advantages to individuals considered above apply in part to organizations as well.The mechanisms that the systems described here‘_.would use also compare favorably, from the economic.stance of organizations, with systems based on the logical extension of the current approach, which require*widely trusted tamper-resistant devices at all points ofentry to transaction systems. Such requirements alsomean substantial agreement, outlay, and commitmentto design before widespread use can begin. In additionto the substantial costs and risks of such an approach,early commitment to design usually leads to obsolete technology once systems come into use. Tamper- .Iresistant techniques currently available also requiresubstantial compromise between cost and security...Since mutually trusted and tamper-resistant equipmentis not required with the systems described here, any-‘_entry point to a system can be freely used; users can,even supply their own terminal equipment and takeadvantage of the latest technology.The new systems would make more sophisticated useof cryptographic techniques than many proposals underthe current approach. But even the difference betweenthe simplest current proposals and the mechanisms required by the systems presented here is just a fractionof a chip in the technologies of the near future. Ordinary microcomputers are already capable of conducting.the required protocols for individuals using the cornmunication, payment, and limited versions of the cre..dential systems described here.Since the sensitivity and the quantity of consumer:’data in the hands of organizations are reduced, so is.their exposure to incidents that might impair publiccperception or incur legal liability. Reductions in datacould also streamline operations, and the increased appropriateness of the remaining data could provide moreeffective policy and decision procedures. Also, obtaining information needed for decision making by surveysand the like might be more successful in the future*under systems ensuring untraceability.Detected abuses can be dealt with to an extent ac*.ceptably close to the limits of any transaction system.Individuals defaulting on requirements or perpetrating1serious abuses can always step outside the controls of-.any transaction system by going “underground.” Trans- . action systems are thus limited to preventing further.transactions once an abuse or default threshold isreached. The new approach stops short of approachingthis limit because, as has been mentioned, it ensuresindividuals some time delay-hopefullyenough for duepro&s if needed-before all transactions are prevented. The new approach restricts the amount of default possible by providing a desired balance betweenprior restraint, as in the basic payment system, andaccountability after the fact, as with credit and otherclearinghouse functions.Undetected abuses can be restrained to an extent.also acceptably close to the limits of any transaction*‘:,Communicatioris of the ACM. 1043 Articlessystem. The communication, payment, and credentialsystems desc.ribed here seem quite able to prevent undetected abu:seby individuals. But no transaction system is able to detect or prevent abuse that results froman individual. obtaining something through legitimateuse of a system and then transferring it, outside thesystem, to another person. Transferring the ability touse a communication system to others is an instance ofthe proxy right already discussed. When such transfersoccur in the context of payment transactions, they canbe treated as illicit payments, which, as has alreadybeen pointed out in the section on payment transactions, can be deterred. The credential system directlyprevents the transfer of credentials from the pseudonyms of one person to those of another. Currently, “inperson” proxy is prevented by certificates bearing photos. Such photo tokens could still be used .with the newapproach, but they would bear only a photo, an indication of the kind of credential, and possibly a pseudonym.It is too easy to step outside current transaction systems by dealing in cash, using coin phones, sendinganonymous letters, and using false credentials. Significant security improvements can only be obtained withcomprehensive systems. But such security under thecurrent approach may meet with substantial and broadbased resistance from individuals-particularlywithawareness of the alternatives posed by the new approach.Future ImplicationsLarge-scale automated transaction systems are imminent. The architecture chosen for these systems mayhave a long-term impact on the centralization of oureconomic system, on some of our basic liberties, andeven on our dlemocracy. The initial choice of directionwill gather economic and societal momentum, makingreversal increasindv less likelv.Economic centr%zation ma; be furthered under thecurrent approach. Computerization has already allowedorganizations to grow to unprecedented size and influence. Further computerization could increase aggregation and centralization by allowing service providersand other major actors to obtain far-reaching information about individuals. If this information were partitioned into separate unlinkable relationships, such aggregation and centralization might be reversed. The information age has other significant potential for decentralization: Information gathering and disseminationlack the inherent centralization of earlier technologies,and payment systems integrated with communicationsvstems allow notentiallv unrestricted access to distribktion channels. The new approach offers individualsand small organizations the same access to such services as large organizations.Some of our basic liberties may be threatened bycomputerization under the current approach. Theinterlinking of relationships and the surveillance required just for practical security may becolme unacceptable. Such surveillance and linking are unnecessary1044Communications of the ACMwhen information can be made public, scanned, orbought and sold pseudonymously.The chilling effect of a growing surveillance potentialcould also decrease expression and participation. Theloss of monitorability and control could increase aliena,.tion and also decrease participation. Sophisticated marketing techniques that rely on profiles of individualsare now being used to manipulate public opinion andelections. The potential exists not only for reversingthese problems, but for increasing democratization. Forinstance, with the kinds of systems presented here,multiparty secure election and polling could be conveniently conducted without centralized coordination andwith those expressing their views able to show relevantcredentials.Advances in information technology have alwaysbeen accompanied by major changes in society: Thetransition from tribal to larger hierarchical forms, forexample, was accompanied by written language, andprinting technology helped to foster the emergence oflarge-scale democracies. Coupling computers to telecommunications technologies creates what has beencalled the ultimate medium-it certainly is a big stepup from paper. One might ask, To what forms of societycould this new technology lead? The two approachesappear to hold quite different answers.Acknowledgments. The author would like to thankJan-Hendrick Evertse, Wiebren de Jonge, and Ronald L.Rivest for discussions during the early development ofthe ideas herein presented, as well as everyone whoshowed interest in and commented on this work.REFERENCES1. Burnham, D. The Rise of the Computer State: The Threat to Our Free-2.3.4.5.6.doms, Our Ethics and Our Democratic Process.Foreword by WalterCronkite. Random House, New York, 1983. (Not cited in text.)Chaum, D. The dining cryptographers problem: Unconditionalsender and recipient untraceability. Available from the author.Chaum, D. Privacy protected payments: Unconditional payer and/orpayee untraceability. Available from the author.Chaum, D. Showing credentials without identification: Transferringsignatures between unconditionally unlinkable pseudonyms. Available from the author.Diffie, W., and Hellman, M.E. New directions in cryptography. IEEETrans. hf. Theory T-17.76(Nov. 1976), 644-654.Rivest. R.L., Shamir, A., and Adleman, L. A method for obtainingdigital signatures and public-key cryptosystems. Commun.ACM 21, i:(Feb. 1978),120-126.CR Categories and Subject Descriptors: C.2.0 [Computer-Communication Networks]:General-security and protection: E.3 [Data Encryption]: public key cryptosystems; J.l [AdministrativeData Processing]: financial (e.g.,EFTS);K.4.1 [Computers and Society]: Public Policy Issues-privacy; K.4.2 [Computers and Society]: Social Issues-abuse andcrime involving computers; K.8 [Personal Computing]General Terms: SecurityAdditional Key Words and Phrases: blind signatures, card com-puters, digital pseudonyms, multiparty security, unconditional security,untraceabilityAuthor’s Present Address: David Chaum. Centre for Mathematics andComputer Science, Kruislaan 413, 1098 SJAmsterdam, The NetherlandsInternet: chaum@mcvax.uucp; Telex: 12571 mactr nl.Permission to copy without fee all or part of this material is grantedprovided that the copies are not made or distributed for direct commercial advantage, the ACM copyright notice and the title of the publicationand its date appear, and notice is given that copying is by permission ofthe Association for Computing Machinery. To copy otherwise, or torepublish, requires a fee and/or specific permission.October 1985Volume 28Number 111
E-VotingSecret-Ballot Receipts:True Voter-Verifiable ElectionsA new kind of receipt sets a far higher standard of securityby letting voters verify the election outcome—even if allelection computers and records were compromised. Thesystem preserves ballot secrecy, while improving access,robustness, and adjucation, all at lower cost.DAVID CHAUM38urrent electronic voting machines at pollingplaces don’t give receipts. Rather, they requireprospective voters to trust them—withoutproof or confirming evidence—to correctlyrecord each vote and include it in the final tally. Receiptscould assure voters that their intended votes are counted.However, receipts have so far not been allowed because ofthe “secret ballot” principle, which forbids voters fromtaking anything out of the polling place that could beused to show others how they voted. The reason for this isto prevent schemes that could improperly influence voters, such as vote selling and various forms of coercion.Introduced here is a fundamentally new kind of receipt. In the voting booth, the voter can see his or herchoices clearly printed on the receipt. After taking it outof the booth, the voter can use it to ensure that the votes itcontains are included correctly in the final tally. But, because the choices are safely encrypted before it is removedfrom the booth, the receipt cannot be used to show others how the voter voted.The receipt system can be proven mathematically toensure election integrity against whatever misbehavingmachines or people might do to surreptitiously changevotes. This level of integrity should enhance voter satisfaction and confidence and positively impact participation.The system also eliminates the need for trusted votingmachines, which typically use proprietary “black box”technologies. It can run with published code on standardPCs, allowing significantly lower cost and higher quality.The receipts also improve robustness, currently achievedby costly proprietary hardware redundancy in storing andtransporting votes, not only because failures can be detected at the polls in time to prevent lost votes, but alsoCPUBLISHED BY THE IEEE COMPUTER SOCIETY■because the votesthat receipts contain can be counted no matter what happens to the machines. Moreover, open-platform hardware, instead ofbeing stored in special warehouses most of the time,could even be used for various purposes year-round, forexample in schools and libraries.The inability of the current approach to reconcile secrecy and security needs has also led to functionalityproblems. The new US Federal requirement for provisional ballots—ballots cast by individuals whose namesdon’t appear on the registration list—means separate handling and counting, singling provisional ballots out for reduced privacy protection. Just as the system presentedhere can seamlessly include all such votes, it can lift the requirement that voters vote from their home precinct, ensuring access while improving convenience and turnout.(It even makes interjurisdiction voting workable.) Courtscan also surgically add or remove the votes of particularfine-grained categories of voters; their inability to do sotoday forces them to call revotes, throw out all ballots, ordetermine winners themselves.Voting with the new approachAfter you input your choices using a touch screen orother input means, with the new approach, a small device that looks like a cash register printer generates aprintout (part of which will become your receipt). Theprintout lists the names of the candidates you chosealong with their party affiliations and offices sought, asFigure 1 shows, as well as your vote on any ballot questions. Included are allowed write-ins and other choices,such as with straight-party voting and prioritized and1540-7993/04/$20.00 © 2004 IEEE■IEEE SECURITY & PRIVACY E-VotingFigure 1. An example part of a ballot printout listing a candidate selected. In addition to being able to include the candidate’sname, party affiliation, and office sought, the printout can also include other types of contests and various graphics options.weighted votes. The printout might also include graphics, such as a voter’s handwritten choice of candidate,party symbols, or (someday) photographs such as somecountries use. It might also alert you to contests or questions you skipped and serves as the single summary ofyour vote. After printing your votes, the machineprompts you to review the printout still in the printerand accept it, giving you the opportunity to amend yourvote and generate a new printout.Figure 2. Last inch of the printout before the two laminated layersare separated.Generating a receiptIf you agree with the printout, the machine asks you toindicate whether you wish to keep the top or the bottomlayer of it. The printer differs from ordinary receiptprinters because it simultaneously prints separate butaligned graphics on both the top and bottom sides of thestrip. After you’ve indicated your choice of layer, the machine prints the final inch of the form. (The voter choosing which layer only after the main part is printed is keyto keeping the system honest.) It then automatically cutsoff both layers, still laminated together, and releases themto you. Figure 2 shows the laminated last inch of theprintout.As you separate the layers, the image of the votes becomes an unreadable and seemingly random pattern oftiny squares printed on each of two layers of translucentplastic material. Neither layer is readable on its own—thelight passing through the sandwiched layers only whereneither layer has printing is what makes your choices visible. Still, each layer separately and safely encodes yourvote exactly as you saw it.The last inch of the printout is different because itslayers have messages that are readable after the layers areseparated, as Figure 3 shows. The layer you select to keepas your receipt bears a message such as, “Voter keeps thisprivacy-protected receipt layer” (Figure 3a), whereas theother layer might state, “Voter must surrender this layer topoll worker” (Figure 3b).Verifying your voteAs you leave the polling place, you give the poll workerthe layer marked for surrender. For your protection and as(a)(b)Figure 3. Last inch of the printout after it’s separated: (a) the receipt(the layer the voter selects to keep) and (b) the layer that’sshredded before the voter leaves the polling place.you watch, the poll worker checks that it’s the correctlayer and destroys it in a small, transparently housed papershredder. You keep the other layer as your receipt. Thevoting machine keeps an electronic version of this samefinal receipt until it successfully sends it in for posting onthe official election Web site. The bits on the shreddedpaper layer are also “shredded” electronically—that is, theonly things that remain of your vote are your physicallayer and, in the machine, a digital version of that sameimage.(One way to handle voters that refuse to surrenderlayers is for the exit shredder—based on its reading of thewww.computer.org/security/■IEEE SECURITY & PRIVACY39 E-Votingballot serial number barcode, which additionally prevents shredding the wrong layer and allows spoiling of“missing” receipts—to give a sticker with a key neededto decrypt the last inch. This also lets poll workers issuethe other last inch to voters claiming their choice of layerwas switched.)You can safely show your receipt to anyone, including political, governmental, public interest, or media organizations. Outside the polling place, for example, agroup such as the League of Women Voters might offerto check your receipt. They simply scan it with a handheld scanner and let you know immediately that it’s authentic and correct (by subjecting the receipt’s printedimage and its coded data to a consistency check and laterensuring that it’s correctly posted online when it shouldbe, all of which is detailed later). An invalid receiptwould irrefutably indicate incorrect operation of election equipment, although a second scanner could readilydispel a false alarm.When the polls close, the polling place sends only thedigital form of the receipts (not the shredded layers orcleartext votes), electronically or by transport of, say, a CD.Election Web siteIf you wish, you can find the page on the official electionWeb site that includes your receipt by entering the receipt’s serial number. You could then check that yourvote was posted correctly—for example, by printing theposted receipt and overlaying it with your original receiptand checking that they are identical. (You need not runconsistency-checking software, because anyone can dothis for all posted receipts, as discussed later.) You couldalso provide the original or its image by fax or photocopyto others for checking.At some point after the polls close, the definitive set ofreceipts to be counted—the receipt batch—is posted on theWeb site along with attesting signatures. The election’sfinal output—the tally batch—is similarly posted. It contains the same number of items as the receipt batch, buteach is a readable plaintext image of the ballot exactly as thevoter saw it in the booth. (Using simple software, anyonecan compute the totals from the tally images.) To protectprivacy and ballot secrecy, the tally batches are in a randomorder, thereby hiding the correspondence between receipts and ballot images.To ensure that a one-to-one correspondence does infact exist between the batches—that is, that no ballotswere inserted, deleted, or changed—the system uses akind of audit of a chain of intermediate batches betweenthe receipt batch and tally batch. After creating and publishing the intermediate batches, the system decrypts randomly chosen samples from them. These samples arechosen so as not to reveal enough to compromise privacy.They reveal enough, however, that checking themagainst the published batches effectively thereby checks40IEEE SECURITY & PRIVACY■JANUARY/FEBRUARY 2004that the correct one-to-one correspondence holds. Anyone can do this checking by running a simple, opensource program that they can download from any of multiple suppliers or even write themselves. The programcan also check the consistency of each receipt batch entry.Such a suite of checks can convince anyone that the receipt batch correctly yielded the tally batch.Receipt systemThe system introduced in this section is detailed in the“More formally” sidebar (on page 44), which in turn servesas a basis for the “Proof sketches” sidebar (on page 46).PropertiesThe receipt system ensures several properties.First, if your receipt is correctly posted, you can besure (with acceptable probability) that your vote will beincluded correctly in the tally. A receipt that isn’t properlyposted is physical evidence of a failure of the election system, and a refusal by officials to post it is an irrefutable admission of a breakdown in the election process.In addition, no one can decode your receipt or otherwise link it to your vote except by breaking the code ordecrypting it using all the secret keys, each of which is assigned to a different trustee.Even if all the election computers were compromisedand running colluding malicious software (even havingaccess to unlimited computing power), there are onlythree ways that a system could change a voter’s correctlyposted ballot without direct detection:• It could print an incorrect layer, gambling that the voterwill choose the other layer.• It could use the same serial number for two different receipts, hoping the two voters choose the same layer.• It could perform a tally process step incorrectly, taking thechance that the step will escape selection during audit.For each ballot and with any of the three approaches, the chance that it would go undetected is onehalf. Thus, the chance that two ballots could bechanged without detection of at least one is only aquarter, three ballots without a single detection aneighth, and so on. Changes in just 10 ballots will avoidany detection fewer than one in 1,000 times, andchanges in 20 ballots will avoid detection fewer thanone in 1,000,000 times.In practice, many voters will not check that their receipts are posted or even have others check them. Forexample, in a large election, if just 10 receipts arechanged and only 5 percent of receipts are checked atrandom, the chance of detections is 50 percent. But inclose elections in which a small number of ballots matter, a sufficiently high percentage of ballots would presumably be checked at least after the results were pub- E-Votinglished. For example, if 100 votes would have changedthe outcome in a large election, 5 percent of receiptschecked would be enough to catch cheating all but onein 1,000 times.Receipt encodingWhat makes the laminated layers readable and the separated layers meaningless is the mutual relationship of thepatterns printed in black on each translucent plastic layer.The printing on both layers is divided into a grid ofsquares, or pixel locations. Each pixel location is printedwith one of two pixel symbols, like a large, filled-in tictac-toe board. The two pixel symbols are reverses of eachother: where one is clear, the other is black, and viceversa. When two different pixel symbols are aligned onedirectly on top of the other as they are when laminated,any clear spot on one is blocked by black on the other,making the lamination appear totally opaque. When thesame pixel symbol is printed on both layers and the symbols are aligned, all the clear parts are directly over eachother and light can thus pass through the laminate. Figure 4 shows layers with both the same and different symbols overlaid.This technique can be used to encode information onone sheet so only someone with a second sheet can readit, the application that Moni Naor and Adi Shamir firstproposed it for.1 It’s useful to associate names with thetwo sheets: I’ll call the first “white” and the second “red”(but these colors have no more graphic significance thanthat you might tint the two translucent sheets to distinguish them). Each sheet is divided into a grid of pixel locations, and each pixel location has a pixel symbol printedon it. When the two sheets are laminated together, thegrids line up exactly: each pixel location on one sheet hasa paired pixel location at the same coordinates on the othersheet so the two are exactly one on top of the other. Firstyou choose the pixel symbols for the white sheet totally atrandom. Now to encode your message in the laminate,you simply choose each of the symbols of the red sheetaccordingly: If you want light to shine through for a pixellocation when laminated, you choose the same pixelsymbol as its paired pixel on the white sheet; if you don’twant light to go through at that location, you choose theother symbol.Most current printing technologies print ordinarytext by creating a grid of pixel locations in which someare printed fully with black ink while others get no ink.For the present system, instead of leaving the backgroundwithout ink, the system pairs nonmatching (that is,opaque) pixel symbol combinations; instead of using fullblack ink for letters, the system pairs matching (that is,partly clear) pixel-symbol combinations, creating grayletters that depend on backlighting for brightness. Figure5 illustrates the differences between the techniques.(The system can use modified direct thermal printers,Top layer:Bottom layer:Both layersoverlaid:Part-transparentOpaqueFigure 4. The two pixel symbols, separate and overlaid. When twodifferent pixel symbols are overlaid, the result is opaque; matchingpixel symbols let light through.NewspaperTop layerBottom layerLaminatedFigure 5. The letter “e” in (a) standard printing and (b) receiptprinting. The receipt printer pairs matching and nonmatching pixelsymbols to produce letters and blank space, respectively.like those deployed at most checkout counters. Theseprinters have two to three times the resolution neededhere, but this can be used to frame pixels and forgive mechanical alignment errors between the ceramic printheads that would run the width of the paper on top andbottom. A clear “fugitive” adhesive laminates the layersand isn’t sticky when the layers are delaminated.)When the receipt layers are still laminated, the voter’schoices are thus printed in a gray made up of half blackand half white spots on a black background. This ballotimage is the visible plaintext summary of the vote accepted by the voter.Because the vote should be encoded in each layer separately, both layers need some red pixels. Swapping twopaired pixel symbols between the layers leaves the laminate visually unchanged. So pairs in half of the pixel locations, say, in a checkerboard pattern, are swapped. If thepixels were tinted, instead of separate red and white layers,www.computer.org/security/■IEEE SECURITY & PRIVACY41 E-VotingIntermediate batchReceipt batchTally batchReceiptimageBallotimage1,000,000ReceiptimageBallot image1,000,001Receiptimage1,625,962BallotimageTrusteetransformTrusteetransformTrusteetransformFigure 6. The overall tabulating process. Receipts pass through trustee-operated mixes, which transform them step-bystep into cleartext ballot images to be posted and tallied. Serial numbers (and all but the red half of the pixel symbols) arestripped off in forming the first intermediary batch. Mixes transform by removing a layer of encryption from each inputand reordering the inputs in their output. Vertical ellipses indicate batch items not shown; horizontal ellipses indicateadditional trustees. (Darker ballot image pixels are inferred from the lighter ones using redundancy in the font.)each layer would look like the red and white tableclothsin a typical bistro.The system in effect uses the one-time pad codingtechnique to encrypt the ballot image. Claude Shannonproved this technique to be unbreakable, assuming thekey is random.2 The keys used—the white pixels—aren’t random but are believed to be indistinguishable inpractice from random except to the set of trustees, whocollectively guard ballot secrecy. Thus, if you have onlyyour receipt layer and are staring at a particular whitepixel on it, you learn nothing. Similarly, a red pixel onlytells you that the lamination would have been partly clearif the paired white pixel matched the red pixel andopaque if it didn’t. But knowing nothing about whichwhite pixel symbol was paired means you can’t infer anything more about whether the combination was partlyclear or opaque.Receipts should encode the votes exactly as the votersees them. It’s technically possible, however, that the stilllaminated printout shows one set of choices, but the receipt layer the voter takes encodes other choices. Thiscould occur only if just one layer was invalid. If both layersare invalid, whichever layer the voter takes will fail checking and provide direct evidence of cheating by the system.If only one layer is invalid, and the voter doesn’t select it, itwon’t be checked, just shredded. However, essential to security, as mentioned earlier, is that the voter chooseswhich layer to take only after the printer finishes printingthe votes. Thus, a single invalid layer has essentially a 50-50chance of being selected by the voter and caught.42IEEE SECURITY & PRIVACY■JANUARY/FEBRUARY 2004Tabulating processWhen the polls close, election officials or the courts shouldresolve any provisionally or otherwise contested voting andthen post the receipts to be included in the tabulatingprocess electronically as the official definitive receipt batch.(A preliminary tally formed before contested and provisional ballots are included can, to obscure the provisional/contested votes being adjudicated, omit a randomselection of ballots that will be included in the final tally.)The tabulating process starts with a receipt batch andproduces a final tally batch of ballot images. The firsttrustee produces the first intermediate batch from the receipt batch. The next trustee forms the second intermediate batch from the first intermediate batch, and so forth,until the last trustee forms the tally batch from the last intermediate batch. Figure 6 diagrams this process.Trustees change the coding and the order of itemsfrom each batch in the chain to the next, thus ensuringprivacy. Requiring each trustee to release some randomsamples, establishing that items have been correctly transferred from batch to batch, ensures integrity.Russian nesting dollsA Russian nesting doll analogy can illustrate the processingof the input batch of receipts into the tally batch of ballotimages. Each batch corresponds to a collection of dolls,each doll to an item in the batch. The receipt batch, for instance, is a collection of outermost “big” dolls, each with allits smaller dolls neatly nested within. The next batch, thefirst intermediary batch, is similar to the receipt batch but E-Votingwithout the big dolls. This continues to the tally batch: thetiny solid wood innermost dolls. All batches have the samenumber of dolls, and within a batch the outermost dolls areall the same size and contain their own smaller dolls.The nesting dolls are like secret agents, each doll holding a unique random code sheet in its hands. The sheet isa grid of pixels printed using the two pixel symbols. Eachdoll is also physically locked with a combination lock thatprevents access to the dolls within. A different secretcombination, known only to a single correspondingtrustee, unlocks all dolls of a particular size.Consider the trustee with the secret combination for,say, the 10-inch dolls. To process an individual doll in thebatch of 10-inch dolls, the trustee first unlocks the dollusing the secret combination and removes its contents, a9-inch doll. The trustee now has two code sheets, onefrom the 10-inch and one from the 9-inch doll. Thetrustee combines the two sheets to produce a new codesheet as follows: for every pixel location where light passesthrough the two sheets when stacked, one pixel symbol isprinted on the new sheet; everywhere no light passesthrough, the other symbol is printed. (When each of thetwo pixel symbols is considered a binary digit, 1 or 0,combining any number of sheets is simply adding the values modulo two.) The trustee places the combined codesheet in the hands of the 9-inch doll and destroys theempty 10-inch doll along with both old code sheets.After likewise processing all the 10-inch dolls into 9inch dolls with new code sheets, the trustee randomizestheir order and outputs them as a batch. The trustee withthe secret combination for the 9-inch dolls takes this batchas input, processes it into a batch of 8-inch dolls, and so on.Coded sheetsA simple way to apply this process to an election starts byforming the sheet held by each big doll differently fromall the sheets of the dolls nested within it. Suppose theoriginal doll maker faithfully chooses sheets for all thedolls inside a big doll at random, but makes copies of allthe sheets. Instead of keeping these copies on separatesheets, the doll maker combines them into a single sheetfor the big doll, one pair of sheets at a time (or all at onceusing modulo-two addition). This is the “white” sheetfor that big doll. Intuitively, it’s formed by an initial“adding in” of all the inner sheets’ coding, which will be“subtracted out” in stages as the dolls are processed.Now suppose a voter has one of these big dolls andwants to use it to vote with privacy. The voter determinesa red sheet that produces the desired ballot image whenoptically combined with the doll’s white sheet (as previously explained). The voter then shreds the white sheetand gives the doll the red sheet to hold, placing the doll inthe initial batch of big dolls. After processing by all thetrustees, the final output batch contains the tiny solidwood dolls in random order, each holding a sheet that re-BatchBatchBatchFigure 7. Batch processing by a single trustee. Triangles show theresult of the random public draw and the broken lines show linkswhose details are accordingly released in audit.veals a ballot image (which is easily seen by laminatingwith a sheet containing the same pixel symbol copiedeverywhere). All of the code sheets combined in thewhite sheet that influenced the red sheet have now beensubtracted out.To provide integrity, the system must be able to catchany trustee attempting to improperly change dolls ortheir sheets during processing. The solution will entail requiring trustees to release complete and detailed audittrails of the processing (as videotapes, for example), butonly for select dolls.To allow trustees to release half of the complete setof tapes without compromising ballot secrecy, theyeach take on the role of processing more than one ofthe batches, say, two successive batches of the chain.This prevents tracing any tiny doll back to a big doll,even by a collusion of all but one trustee. After processing, a public lottery draw selects half the dolls in thetrustees’ first input batch, and the trustee releases theirvideos. Videos of these dolls’ second processingwouldn’t be revealed (because they might allow linking), but the second-batch videos of the other dolls arerevealed. Figure 7 shows an example processing of twosuch batches by a trustee.Exact tracing is thus prevented because trustees releaseonly one video per doll for the two adjacent batches. Still,each time a trustee improperly forms a batch item there isa 50-percent chance of it being selected for release, so theodds of being caught stack up just as fast as with cheatingby introducing a bad printed layer.EncryptionReturning to the receipt system, the analogy’s red andwww.computer.org/security/■IEEE SECURITY & PRIVACY43 E-VotingMore formallyAcomplete system can be described somewhat more abstractlyand formally, much as a typical cryptographic protocol: interms first of what messages should be exchanged in what order,and then how the parties are to check what they receive. Thereceipt system has two separate phases: a voting phase and a tallyphase.Voting phaseThe voting phase comprises a number of instances, each of whichhas up to six successive steps:1. The prospective voter supplies a ballot image B.2. The system responds by providing two 4-tuples: <Lz, q, Dt, Db>,(“L” is for layer, “q” is for serial number, “D” is for doll, and “z” isfor either “t” for top layer or “b” for bottom layer.) Each 4-tuple isprinted on a separate transparent layer.3. The voter verifies (using the printing’s optical properties) thatLt ≈ L b = B and that the last three components of the 4-tuple areidentical on both layers.4. The voter either aborts, and is assumed to do so if the opticalverification fails, or selects the top layer x = t or the bottom layerx = b.5. The system makes two digital signatures and provides them as2-tuple < sx(q), ox (Lx, q, Dt, Db, sx(q)> (“s” is for seed and “o”is for overall).6. The voter (or a designate) performs a consistency check to ensurethat the digital signatures of the 2-tuple check, using agreed public inverses of the system’s private signature functions sx and ox,with the unsigned version of the corresponding values of the selected 4-tuple (as printed) on the selected layer, and that sx (q)correctly determines Dx and the half of the elements of Lx that itshould determine.More particularly, let the relationships between the elementsof the 4-tuples and the 2-tuple be as follows: The red bits Rz andwhite bits Wz (both m by n/2 where n is even) determine the mby n binary matrices Lz in a way that depends on whether z = t orz = b: Lti,2j–(i mod 2) = Rti,j, Lti,2j–(i+1 mod 2) = Wti,j, Lbi,2j–(i+1bbbmod 2) = R i,j, L i,2j–(i mod 2) = W i,j, where 1 £ i £ m and 1 £ j£ n/2. The ballot image and the paired white bits of the oppositelayer y determine the red bits: Rx ≈ Wy = Bx.The cryptographic pseudo-random sequence functions h andh’ (whose composition yields binary sequences of length mn/2)determine the white bits from the signature on the serial numberas follows: Wzi,j = (dzk ≈ dzk–1 ≈ … ≈ dz1)(mj–m)+i, where dzl ’= h(sz(q),l) and dzl = h’(d’zl). The d’zl also forms the “dolls”using the public-key encryption function el, whose inverse isknown to one of the trustees: Dzl = el(d’zl … e2(d’z2,(e1(d’z1)),where 1 £ l £ k and, for convenience, Dz = Dzk. (Separate h andh’ are for improved efficiency with large ballots.)white sheets correspond, of course, to a ballot’s red andwhite pixels (although without checkerboarding). Theanalog of a lockable wooden doll is public-key encryption, inwhich anyone can encrypt a message using a publishedpublic key, but only the holder of the corresponding private key, the trustee, can decrypt it. Thus any voting machine can in effect be a doll maker and successively formthe layers of a digital doll using published keys, but onlytrustees can strip off the respective layers. (Various knownredundancy and key-sharing techniques provide resiliency in case some trustees don’t participate.) With encryption as the mechanism instead of a videotape, in effect only the code sheet originally held by the output dollmust be released. (It’s easy to check that applying the public key to the combination of this original sheet and theoutput doll results in the input doll.)The initial printout in the voting booth actually usestwo dolls. One of these is checked completely by beingreconstructed from values printed on the last inch of thereceipt layer and then not used further. The other dolland its checkerboard half of the red pixels create a “duo”that travels together through the chain of batches in thetally process. Such duos make up all batches. Trusteesprocess each batch by removing a layer of encryptionfrom the duo’s doll and applying the revealed digital sheetto the duos pixels. By the time the duo reaches the tally44IEEE SECURITY & PRIVACY■JANUARY/FEBRUARY 2004batch, nothing is left of the dolls, and the pixels have become a readable plaintext ballot image.(Dolls that include error correction are printed on thelayers of plastic in a special way. A copy of both such dollsis printed on one layer; on the opposite layer the sameimage appears but with the pixel symbols reversed. Thiscreates a uniform opaque background around the voteswhose absence would be easily noticeable to voters, ensuring that each layer has identical copies of both dolls.)What codes to use?Digital signatures are printed in the barcode on the last inchof the receipt layer. Such signatures have legal standing inmany countries, and are considered irrefutable proof ofthe signed message’s origin. A verifier outside the pollingplace can scan your receipt to immediately check, amongother things, that its signature is valid, that an authorizedvoting station generated it, and that it correctly covers allthe data printed. If the signature doesn’t pass, the physicalreceipt is direct evidence of system failure. If the receiptdoes check, however, it cannot be credibly denied a placein the definitive receipt batch.Cryptographic techniques are classified as either unconditionally secure or computationally secure. The former,like the one-time pad with random key, cannot be broken, even if an adversary were to apply infinite comput- E-VotingTally phase•The tally phase takes its input batch from the outputs of anagreed-on subset of voting instances reaching step 6. For eachsuch instance, only half of Lx and all of Dy are included in thetally input batch, consisting of the duo Bxk = Rx, Dy = Dyk, whichcan be written as Bk, Dk. A series of k mix operations1 transformseach such duo into a corresponding ballot image Bz. The lth mixtransforms each duo Bl, Dl in its input batch into a correspondingBl–1, Dl–1 duo in its lexicographically ordered output batch bydecrypting Dl using its secret decryption key corresponding to el,extracting dl ’ from the resulting plaintext, applying h’, and finallyapplying Bl–1 = dl ≈ Bl. The kth mix performs the same operationon each duo, and because D0 is empty, the result is B0 = Bz.Prior arrangement partitions the k mixes into contiguoussequences of four among a set of k/4 trustees, where k is divisible byfour. For simplicity, assume that the input batch size is also divisibleby four. When the mixing is complete, half the tuples in each batchare selected for opening. The work of Markus Jakobsson, Ari Juels,and Ronald Rivest2 inspired this approach. A random public draw,such as that used for state lotteries, ensures that these choices areindependent and uniformly distributed. The tuples selected foropening depend on the order in each trustee’s four mixes:•In the third, half the tuples pointed to by those opened in the second mix and half the tuples not pointed to are opened.For the fourth mix, as with the second, those tuples not pointed toby the previous mix are opened.A few extensions are worth noting at this point. For improvedprivacy, multiple doll pairs allow separate ballot images percontest and/or question. Error correction can be provided in thespace around the votes. Also, to prevent a voter’s choice of layer,which is revealed to the poll workers, from determining the ballotimage type, and to prevent bias in voter preference for particularlayers, the dolls can determine a mapping between the physicallayers and a pair of symbols that the voter chooses between. Thesymbols are printed before layer selection in a way that hidesthem until after the layers are separated.References1. D. Chaum, “Untraceable Electronic Mail, Return Addresses, and DigitalPseudonyms,” Comm. ACM, vol. 24, no. 2, 1981, pp. 84–88.2. M. Jakobsson, A. Juels, and R.L. Rivest, “Making Mix Nets Robust for Elec-••In the first mix, half of all tuples are opened.In the second, the tuples not pointed to by those opened in the firstmix are opened.ing power. The receipt system uses such unconditionally secure techniques to ensure that integrity is notcompromised except with the probabilities of detectionenforced.Most cryptography used in practice, however, is computationally secure—that is, in principle it is breakable ifenough computing power is applied. No criminal haslikely been able to make such computations using resources available today (because many systems, includinginternational high-value wire transfer, that rely on suchcodes are still in place). Such standard cryptographicbuilding blocks, which are also like those used widely bybrowsers when accessing secure Web sites, are enough(along with addition modulo two) to build the systemsdescribed here.The receipt system uses computationally secure encryption to form the layers, which ultimately encryptthe data in receipts and batches, and thus protect privacy and ballot secrecy. After voting, the codes protecting receipts and posted batches, which are only readilylinkable to ballot numbers and not people (apart fromperhaps the case of provisional ballots), can easily be asgood as those protecting comparable and much moreidentifiable, sensitive, and detailed data traveling onnetworks today.Technical provision of privacy in voting is limited,tronic Voting by Randomized Partial Checking,” Proc. Usenix Security2002, Usenix Assoc. 2002, pp. 339–353; also available as IACR reprint2002/025.however. Because of current surveillance technology,such as sensors like miniature cameras and emanation receivers, as well as memory and transmitters, the confidentiality of what transpires in voting booths cannot in practice be held to any absolute standard. Other limitingfactors include• Most US voter party affiliations are a matter of publicrecord.• The more a device helps a voter the harder it is to keepit from learning who they vote for (although, as in thesystem proposed here, devices need not be able to retaindata between votes).• Even the “gold standard” of voting systems—manualpaper ballots—is subject to marking or ballot numberrecording and automatically captures fingerprints.• Theoretical limits generally force a choice in cryptographic systems between unconditional integrity andunconditional privacy.Thus the system presented here is arguably optimal. Itprotects privacy computationally according to currentbest practices by encrypting votes in receipts and published batches. And it protects the tally’s integrity unconditionally by enforcing sufficient probabilities of detecting tampering.www.computer.org/security/■IEEE SECURITY & PRIVACY45 E-VotingProof sketchesThe properties asserted informally in the text can be abstractedand stated more precisely in terms of the more formaldescription provided (in the sidebar on page 44). Withoutimplying any particular level of rigor, explanations for thesestatements can be illustrated in terms of the familiar format oftheorems and proof sketches.Theorem 1If, for a selected and an unselected 4-tuple from an instance ofstep 2 in the voting process, the selected 4-tuple satisfies the consistency check in step 6 and there is a 2-tuple that would satisfysuch a check with the unselected 4-tuple, the doll of the unselected layer, as printed on the selected layer, is correctly formedand determines all white pixels printed on the unselected layer(relative to which the voter sees the vote in the receipt’s red bits).Proof (sketch): The serial number q and the doll Dy are printedon both layers identically, as the voter verifies in step 3. The dollDy in the unselected layer’s 2-tuple is correctly determined by q,according to the functions sy, h, and e, because the unselected 4tuple would satisfy the consistency check in the hypothetical step6. Similarly, q correctly determines the white bits Wy according tosy, h, and h’ that the voter checks in the hypothetical step 6 asbeing correctly printed on the unselected layer. Because theencryption e is bijective, Dy determines the d’yi, which determinesWy. Thus, the Dy printed on the receipt determines the Wy printedon the unselected layer.Theorem 2Any properly formed, selected layer and its resulting processingreveal the ballot images only in encrypted form until they appearin the tally batch.Proof (sketch): Of the selected layer’s six components <Lx, q,tD , Db, sx(q), ox(Lx, q, Dt, Db, sz (q))>, only the first depends onthe ballot image B. The Lx bits are partitioned among the Rx bitsthat depend on B, and the Wx that don’t. The Wix are eachencrypted by ei and can therefore be ignored. Each Bl, 1 £ l £ k,appears in its respective input batch summed modulo 2 with eachdp, l £ p < k. Thus, each time any B appears in an input batch itappears ≈ed with a distinct pseudorandom value that only appearsin all following sums. The resulting set of linear equations thuscannot be solved for any B.Theorem 3For any trustee’s mixes, a duo’s prescribed opening doesn’t reveala restriction on the correspondence between any individual inputand output.Proof (sketch): It’s easy to see that the restriction imposed by anodd-numbered batch followed by an even-numbered batch—a doubleton of batches—requires that each of the two known halves ofthe inputs results in a respective known half of the outputs. (Note,however, that this could reveal something about an individual inputand output, such as whether the input could correspond to a particular unique output.) A next doubleton that exactly splits eachoutput partition of its predecessor across its own input partitionsenforces the restriction that exactly half the members of an inputpartition are in each output partition, but leaves any particular inputto the two doubletons free to be any particular output.Theorem 4The probability that a trustee that improperly forms u distinct duos inany of its output batches will be detected in at least one duo is 1 – 2–u.Proof (sketch): The random draw selects the duos to beopened in a trustee’s first batch independently of the trustee’scontrol; an opened duo is either correct or not. The probability ofdetection is thus 50 percent for each improperly formed duo in thebatch. Because the opened values are all correct, the half chosenfor the next batch is selected independent of any improperlyformed duo, and so on inductively.his new type of receipt system reduces the cost of integrity while raising its level dramatically and makingits assurance open to all interested parties. Robustness issimilarly more cost-effective and raised to a level where ittoo can be ensured by voters (assuming they can access afunctioning booth) through their receipts. Privacy andsecret-ballot protections can easily meet current bestpractices and are arguably practically optimal. Improvedfunctionality of the system facilitates accessibility andhigher turnout, as well as needed improvements in adjudication. Perhaps most fundamentally, it can do a greatdeal to repair and improve voter confidence.The hardware costs of these systems can be lowerthan current black box systems, which governmentsbuy at many times the price of open-platform PCs. Thecost of suitable printers in volume should be consider-T46IEEE SECURITY & PRIVACY■JANUARY/FEBRUARY 2004ably less than the hardware cost saving. This doesn’teven include savings in maintenance, upgrade flexibility, multiple uses, and reductions in outmoded securityprovisions. In fact, because of the provable integrity,federal dollars could be very well spent sponsoring development of such systems and making them available.The Help America Vote Act is funding the introduction of computers into almost all voting booths in theUS over the next few years, and the systems that are deployed through this unprecedented funding will likelybe in place for a long time. (There is also, for instance, aneffort to automate Latin-American voting using theBrazilian model, which also includes computers in voting booths.) A growing grassroots movement is pushingto allow voters to see a printed summary of their vote,which is retained for possible recount. So far such sum- E-Votingmaries have not been shown to be effective or workablein general and have been replaced in Brazil. This movement does, however, indicate a growing level of publicconcern, and the two printing approaches could evenbe combined. The sad truth, however, is that the processof deciding which types of systems to deploy has so farfor the most part been closed and informed neither byexplicit performance requirements nor generally accepted security practices.The receipt system presented here offers a new levelof integrity, access, robustness, and adjudication, all atlower cost, that make it a compelling way to securepolling-place elections—and it should be the only wayacceptable now.AcknowledgmentsIt is a pleasure to acknowledge Ron Rivest, who served as a superbsounding board for ideas. The “WOTE” workshop was also verystimulating. Later, Jim Dolbear and Lori Weinstein provided a lot ofhelp. Detailed comments from Josh Benaloh, Paul Craft, David Jefferson, Doug Jones, and Andreu Riera, as well as feedback from Je-remy Bryans, Dan Boneh’s group, Stuart Haber, Robert Naegele,Peter Ryan, Marius Schilder, and Adi Shamir were also helpful.References1. M. Naor and A. Shamir, “Visual Cryptography,” Proc.Advances in Cryptology (Eurocrypt 94), A. De Santis, ed.,LNCS 950, Springer-Verlag, 1995, pp. 1–12.2. C.E. Shannon, “Communication Theory of SecrecySystems,” Bell System Technical J., no. 28, 1949, pp.656–715.David Chaum is currently affiliated with several companies, universities, and international projects. Widely recognized as theinventor of electronic cash, he also originated a number of basiccryptographic techniques, general results, and techniques thatallow individuals to protect their identity and related information in interactions with organizations. He has more than 50original technical publications and 25 separate cryptographyrelated patent filings. Chaum has a PhD in computer sciencefrom the University of California, Berkeley. He has taught, led acrypto research group, and founded DigiCash and the International Association for Cryptologic Research (IACR). Contact himat info@chaum.com.PURPOSE The IEEE Computer Society is theworld’s largest association of computing professionals, and is the leading provider of technical information in the field.EXECUTIVE COMMITTEEMEMBERSHIP Members receive the monthly magazine Computer, discounts, and opportunities to serve (all activities are led by volunteermembers). Membership is open to all IEEEmembers, affiliate society members, and othersinterested in the computer field.COMPUTER SOCIETY WEB SITEThe IEEE Computer Society’s Web site, atwww.computer.org, offers information andsamples from the society’s publications and conferences, as well as a broad range of informationabout technical committees, standards, studentactivities, and more.BOARD OF GOVERNORSTerm Expiring 2004: Jean M. Bacon, RicardoBaeza-Yates, Deborah M. Cooper, George V. Cybenko,Haruhisha Ichikawa, Thomas W. Williams, YervantZorianTerm Expiring 2005: Oscar N. Garcia, Mark A.Grant, Michel Israel, Stephen B. Seidman, Kathleen M.Swigger, Makoto Takizawa, Michael R. WilliamsTerm Expiring 2006: Mark Christensen, AlanClements, Annie Combelles, Ann Gates, Susan Mengel, James W. Moore, Bill SchilitNext Board Meeting: 28 Feb. 2004, Savannah, Ga.IEEE OFFICERSPresident: ARTHUR W. WINSTONPresident-Elect: W. CLEON ANDERSONPast President: MICHAEL S. ADLERExecutive Director: DANIEL J. SENESESecretary: MOHAMED EL-HAWARYTreasurer: PEDRO A. RAYVP, Educational Activities: JAMES M. TIENVP, Pub. Services & Products: MICHAEL R. LIGHTNERVP, Regional Activities: MARC T. APTERVP, Standards Association: JAMES T. CARLOVP, Technical Activities: RALPH W. WYNDRUM JR.IEEE Division V Director: GENE H. HOFFNAGLEIEEE Division VIII Director: JAMES D. ISAAKPresident, IEEE-USA: JOHN W. STEADMANCOMPUTER SOCIETY OFFICESHeadquarters Office1730 Massachusetts Ave. NWWashington, DC 20036-1992Phone: +1 202 371 0101Fax: +1 202 728 9614E-mail: hq.ofc@computer.orgPublications Office10662 Los Vaqueros Cir., PO Box 3014Los Alamitos, CA 90720-1314Phone:+1 714 821 8380E-mail: help@computer.orgMembership and Publication Orders:Phone: +1 800 272 6657Fax: +1 714 821 4641E-mail: help@computer.orgAsia/Pacific OfficeWatanabe Building1-4-2 Minami-Aoyama,Minato-kuTokyo107-0062, JapanPhone: +81 3 3408 3118Fax: +81 3 3408 3553E-mail: tokyo.ofc@computer.orgPresident:CARL K. CHANG*Computer Science Dept.Iowa State UniversityAmes, IA 50011-1040Phone: +1 515 294 4377Fax: +1 515 294 0258c.chang@computer.orgPresident-Elect: GERALD L. ENGEL*Past President: STEPHEN L. DIAMOND*VP, Educational Activities: MURALI VARANASI*VP, Electronic Products and Services:LOWELL G. JOHNSON (1ST VP)*VP, Conferences and Tutorials:CHRISTINA SCHOBER*VP, Chapters Activities:RICHARD A. KEMMERER (2ND VP)†VP, Publications: MICHAEL R. WILLIAMS†VP, Standards Activities: JAMES W. MOORE†VP, Technical Activities: YERVANT ZORIAN†Secretary: OSCAR N. GARCIA*Treasurer:RANGACHAR KASTURI†2003–2004 IEEE Division V Director:GENE H. HOFFNAGLE†2003–2004 IEEE Division VIII Director:JAMES D. ISAAK†2004 IEEE Division VIII Director-Elect:STEPHEN L. DIAMOND*Computer Editor in Chief:DORIS L. CARVER†Executive Director: DAVID W. HENNAGE†* voting member of the Board of Governors† nonvoting member of the Board of GovernorsEXECUTIVE STAFFExecutive Director: DAVID W. HENNAGEAssoc. Executive Director: ANNE MARIE KELLYPublisher: ANGELA BURGESSAssistant Publisher: DICK PRICEDirector, Finance & Administration:VIOLET S. DOANDirector, Information Technology & Services:ROBERT CAREManager, Research & Planning: JOHN C. KEATONwww.computer.org/security/■IEEE SECURITY & PRIVACY47
The Spymasters Double-Agent ProblemMultiparty Computation SecureUnconditionally from Minorities andCryptographically from Majorities _David ChaumCentre for Mathematics and Computer ScienceKruislaan 413 1098 SJ AmsterdamSUMMARYA multiparty-computationprotocol allows each of a set of participantssecret input to a mutuallysecurity properties:agreedassumptions:whereauthenticatedincludingofenforcetwoof the output, as defined by the agreed computation.those(a) public-keypairsSuch protocols(1) secrecy of the inputs, apart from what is revealed by theoutput; and (2) correctnessAll solutions,computation.to providepresentedcryptography;participantscanhere, are basedon two kindsofand (b) limited collusion in a settingexchangemessageswithsecretandcontent. Some of the previous solutions relied totally on assumption(a), the others totally on (b).The main result presentedproperties,assumptionhere is a protocol that also provides both security(1) and (2), but that does not rely on either assumption(b) alone -securitycan be violatedonly by violating(a) orbothassumptions.The secondcomputationconstructionimprovesresults based on assumptionthe previouslypublishedmultiparty(b). Let the number of participantsbe n,the largest tolerable number of disrupters be d, and the largest tolerable number ofparticipants in any collusionbe c. (Note that many collusions may exist, even tothe extent that all participantsparticipantsare involved,in any single collusion.)n > 2c. The first inequalitybut c is the maximumThe constructionnumberofrequires n > 2d +c andgives a trade-off between the number of disrupters andthe largest collusion size, which includes the previously achieved case of both lessthan a third. The second inequality,which means that all collusions of minoritiescan be tolerated, is argued to be optimal and makes the main result also optimal.G. Brassard (Ed.): Advances in Cryptology - CRYPT00 Springer-Verlag Berlin Heidelberg 1990‘89, LNCS 435, pp. 591-602,1990. 592A third construction, on which the second is based but which is interesting inits own right, is that of an “all-honest world.” This is a setting, relying only onassumption (b), in which any participant who has revealed secrets to any othercan prove publicly that the secrets revealed are correct and receivable by thesecond participant-even if the second participant denies receipt orcorrectness.1 INFORMAL INTRODUCTIONA spymaster’s deepest fear, it might be said, is that of a “double agent.” If thespymasters of major countries would be willing to pool all the information theyhave on their agents, then they could discover-to their mutual benefit- alldouble agents who play one side off against the other. But for a spymaster,revealing this sensitive data to “the other side” is, of course, unthinkable.A solution to the spymasters’ problem illustrates the main result achievedhere: optimal security for general multiparty computations, given onlycryptography and diplomatic pouches. And since these are the means availableto spymasters, this is the kind of security they require.If only the spymasters could use a physical computer that they all trust.Then they could simply supply their ultra-secret dossiers on each agent as inputto a mutually agreed program that would derive and output the identities of alldouble agents. It is assumed that a suitable program can be agreed on. The onlydifficulty is the computer: How could such a device be physically built andoperated securely? (But see [C].)Spymasters know, from the literature, that the effect of such a mutuallytrusted computer can be achieved merely by exchanging messages. They knowalso that two quite different kinds of protocols have been proposed for this. Themost recent type [CCD & BGW] requires only that each pair of participantsexchange messages in a way that ensures authenticity and secrecy of messagecontent. This the spymasters can readily achieve by diplomatic pouch andcourier. The problem they have with this kind of approach, however, is that if asufficient number of countries collude, these countries can learn all the secretagent profiles of the other countries.The earlier kind of protocol in the literature [ G W 2 & CDG] does not havethis problem; with it, collusion yields no advantage. Its drawback, though, is thatsecrecy relies on public-key cryptography. Thus, if some country were able tobreak the agreed public-key system, its intelligence service could clandestinelylearn all the other countries’ secrets. 593Neither approach alone is optimal and hence acceptable to the spymasters.And simply conducting both kinds of protocol in parallel would be ridiculous, sinceit would give the disadvantages of both-a country breaking the cryptosystemcould discover all other countries’ secrets, and any sufficient collusion could alsolearn the secrets.The new techniques presented here allow the best of both approaches in asingle protocol. No collusion of countries is sufficient to obtain secrets of noncolluders; nor does breaking the cryptosystem yield any information whatsoever.The only way some countries can learn the secrets of others is for a collusion of amajority of countries to break the cryptosystem. 5941.1 EXAMPLE OF THE CONSTRUCTIONThe figure shows a setting with three countries a, b, c. In addition to nationalheadquarters buildings, the countries have embassies located near one another ina neutral zone N. The embassies’ mutual proximity is convenient, since courierswill transfer pouches containing secret messages between them, Headquartersuse only another means of communication, which is also used by the embassies:staff members who write messages on rooftop blackboards. All countries areensured of obtaining the identical message “broadcast” in this way, via their spysatellites.The spymaster of each country Q, b, c has secret input for the computationSO, Sb, S,- respectively. A spymaster (not shown) does not provide these mostsensitive secrets to the embassy or headquarters staff (shown on the rooftops).Instead, spymaster i “Feistels” Si into two parts [F], a random string Ri and thebit-wise exclusive-or sum Ri@Si, and personally delivers the first part to theembassy and the second to headquarters. Notice that this arrangement means,for example, that what is known to the headquarters of country b alone, sb@R&,reveals nothing about Sb; similarly, what is known to b’s embassy, Rb,also givesno clue about Sb.1.2 THE PROTOCOLTo uncover double-agents, both types of protocols for multiparty computationsare u s e d - b u t in a special way. The cryptographic type is performed as a fourparty protocol. Each headquarters is a party to the protocol, and the fourth partyis played by the embassies outputting in unison. This means that the embassies,whenever they are required to do so by the four-party protocol, must all write thesame thing on their blackboards.To decide what to write, the embassies together perform a three-partyprotocol. They do this every time they must write something for the four-partyprotocol; thus, they perform one complete three-party protocol each time thefour-party protocol requires a contribution from them. (Consistency acrossthree-party protocols is ensured by “bit commitments.”) These three-partyprotocols use pouches to provide security that does not depend on cryptography.(To achieve optimal security, as detailed later, they also use the blackboards, butonly while the four-party protocol awaits their decision.)The embassies provide outputs to the four-party protocol that are the sameas would be provided by a single party knowing all of the Ri’S-but the threeparty protocols prevent any embassy from learning more than its Ri. The function 595f computed by the four-party protocol isflRaIRblK,, Ru@Su, Rb@Sb, &@S,) =e(S,, Sb, Sc), where e is the agreed double-agent outputing function and “I!”denotes concatenation. Thus, the computation off by the four-party protocol firstX-ORs out the Ri’S (that it gets as inputs from the embassies) from theheadquarters inputs, and then computes e on the Si..1.3 WHY IS IT SECURE?The cryptographic protocols of [CDG]offer optimal security, in the sense thatthey allow a single designated participant whose secret input is protected withoutany reliance on cryptographic assumptions. This participant is played byconsensus of the embassies, which is itself a protocol that also does not requkecryptographic assumptions. Thus, the sb@Rb, which reveal nothing about the Si,are the only inputs exposed to cryptanalysis. On the other hand, the only protocolvulnerable to collusion is the embassy consensus protocol; but its only inputs arethe Ri, which also reveal nothing about the Si.2. COMBINING CRYPTOGRAPHY AND POUCHESThis section treats the protocol introduced in the previous section more precisely.First it makes the model explicit. Then it describes the protocol, relying on theintroduction of the previous section. Finally, the main result is contained in twotheorems: one for secrecy of the inputs; the other for a topic ignored in theprevious section, correctness of the output.2.1 MODELThe construction is based on two assumptions:(a) Trap-door one-way bijections and “claw-free” functions exist. (Suchassumptions underlie the cryptographic protocol [CDG] and are satisfied bythe w e l k m w n quadratic residuosity assumption [GM].)(b) Less than the specified number of participants collude and each pair ofparticipants can communicate with secrecy and authentication. (Thisassumption underlies the protocols of [CCD]and [BGW]. The channelrequired can be achieved in practice in various ways: by exchanging longkeys in Person and then using a one-time pad and correspondingauthentication coding; by exchanging short keys in person and then using aconventional CVPtosystern; or perhaps even by realizing quantumcryptography w31.) 5962.2 PROTOCOLThe participants in the protocol correspond to the spymasters, of whom there aren. This means that the i’th participant, l l i l n , knows both Si and Ri. Thus, theparticipant is involved in one n+l-party [CDG]protocol and also in a number of n party protocols of the type presented in [CCD] or DGWl or section 3.The computations performed by the protocols are as described in section 1.A technical point only hinted at there, though, is the source of randomness usedby the n -party protocols. The X-OR of unconditionally-privacy-protecting bitcommitments issued initially by all participants can be used as the “random tape,’of the computation playing the role of the n+l’th participant. Participants thenshow, by “blob equality” [BCC],that their input to each protocol round isconsistent with their contributions to the random tape.2.3 PROPERTIESThe protocol has the following two security properties:Theorem 2.1: The secrecy of each participant’s input is protected unless bothassumptions (a) and (b) are violated.Proof: (Sketch) The inputs to either individual protocol by a participant followingprotocol are statistically independent of that participant’s secrets. The output ofthe protocol that relies on assumption (b) only enters the other protocol through apredetermined participant, whose privacy also depends only on (b). Thus, it isnecessary (and sufficient) to violate both (a) and (b) in order to gain informationabout a participant’s secrets, Q.E.D.Theorem 2.2: The correctness of the output is ensured with probabilityexponentially high in a security parameter unless both (a) and (b) are violated.Proof: (Sketch) The [CDG] protocol gives exponential certainty that the f i s t nparticipants cannot cause incorrect output. The n+l’th participant can falsifyoutput, but only by violating assumption (a). For the pouch-based protocolsplaying this n+l ’th participant, the correctness of their contribution is guaranteedwith exponential certainty unless assumption (b) is violated ([BGW] achieve astronger result of not allow even an exponentially small chance of cheating).Thus, violation of both (a) and (b) is necessary to give a non-negligible probabilityof false output. Q.E.D. 5973 IMPROVED POUCH CONSTRUCTIONThe model underlying this section is stated in $3.1. Next, $3.2 describes a “cutand-choose” originally proposed by [Be] for other purposes, and used by [CCD]and [BGW]. Then $3.3 presents the “all-honest world” construction. Finally,$3.4 shows how circuits are simulated, using the essence of the “double-degreepolynomial” trick proposed in both [CCD] and [BGWI.3.1 MODELAs already mentioned, the number of participants is denoted n, the largesttolerable number of disrupters d , and the largest tolerable number of participantsin any single collusion c.Disrupters are defined as participants whose outputs do not follow protocol.Once a participant is agreed to be a disrupter, the protocol can (if necessary) berestarted without that participant (but see $4); this is why disrupters may try tofalsely blame others for sending them improper messages. Violation of p~operty(2), correctness of the result, requires active cheating, and hence disrupters.A collusion, on the other hand, is a set of participants who merely share theirinformation in efforts to learn the secret input of others. Because a collusion couldeven be a secretly conducted instance of the type of protocol described here,each participant could be a member of multiple collusions. It will be sufficient,however, simply to ensure that no collusion has access to information from morethan c participants.The construction requires n > 2d+c and n > 2c. If n = 3, for instance, then d =0, which means that even a single disrupter can falslfy the output; but, since eventhis small II allows c = 1, secrecy of the inputs can be protected unconditionallyagainst any participant acting alone. When n = 4,a single disrupter can betolerated. More generally, c = 1 allows almost half the participants to bedisrupters. At the other end of the trade-off, with d at about a quarter n, any c lessthan half n is possible- This last is optimal; otherwise, disjoint sets of participantscould conduct an arbitrary two-party protocol with both parties protectedis impossible.uncondition~lY--and this, as argued in [CDG],3.2 SET-UP BLOBSIncluded in the muhJdb’ agreed and public protocol definition are: an integer ksuch that Zk > n; an assignment of a distinct point in GF(29 to each participant;and a security parameter s. 598A participant issues a blob by first choosing a polynomial of degree at most C,uniformly over GF(29, with a value at 0 of 1 or 0. Then the issuing participantuses the corresponding pouch to supply every other participant with a share-thevalue of the polynomial at that other participant’s point. When a blob must beopened, every participant broadcasts the share it holds for the blob and the issuerseparately broadcasts what each other participant should output.Every blob used in the remaining protocol is subjected to s challenges byeach participant. Consider a single challenge of a particular participant. First, theissuer creates a new blob, and then the challenger broadcasts a random bit. If thischallenge bit is 0, the new blob is opened (as defined above); if it is 1, eachparticipant computes the sum of the share it held of the original blob with theshare of the new blob, and the resulting sum blob is opened.If the challenger and issuer disagree on the value of the polynomial at thechallenger’s point, the challenger is said to object; further objections can result ifand when the original blob is opened. If more than d participants ever object forany single issuer, then that issuer is clearly indicated as a disrupter (under theassumption of at most d disrupters) and the protocol terminates.Theorem 3.1: If the number of objections for a blob does not exceed d, then it canbe opened both as 1 and 0 with probability at most 2 4 .Proof: (Sketch) With probability 1-24, all non-objecting non-disrupters, ofwhom there are at least c+l, will broadcast shares consistent with a singlepolynomial p . This is a simple consequence of the challenge and responsetechnique. Because each polynomial has degree at most c, it is always completelydetermined by c+l shares. Since d+c+l consistent shares are broadcast duringopening, at least d shares may be called redundant because they are consistentwith p but are not necessary to determine p . For the blob to be opened as both 1and 0, shares would have to be consistent with two distinct polynomials, p and q.If d+c+l shares are consistent with p , then d+l must be changed to be consistentwith 4,since the redundancy means that changing any d or fewer shares leavessufficient shares to determine p . Thus at least d+l shares must be changed, sod+l disrupters are implied. Q.E.D.3.3 THE ALL-HONEST WORLDDuring the protocol proper, pouches will not be used (except possibly forByzantine agreement [LPS] of broadcasts when n 534. Instead, by setting up anall-honest world,” the participants arrange in advance for every bit of messageLL 599that will be sent between them. For each such message bit to be sent in the allhonest world, the parity of the bits in two blobs-neblob issued by eachcommunicant-is made public in advance. There are two cases.In the fust case, the cardinality of the union of the objector sets for the twocommunicants does not exceed d. The intersection of the non-objecting sets forthe two communicants thus contains at least d+c+l participants. Two blobs areissued, one by each of the two communicants, and the sum of the two blob isopened. Such “opening” differs from that for an ordinary blob, since the issuerswill not broadcast the shares they issued. If the shares broadcast by theparticipants in the intersecting set are consistent with a single polynomial having abinary value at zero, then this value at zero is the public parity bit. If no such bit isrecognizable, both blobs are opened separately (which adds at least one memberto one of the two objector sets) and the process is repeated for a new pair ofblobs.In the second case, that cardinality of the union of objector sets exceeds 4there will be c+l participants, called a common set, who will successfully satisfythe first case with each of the pair of communicants. (To see this, notice that thesecond case implies that one of the two communicants is a disrupter-thus, aparticipant involved in such situations with d other participants is recognizable asa disrupter.) Consider, without loss of generality, a particular pair ofcommunicants with a common set and a particular participant in that common set.This common participant will use two blobs satisfying the first case, one witheach of the two communicants. The common participant asks everyone to addtheir shares corresponding to the two blobs, and opens this sum blob to reveal theparity of the contents of the two original blobs. The channel parity bit is theneasily computed as an X-ORof all such bits made public by the common set.To send a bit in the all-honest world once all the parity bits have beenestablished, the sender simply makes public the actual message bit X-ORed withthe sender’s contribution to the parity bit. Then the sender can prove thecorrectness of the bit sent by using the sender’s other blobs in a generalsatisfiability protocol, like that of [BCC] or [GMWl]. The secrecy of thetransmission is ensured because at least c+l other participants must collude torecover the secret contents of all blobs used in establishing the parity bit. Thereceiver can also use the bits received in proofs related to subsequent outputs,since these bits can be expressed as sums involving only public bits and thecontent of the recipient’s own blobs. 6003.4 THE PROTOCOL PROPERThe actual secret input of participants to the computation itself will be committedto by blobs issued in the all-honest world. When a share is sent in such a blobissuing, the sender proves that the correct value of the share has been sent, andthat it is receivable, based on the public parity bits. The blobs used in this proofare all from the initial set-up phase and include blobs committing to the “randomtape” that detennines the choice of polynomials.When two bits in the circuit simulated by the computation (either actualsecret inputs or intermediate values) are to be X-ORed, each participant adds theshare they hold for each of the bits, which yields their share for the new bit.When two bits are to be ANDed, each participant first multiplies the twoshares held, yielding a share of a “double degree” blob having maximal degree 2c.Then the resulting share is added to a share from n new “double-degree” blobs,one issued in the all-honest world by each participant. This sum double-degreeblob is then “opened” in the all-honest world; each participant opens its part of theparity bits involved. A second blob is also issued in the all-honest world by eachparticipant; it is shown to be properly formed and to contain the same bit as thecorresponding double-degree blob issued by that participant. The result of theAND-gate is then formed by each participant as the X-ORof all second blobs, orthe inverse of this, depending on whether the double-degree blob opened contains0 or 1, respectively.4 RELEASE OF RESULTSIssuing an actual secret input as a blob in the all-honest world costs the issuer bycreating exposure to collusion. To spread such exposure evenly, participants canreciprocally commit to more and more information about their secret inputs in a“gradual commit,” which is essentially the inverse of the “release of secrets”notion surveyed in [BCDG].After the gradual commit, participants could still be robbed of the benefit oftheir new exposure if the computation were not completed. Any participant canstop the all-honest-world computation, but not without being recognized by theothers as having done so. Even if 2d participants stop, however, the c+lremaining ones can input all the shares they received in the all-honest world to anew protocol with a reduced n (and, consequently, possibly a reduced c). Thisnew protocol-which has information already proven correct and sufficient todetermine all the original secret inputs-computes the same result as the originalComputation would have. 601CONCLUSIONSome earlier results are extended, improved, and generalized here; and twopreviously unlinked but fundamental sets of results are unified.ACKNOWLEDGEMENTSIt is a pleasure to acknowledge all the discussion with my coauthors ClaudeCrkpeau and Ivan Damghd on our joint work [CCD] that laid a foundation forsection 3. It is also a pleasure to thank Jurjen Bos for his help in simplifying andimproving the presentation. 602REFERENCESBennett and Brassard: An update on quantum cryptography. ProcCrypto 84, pp. 474430.Brassard, Chaum and CrCpeau: Minimum disclosure proofs ofknowledge. JCSS October 1988, pp. 156-189.Brickel, Chaum, Damgbd and van de Graaf: Gradual and verifiablerelease of a secret. Roc. Crypto 87, pp. 156-166.Benaloh: Secret sharing homomorphisms: keeping shares of a secretsecret. Proc. Crypto 86, pp. 251-260.Ben-Or, Goldwasser and Wigderson: Completeness theorems fornon-cryptographic fault-tolerant distributed computation. Proc. STOC88.Chaum: Computer systems established, maintained, and trusted bymutually suspicious groups. Memorandum UCB/ERL M79/10, U.C.Berkeley, February 22, 1979Chaum, CrCpeau and DamgArd: Multiparty unconditionally secureprotocols. Proc. STOC 88. (To appear in JCSS.)Chaum, Damgbd and van de Graaf: Multiparty computationsensuring privacy of each party’s input and correctness of the result.ROC.Crypt0 87, pp. 87-1 19.Feistel: Cryptographic coding for data-bank privacy. RC 2827, IBMResearch, Yorktown Heights, March 1970.Goldwasser and Micali: Probabilistic encryption. JCSS, April 1984,pp. 270-299.Goldreich, Micali and Wigderson: Proofs that yield nothing but theirvalidity and a methodology of cryptographic protocol design. Proc. ofFOCS 86, pp. 174-187.Goldreich, Micali and Wigderson: How to play any mental game, Roc.of STOC 87.Goldreich and Vainish: How to play any mental game: an efficiencyimprovement. Proc. Crypto 87, pp. 73-86.Lamport, Shostak and Pease: The Byzantine generals problem. ACMtrans. h o g . Languages and Systems, 1982, pp. 382401.
A number of organizations who do not trust one another can build and maintain a highly-secured computer system that they can all trust (if they can agree on a workable design). A variety of examples from both the public and private sector illustrate the need for these systems. Cryptographic techniques make such systems practical, by allowing stored and communicated data to be protected while only a small mechanism, called a vault, need be physically secured. Once a vault has been inspected and sealed, any attempt to open it will cause it to destroy its own information content, rendering the attack useless. A decision by a group of trustees can allow such a vault-or even a physically destroyed vault -to be re-established safely. Networks of vaults can allow reliable operation even in the face of communication channel and vault failures . Networks also have several security advantages over single vault systems: (1) information that is no longer needed can be permanently destroyed, (2) comprehensive records of security relevant actions by the trustees can be maintained, and (3) abuse of the trustees' power requires advance notice. Algorithms which implement such a network are presented in a specially adapted formal specification language; examples of the algorithms' use are given; analysis of communication, memory and time requirements are presented; and security and reliability properties are proved. Each of some mutually suspicious groups can supply part of a vault, in such a way that each group need only trust its part in order to be able to trust the entire vault. Another approach to construction is based on public selection of a system's component parts at random from a large store of equivalent parts. The practicality and ramifications of the ideas presented are also considered.
The time spent discussing the material in this dissertation with Bernard Mon-Reyaud was extremely enjoyable, and lead to the development of an excellent friendship. Similarly, the time spent with Eugene Lawler, resulting from his participation in the thesis process was also quite enjoyable, and included many pleasant sessions during which, among other things, I received his counsel on the academic life in general and also on quite a range of particulars. Carlo Se'quin and I had many stimulating discussions, mostly before and as a result of my masters thesis work, though he did contribute to the present work in a variety of ways, including participation in the qualifying exam. Bob Fabry and I worked together for well over a year, and his support during that time exceptional. Whit Diffie has contributed to the present work through numerous lengthy and extremely valuable discussions. A few of my peers at Berkeley also contributed in no small way-interacting with them fulfilled ones expectations about how such relationships make gradschool: David Chin, Jim Demmel, Robert Hyrele, Peter Kessler, Keith Sklower, and Tim Winkler. This work started one summer, during which I spent a great deal of time with Doug Cooper. He helped me overcome a fear of writing. Manuel Blum was also around a lot that summer, and he and I talked. He maintained that one should never try to predict the effects of ones actions on society. It was the rejection of this principle which lead to the present work.
1 Chapter I Introduction §1 Problem Statement & Motivation This section defines the increasingly important problem of providing computer systems that can be trusted by groups who don't necessarily trust one another. Example applications motivate the need for solutions and illustrate the nature of the solutions proposed Concern over the trustworthiness of computer systems is growing as the use of computers becomes more pervasive. It is not enough that the organization maintaining a computer system trusts it; many individuals and organizations may need to trust a particular computer system. For example, consider a computer that maintains the checking account balances of a bank. The bank is concerned, among other things, about possible loss of balance records. The Federal Reserve Bank must know the total of these balances, to ensure that the legally required percentage of the balances is on deposit with it. The Internal Revenue Service requires the ability to check the balance of an individual's account. Individuals, or a consumer organization acting on their behalf, may wish to ensure that disclosures are made known to those involved, and that inquiries can never be made on information that is more than a few years old. There are many other similar applications of computers which involve private sector records related to consumers, such as those arising from credit, insurance, health care, and employment relationships. Public sector record keeping, in such areas as tax, social security, education, and military service are also quite similar. Another class of applications involves information about public or private sector organizations as opposed to information about individuals. For example, various international agencies, such as the International Atomic Energy Agency, must be able to ensure the secrecy of the member nations. in~ormation they receive from their Numerous industry organizations develop statistics from confidential information submitted to them by their member corporations. Brokers and other middlemen in the mailing list industry must be able to a ensure the confidentiality of the lists they receive from a variety of list compiling organizations for purposes of removal of duplications or various kinds of prescreening. All of these applications involve one group who owns or controls the computer system, and who is particularly concerned with reliably maintaining the operation of the system and with ensuring the survival of the data maintained by the system-they will be called the "trustees." A second group or set of groups are primarily concerned about the confidentiality of the data which relates to them that is available to the system. There may be a third group or set of groups, which may overlap with the first and second groups, who are concerned about the correctness of the operation of the system. Of course, many applications of computer systems used solely within large organizations have a similar flavor, because such organizations are often composed of groups or individuals with conflicting interests. 3 §2 Overview & Chapter Summaries The basic idea of the proposed systems is introduced and the organization of the thesis is presented as a guide to the reader. This thesis otiers a system design and feasibility argument for computer systems which can be established, maintained and trusted by mutually suspicious groups. Such systems can be used to meet the requirements of applications like those mentioned in the previous section, if a workable design can be agreed on by the participants. The cryptographic techniques which form the basis of the approach are introduced in the next chapter, Chapter II. They make such systems practical by reducing the mechanism upon which reliability and security depend. This mechanism-the processor and its high-speed store-will be called a vault. Vaults will be constructed in a way that can be verified by all the participants, or by any interested party, and then they will be physically secured, such as by being shielded within a small safe-like container. In addition to introducing the cryptographic techniques, and presenting the relationship of the present work to the literature, Chapter II also surveys the varied literature which lends support to the practicality of the ideas presented: applications of cryptography; design and verification of security properties; securing apparatus from tampering and probing; and survivability of equipment, data and cc,>mmunication. Chapter III abstracts from the techniques of Chapter II the assumptions which form the basis of the proofs contained in a later chapter. At the same time, Chapter II also presents some important underlying assumptions which, although they do not enter directly into the proofs, influence the nature of the proposed systems. Chapter IV introduces a system based on a single vault. This serves the dual purpose of introducing a number of concepts used in the proposed multiple vault systems, and pointing out a number of shortcomings of single vault systems which are solved by the systems to be proposed. The algorithms which define the operation of the multiple vault systems to be proposed are presented in Chapter V, using a specially adapted formal specification language. Then Chapter V1 provides an example of the use of the algorithms, which demonstrates how a multiple vault system can be established. Proofs of various security and reliability properties are presented in Chapter VII, which make use of the assumptions of Chapter III. Analysis of the performance issues of space, communication, and time requirements of systems based on the algorithms of Chapter V is presented in Chapter Vlll. Chapter IX presents techniques for constructing and placing into operation a secured vault, while maintaining the trust of potentially mutually suspicious groups. The final chapter, Chapter X, briefly considers work remaining and the implications of the present work. Before delving into the supporting literature, however, it is important to indicate some of the unique contributions of the present work. §3 What's SoN ew About All This? Suggested are the novelty and advantages of the present work over other work known to the author. This thesis addresses the problem of establishing and maintaining computer systems that can be trusted by those who don't necessarily trust one another. This particular formulation of the problem is believed to be a contribution in its own right. In addition, the present work combines an unusually wide diversity of security technologies. The tecl).niques presented for allowing construction of apparatus which can be trusted by mutually suspicious groups also appear to be new. The detailed algorithms presented are the result of several major iterations, and are believed to take into account most of the important issues. The use of cryptography is central to many of the algorithms and is quite a bit more 5 complex than that reported elsewhere. This motivated substantial extension of a previously defined specification language in order to integrate a variety of cryptographic techniques into the type-checking and parameter-passing mechanisms in a convenient way. Also, a new general problem for computer network security, "the covert partitioning problem," is introduced along with algorithms which provide a solution and proofs of their correctness.
Chapter II Survey of the Literature Considered is some of the literature which lends support to the feasibility argument of the present work, and some related work. This thesis puts forward a proposal for a new kind of highly secure computer system. The technologies upon which these systems must be based are quite diverse and cut across some traditional boundaries. Nevertheless, an attempt will be made to indicate the feasibility of the proposed systems by pointing to relevant surveys or directly into the literature. § 1 Cryptographic Algorithms The various types of cryptographic algorithms used in the present work are discussed with reference to the relevant literature. Information is encrypted to allow it to pass safely through a potentially hostile environment. Conventional Cryptography Secrecy. Traditionally, concern confidentiality of message content. has centered on providing the Consequently, cryptographic techniques were devised to make it very difficult (in some cases impossible) to transform encrypted information back to its unencrypted form without possession of a secret piece of information, called a key. Two correspondents who were the sole possessors of a key could use it to maintain the secrecy of the message content of their correspondences. Note that the cryptographic algorithms themselves are assumed to be public knowledge; only the key need be kept secret. Ultimately, all cryptographic algorithms can be thought of as transforming symbols into other symbols. With a Captain Midnight decoder badge, the badge is the key, and letters are mapped into other letters. The un-breakable Vernam cipher maps only single bits into other bits, by adding each bit modulo two with a different key bit [Kahn 67]. On the other extreme, block cryptographic algorithms map large strings of bits, called blocks, into other blocks. The National Data Encryption Standard, for example, maps 64 bit blocks into 64 bit blocks, using a 56 bit key [NBS 77] . Many blocks can be "chained" together during encryption, effectively forming a single large block [Feistel 70]. Authentication. The present work assumes the use of block schemes, like the Data Encryption Standard, which make it very difficult to modify part of an encrypted block of information without causing drastic changes to the entire decrypted block. A large serial number can be appended to a block before encryption; its presence after decryption provides authentication of the block as a valid block that has not been altered. In such systems, it becomes extremely difficult for someone without a key to create a block that will contain a desired serial number when it is decrypted by a keyholder. Two communicants with a common key can converse using encrypted blocks of data, checking the serial number of each received block to ensure that it has arrived in the proper sequence, and to ensure that it has not been altered [Feistel, Notz and Smith 75]. Public Key Cryptography The cryptographic techniques considered so far have the unfortunate property that a common key must be distributed to the communicants, while it is kept secret from everyone else. In contrast, consider a fundamentally different sort of cryptographic algorithm independently proposed by Diffie and Hellman [76], and Merkle [78]. To use these algorithms, each participant creates a private key, that is never revealed to anyone else. Only a suitably related public key is made known to everyone. Here we will be concerned with public key cryptographic algorithms (like that of Rivest, Shamir and Adleman [78]) where the two keys are inverses of one another, in the sense that a block encrypted with one can be decrypted only with the other. Sealing. Public key cryptography can be used to provide the secrecy of message content. A confidential message can safely be sent if it is first seal~d. an operation which includes encryption with the recipient's public key. Only the intended recipient can decrypt the received message -because the corresponding private key must be used to decrypt it. A large random number is joined to the message during sealing, to counter two potential threats: (1) if the same message is sent more than once, such a message will be revealed as such to an eavesdropper; (2) an eavesdropper's guess of the message could be verified by encrypting the guess with the public key and then checking if the resulting bits are identical to the sealed message. Signing . Authentication in public key cryptosystems is much more useful than that provided by conventional cryptography, because only a public key is 9 needed to authenticate a message, and hence anyone, not just the holder of a secret key, can check the authenticity of messages. Someone signs a message by encrypting it with their own private key. If a serial number of some agreed upon structure, such as all zeros for example, is joined to the message during signing, then its presence after decryption with the corresponding public key authenticates the signature. Compression Functions The so called "one-way" functions were introduced by Purdy [74] as part of the now familiar method of protecting passwords stored in computer systems. The one-way function and the image of all the passwords under the function are publicly readable, but they must be protected from alteration. Thus, the ideal one-way function is easily computed, but the inverse is computationally infeasible. For the present work, a compression function will be a special kind of oneway function which maps an arbitrarily large domain into a fixed range, but which is practically impossible to invert. Such functions are quite handy since they in effect allow a relatively small number of signed bits to authenticate a large number of bits. Similar concepts have been described by various authors. {see Feistel [70] or Needham and Schroeder [78] for example.) Key Generation The automated generation of true physical random numbers has received some attention in the literature {see Knuth [7] for example). Sampling the noise generated by specially fabricated noise diodes seems to be an excellent source of raw bits (thermal noise and radioactive decay also seem good, but more cumbersome), which must then be corrected for bias in the detector. 10 Techniques for perfect correction of independent events with a fixed-bias detector are widely known. (Notice, however, that detector drift and physicl dependencies in the source contribute to less than perfectly independent raw bits.) The simplest such technique takes as input successive pairs of independent bits and outputs say a 1 bit for pairs of the form 1 0, outputs a 0 bit for pairs of the form 0 1, and produces no output for the other possible pairs 1 1 and 0 0 [Von Neuman 51; Gill 72]. It is also possible to combine many random numbers of some less than optimal entropy to produce a single number of increased entropy, such as by adding many numbers bit-wise modulo-two. While details are beyond the scope of the present work, it is important to notice that many cryptographic algorithms may be quite weak for some choices of key. Care must be taken to determine if a candidate key is such a weak key and to randomly create another candidate in such a case. §2 Applications of Cryptography Discussed are some or the relatively few publications which assume good cryptographic algorithms and go on to consider applications. Many kinds of security rely on the secrecy of their techniques. In contrast, much of the open literature on cryptography owes its existence to the premise that such secrecy may not be necessary or even desirable with cryptographic techniques. Shannon [ 49] assumes that the cryptographic algorithm is known to the "enemy" and only the key is secret. Kerckhoffs [ 1883] made a similar assumption. Baran [64] provides convincing arguments for making public the details of what he calls "cryptographic design" which includes the "hardware details". There has been much work that considers the use of encryption for communications security and data security. The remainder of this section mentions some of the more relevant work in these areas . Work with a heavy emphasis on 11 the cryptographic algorithms themselves has been omitted, however, since this thesis is not concerned with particular cryptographic algorithms. Communications security Protocols that provide secrecy and authentication of communication between two devices using conventional cryptography are relatively straightforward and have been touched on by many authors, among them are Feistel, Notz, and Smith [75] and Kent [76]. Public key protocols for this kind of communication are similar to those based on conventional cryptography [Needham and Schroeder 78]. Key distribution . With conventional cryptography, the channel used to originally transmit the key from one participant to the other must provide both secrecy and authentication. Also, O(nZ) keys can be required when n participants wish to converse amongst themselves using conventional cryptography. Heinrich and Kaufman [76] and Branstad [75] described an approach to distributing these keys that uses a central trusted device. (The techniques of the present work would be ideal if such an approach were to be used in an appUcation with mutually suspicious participants.) Needham and Schroeder [78] describe both a centralized scheme and one in which the participants each use a trusted loc·a l device, all local devices having cryptographically secured communication amongst themselves. Diffie and Hellman [76] describe a scheme (devised with the collaboration of Lamport) which can only be corrupted by compromise of all of some fixed set of trusted devices. The key distribution problem was at least part of the impetus for the two independent proposals of public key cryptography (Merkel [78] and Diffie and Hellman [76]). Only O(n) keys are required by systems of the kind proposed by Ditiie and Hellman. The key distribution problem is further simplified because 12 neither kind of system requires keys to be kept secret during distribution-only their authenticity must be ensured. Traffic Analysis. The problem of keeping confidential who converses with whom, when and how much they converse, will become increasingly important with the growth of electronic mail. The problem of keeping an adversary from learning anything about the timing, amount or routing of messages in a communication system has been called the "traffic analysis problem." Baran [64] has solved the traffic analysis problem for networks using conventional cryptography, but his approach requires each participant to trust a common authority. In contrast, a system based on public key cryptography [Chaum 81], can be compromised only by subversion or conspiracy of all of a set of authorities. In the limiting case, each participant can be an authority. The last approach allows one correspondent to remain anonymous to a second, while allowing the second to respond via an untraceable return address. This permits rosters of untraceable digital pseudonyms to be formed from selected applications. Applicants retain the exclusive ability to make digital signatures corresponding to their pseudonyms. Elections in which any interested party can verify that the ballots have been properly counted are possible if anonymously mailed ballots are signed with pseudonyms from a roster of registered voters. Another use allows an individual to correspond with a recordkeeping organization under a unique pseudonym which appears in a roster. of acceptable clients. Data Security Conventional cryptography has received some consideration as a technique , for protecting stored information. The use of encryption to protect objects within operating systems, first suggested by Peterson and Turn [67], suffers 13 from the problem of key management. One might argue that whatever techniques were applied to protect the keys, might have been applied to the data itself, thus eliminating the need for encryption. But advantage can be taken of the small, fixed-size of the keys. The use of cryptographic techniques to protect data stored in a potentially hostile environment are relevant to the present work. There are three important considerations for protecting stored data, each corresponding to one of the issues of secrecy, authentication, and traffic analysis in the context of communication. First, if the same data is stored more than once under the same key, then some non-repeating data, such as the random serial number used in sealing, must be included in the data lest the repdition be revealed. Second, it may not be sufficient to be able to authenticate the memory location associated with a page received from storage if data has been stored at that location more than once; a solution to this, the "most recentness" problem, must be provided so that the page can be authenticated as the last copy written. (Solutions to this problem which also solve the first problem are presented in the work of Bayer and Metzger [76] mentioned below.) Finally, the pattern of read and write accesses must be considered as a possible source of information to an adversary. A most general solution to this last problem, which makes no assumptions about the application program, might be to alternately read every stored location ever written and then to perform a fixed number of writes. Clearly this is not an attractive solution, and much more reasonable solutions, possibly including the introduction of some bogus requests, can be developed by careful design of the application program. An interesting technique has been developed for encrypting information which is divided into pages. A different key is used to encrypt each page. The key used for a particular page is produced by encrypting the address of the page using a master key. Mapped addresses (so that addresses can be changed 14 for new versions of a page) and physical addresses are considered by Bayer and Metzger [76]. Content addresses have been dealt with by Gudes, Koch, and Stahl [70]; and by Flynn and Campasano [78]. Some simple systems have actually been built that encrypt data at a secure site before transmitting it to an un-secured data base management system [Notz and Smith 72; Carson, Summers and Welch 77]. The terminals or their users are presumably the only holders of the keys so that only they can access the data. §3 Partial Key Techniques Various solutions to the problem of dividing a key, or other secret information, between individuals or other entities are presented. Feistel [70] describes schemes in which a cryptographic key is divided into n parts, each part is given to a different person, and the original key can be recreated by combining all n parts. These schemes use random bits for each part except the last, which is chosen so that the desired key is the bit-wise modulotwo sum of this last part and the rest of the parts. A disadvantage of such schemes is that if just one part is lost, then the original key can not be recreated. The technical report on which this thesis is based (Chaum [79]) introduced a scheme for dividing a key into parts, called prtrtial keys, in which some selected subsets of the partial keys are sufficient to re-create the original key. The approach used was based on multiple encryption. Independently, and at about the same time, Blakley [79] and Shamir [79] published more elegant schemes which do not have the inherent flexibility of the multiple encryption schemes, but can use less space and run faster for large n when the required sets are all possible sets with cardinality greater than some fixed number. These techniques are unbreakable as is the Vernam cipher mentioned earlier, 15 and the Vernam cipher has even been called a degenerate case of these techniques [Blakley 80]. Further work by Azmuth and Bloom [80] includes means for determining which if any partial keys submitted for a re-creation are bogus. §4 Computer Security The field of computer security is divided into four areas, and each is dealt with in a separate subsection. Computer security is the topic of several journals, several annual conferences, dozens of books, thousands of articles in the technical literature, and many more pieces in the popular press. It is far beyond the scope of the present work to try to survey this vast literatt:re. For the purposes of this section, the field of computer security is divided into four broad groups of concerns: (1) issues related to personnel and their access to facilities; (2) design of desired security properties; (3) verification of implementation of the desired security properties; (4) physical security of equipment against probing and modification. Survivability issues are covered in the next section. Personnel Discussion of personnel issues are liberally sprinkled throughout the computer security literature, particularly that aimed at the practitioner. From the technical point of view, the major issues with respect to personnel are how to reduce the exposure to personnel, and then how to force conspiracies of persons for what exposure remains. Essentially two ways to force conspiracy are used. The most desirable mechanisms are those which can force equally knowledge- able persons to conspire. For example, the so called "two man rule," used for control of nuclear weapons, may require that two keys located at substantial distance from one another be turned simultaneously. A somewhat less appealing but much more widely used approach is to attempt to limit the knowledge of individuals to such narrow aspects of a system that they must conspire with others in order to have the knowledge and skills required to compromise the system (see [FDIC 77] for example). Since the present proposal uses equipment which is essentially inaccessible to perso!'lnel, and techniques which are a generalization and extension of the two man rule, many of the personnel issues are not particularly relevant. Other questions raised in this literature include: How can trustworthy personnel be selected? What sort of "access control" mechanisms are appropriate for controlling the movements of people into and within a facility? What is the best way to motivate compliance with security relevant rules? and How can the user interface of the security mechanism best be designed so as not to encourage bypassing by the user? In any system in which personnel must be trusted, the possibility always exists of influence by positive means such as bribery, negative means such as blackmail, and the combination. Also, one can never be sure that a person's behavior will remain uniform. For example, stress in personal life, breakdown, suggestion and drugs can cause substantial changes in behavior. Protection In some dedicated applications, such as some of those mentioned earlier for which the present work may be particularly well suited, answers to the question Who can make what kind of accesses to what data? may be quite obvious and simple. In more general purpose systems, such as operating systems and data- 17 base management systems, it may be difficult to decide on a way to describe the kinds of accesses allowed. There may be various design objectives, such as, closeness of fit to anticipated application requirements, ease of user understanding, implementation efficiency, appropriate default rights, congruence with user motivation, and convenience of use. For operating systems, the proposed access control models are often divided between the "access control matrix" approaches [Lampson 74], and the "information fiow" approaches [Denning 76]. In the access control model, a matrix contains the type of access allowed by each of a set of subjects to each of a set of objects. Data fiow is a generalization of the U.S. classification scheme, which was based on the British scheme, where information is allowed to fiow up to higher classifications but not down to lower classifications. Recently, Stoughton [81] has proposed a synthesis of the two approaches. In database management systems, the protection structures proposed may be divided between the access control style and the value dependent. An interesting approach called query modification has been suggested [Stonebraker 75], in which additional restrictions are automatically appended to each query before it can be processed. The general case is further complicated because provisions must be made which allow access rights to be changed and even for the rights related to who can change access rights to themselves be changed. Much theoretical work, such as that of Harrison, Ruzzo & Ullman [76], demonstrates that it may not be practical to determine who ultimately may access what, even with rather limited kinds of transfer rights. In general, when preventive means are not available, it may still be possible to preserve a record which reveals abuses. Thus, various "logging" or "audit trail" techniques have been proposed, such as those of Weissman [69]. 18 Verification ln the present context, verification is intended to mean the process of developing certainty that some formally described mechanism has some desired properties; the term certification is used here to mean that some physical mechanism "conforms" to the formal description. This subsection points into the relevent literature on verification; little has been found in the literature on certification (but see Weisman [69]), a topic which is covered in Chapter IX. The field of program verification was given a formal foundation by Floyd [67]. He defined a program to be "partially correct" (with respect to some input and output assertions) if the truth of the input assertions before program execution guarantees the truth of the output assertions after program termination. (A "totally correct" program was a partially correct. program whose execution is guaranteed to terminate.) He gave a method based on inductive assertions for determining partial correctness of programs. Proof techniques for parallel programs have also appeared (see Ovd.cki and Gries [76] for example). Proving properties about cryptographic protocols is also receiving attention (see Dolev and Yao [81] for example). A variety of automated specification and verification systems have been developed and are extensively used for security work (see Cheheyl et al [81] for a recent s·urvey). In such systems, formal specification languages are used to define the intended function of a module, while omitting as much implementation detail as possible (see Rammamoorthy and So [81] for a survey). For example, the HDM (Hierarchical Design Methodology) [Robinson and Levit 77; Levitt, Robinson and Silverberg 79] uses the specification language presented by Parnas [72] to describe systems as a hierarchy of abstract machines. (The Parnas specification language is extended in Chapter V and used to present the algorithms proposed here.) Global and local security properties of programs executing on multiple processors, and employing cryptographic techniques, of much 19 the same order of complexity as those algorithms presented in Chapter V have recently been verified [Good et al 82]. §5 Physical Security The little open literature ~n protecting equipment from probing and modification is considered. Shielding techniques for protecting mechanisms against analysis of their radiated signal energy, or probing by externally supplied energy, seem to be rather well understood, and are covered by the classified TEMPEST specifications. Tamper-sating systems can be divided between those which merely indicate tampering to an inspector, and those systems which can detect tampering and can respond by, for example, destroying some secret information. In some cases it may be desirable to augment a tamper-responding system with tamper- indicating techniques and periodic inspections. (See the next chapter for more on combinations.) There is a small amount of unclassified literature on tamperindicating techniques [Poli 78], but almost nothing on high level tamperresponding techniques-but see Chaum [82]. One approach to the problems of TEMPEST and tamper-sating includes placing apparatus to be protected in relatively inaccessible locations. For example, satellites or satellite platforms may provide an ideal location because it becomes very difficult to surreptitiously compromise equipment in such a visible and inaccessible location, or to get close enough to obtain an acceptable signal to noise ratio from even moderately well shielded equipment. (Such locations may also be quite attractive because of the kinds of communication channel typically provided by satellites, as mentioned later.) Another location which has great potential, and has actually been used for protecting apparatus (see Sandia [81] for example), is the bottom of well holes 20 in rock formations. Seismic sensors do a good job of detecting attempts to come even moderately close to the protected apparatus. Installations in office building environments are also possible. While it is beyond the scope of the present work to discuss the various possibilities for solving these problems in less remote locations, it may suffice to point out that tamper safing and shielding have obvious importance in intelligence and military systems, and one can safely assume that these problems have been adequately solved for these applications. Thus, it appears that the physical security requirements of the applications considered earlier are quite reasonable. §6 Survivability This section surveys the issues in survivable systems, which include barriers or hardening, redundant communication, redundant storage, and reliable mechanisms. As in the previous section, the requirements of the kinds of applications considered will appear quite practical based on the following discussion. Barriers The problem of providing substantial resource requirements and delays to would be penetrators has been referred to as the barriers problem in the nuclear safeguards literature [Sandia 78]. Acceptable barriers for some applications can be provided by concrete and steel structures, but more sophisticated barriers are constantly under development by the manufacturers of better safes and vaults. Such developments are rarely published and are only alluded to in sales literature. Unfortunately, the so called "shaped charge" can almost instantly penetrate any barrier of reasonable thickness. But, quite satisfactory barriers can be provided by placing equipment to be protected in inaccessible 21 locations, such as the well holes described in the previous section. Reliable Equipment Largely because of developments in space and aviation, computer systems and related equipment have been developed which use redundant mechanism to achieve extremely high reliability. (See Randell et al [78] for a relatively recent survey.) Some of these advances are already enjoying widespread use in earthbound business transaction processing systems, and are likely to become increasingly more widespread because of trends such as decreasing hardware costs and increased dependency on real-time systems. Thus, for the sorts of applications the present work is directed at, highly reliable systems may be rather common. Survivability of Data One very nice thing about safely encrypted data is that a proliferation of copies does not pose any additional threat to security, but it has great potential for increased survivability. Multiple copies of encrypted data can exist at a variety of sites, some of which may be hardened. Also, when broadcast style communication channels are used, locations which are maintaining copies of data may not even be known to the issuer of the data, and might therefore be extremely difficult for an adversary to even detect. Today, several companies provide secure data storage sites for magnetic recording media. Some of the facilities are located deep within mountains while another is in an abandoned telephone switching center which was hardened to withstand a several megaton blast. 22 Survivability of Communication The ability to communicate in spite of an adversary is of obvious imporlance for military applications. The use of redundant and alternate channels is one standard approach to the problem [Frank & Frisch 70]. Other more effective approaches are under development and in use, however, they receive little coverage in the literature. One important approach is the use of cryptographically controlled "spread spectrum" radio techniques, which provide a broadcast signal which is nearly impossible to jam [Haakinson 78]. Also highly redundant error correcting codes can greatly increase the survivability of transmissions in a noisy environment. §7 Related Work A few extended citations give credit to some relevant earlier work. It seems appropriate to include this section to put the present work in perspective with some proposals of others addressed at similar problems. Feistel might be called the father of modern conventional public cryptography. His plan and motivation for non-military use of cryptography comes through in the first part of his introduction to "Cryptographic Coding for DataBank Privacy," which is excerpted below. This document remained classified "IBM CONFIDENTIAL" for a couple of years after it originally be came a "Research Report" in 1970. A Data Bank is essentially a machine to machine communications network in which input terminals are connected to a centrally located computer, the physically secured CPU. The most outstanding feature of the kind of network structure we are talking about is that it must function reliably in a hostile environment. Secrecy in the usual sense, that is concealment of the meaning of the messages 23 conveyed, would form the basic element of protection. This is required to insure the privacy of those forming the data bank community. But machine communications systems, in conlrast to systems which can enlist the subtle filtering capabilities of the human brain are very sensitive to interference and deception. Without special protection computers are easily fooled and this can become an intolerable burden to a data bank operation if this remains unnoticed. Both accidental and intentionally designed errors must be detected with very large safety margins. A machine to machine communications network requires a properly secured method which assures the receiver that all incoming communications are of legitimate origin and uncorrupted. In military systems such methods are called authentication. We shall present a method called centralized verification. In contrast to militar;-y systems, where all participants have the same key, our system emphasizing individual privacy permits each individual member of the data bank to have his own private key .... The heart of our Data Bank Network is the so called Vault, which is properly secured physical location of the central data processing facility consisting of a time sharing CPU and appropriate storage or filing facilities. Schroeder realized, early on, that many important applications of computer systems could involve groups with conflicting interests. His dissertation, "Cooperation of Mutually Suspicious Subsystems in a Computer Utility," evolved out of work on MULTICS under Saltzer, at MIT, and also appeared as a Project MAC technical report in 1972. The following excerpts indicate the motivation and scope of his work. This thesis describes practical protection mechanisms that allow mutually suspicious subsystems to cooperate in a single computation and still be protected from one another. The mechanisms are based on the division of a computation into independent domains of access privilege, each of which may encapsulate a protected s'y stem. The central com. ponent of the mechanisms is a hardware processor that automatically enforces the access constraints associated with a multidomain computation implemented as a single execution point in a segmented virtual memory .... In this thesis interest is centered on protection mechanisms within computer systems. The viewpoint is that of a computer system designer who is intent upon providing efficient protection mechanisms applicable to a wide range of problems. Questions of privacy influence this effort to the extent of implying criteria which must be met before such a computer system can be applied to those problems where privacy is an issue. The thesis, however, contains little explicit consideration of privacy. To further define the scope of the thesis, consideration is limited to problems of hardware and software organization. While it is recognized that issues such as installation security, communication line security, hardware reliability, · and correctness of hardware and software implementations of algorithms must be considered in order to achieve the secure environment required for useful application of protection mechanisms, these topics are beyond the scope of the thesis .... Taken together, the hardware and software mechanisms described in this thesis constitute an existence proof of the feasibility of building protection mechanisms for a computer utility that allow multiple user-defined protected subsystems, mutually susp1cwus of one another, to cooperate in a single computation in an efficient and natural way. Parker has provided the public with many amusing tales of crimes perpetrated by individuals against organizations maintaining computer systems. While the present work tends to be concerned with protecting individuals or groups from organizations maintaining computer systems, the solution envisaged by Parker in his 1976 copyright book, Crime by Computer, is quite instructive. It must become clear to the business community, government, and fmally the public that the safety of our economy and our society is growing increasingly dependent on the safe use of secure computers. An ideal secure computer system including data communication capability would be one of proven design which could be run safe from compromise without human intervention. It would be served by computer operators who would be allowed only to perform tasks directed by and closely monitored by the computer. No maintenance by human beings would be allowed in its secure operational state. All failures short of being physically damaged from an external force would be failsafe, and a failure not automatically reparable or overcome would cause the system to shut down in an orderly, safe fashion and loc).<: up all 25 data files in a separate, secure storage. It might take four trusted executives, including a special government inspector, simultaineously to insert and turn keys in the system console locks to change the mode of operation from "secure" to "open." Then human access to modify and repair the system would be allowed. Before returning the system to secure state again, a team of auditors would go through an elaborate process of reproving and testing the secure state . Once the system is again declared secure, another group of four executives would simultaneously turn their keys in the console locks to make the system again operable in secure state.
Chapter III Assumptions This chapter is intended to make su!Iicient assumptions so that the proofs of Chapter VII can be completed. In addition, the fundamental assumptions which shape the proposed design are presented. In the first two sections of this chapter, notation is presented for the cryptographic techniques introduced in the previous chapter, and this notation is then used to describe the properties desired of the techniques. Section three makes explicit the assumptions about certification used in the proofs of chapter VII. (Certification of vaults is covered in Chapter IX.) The last two sections of the chapter present the assumptions about physical security and organizational structure which shape the design of the proposed systems. § 1 Cryptologic Defines exactly what a crypto-system is assumed to make intractable. It will be assumed that the possibility of successful "forgery," "sealbreaking," or "de-compression" efforts, using feasible amounts of computation, is so small that it can safely be ignored. 27 Notation. Someone becomes a user of a public key cryptosystem by creating a pair of keys, Kand J\ 1, from a suitable randomly generated seed. The public key K is made known to the other users, or anyone else who cares to know it; the private key J\ 1 is never divulged. The encryption of X with key K will be denoted K(X), and is just the image of X under the mapping implemented by the cryptographic algorithm using key K The increased utility of these algorithms over conventional algorithms results because the two keys are inverses of each other, in the sense that J\ 1(K(X)) = K(K 1(X)) =X . . Forgery A user signs some material X by prepending a large constant C (all zeros, e.g .) and then encrypting with its private key, denoted J\ 1(C.X) = Y. Anyone can verify that Y has been signed by the the holder of J\ 1 , and determine the signed matter X, by forming K( Y) = C.X. and checking for C. A digital signature is forged by someone who creates it without the appropriate private key J\ 1• A potential forger is assumed to have the public key K and the ability to have some items of the forger's choice signed. A forgery attempt is considered successful if it yields some item Y that has not been signed using the private key but for which K( Y) = C.X. regardless of what X is . One forgery strategy is to choose values for Y at random, until one is found whose decryption with Kyields something with a prefix of C. An alternative attack that is of general utility requires only a public key. The corresponding private key can be found by using candidate private keys to decrypt an item encrypted with the public key, until one such decryption yields the original item. B Sealbreaking The sealing of X with K. is denoted K(R,X), where R is a random string. A potential sealbreaker is assumed to have the public key K. a set of items of uniform size and another set containing the items of the first set in sealed form. A successful sealbreaker knows something about the correspondence between the elements of the two sets. One sealbreaking strategy is to guess the random information R that was used to seal one particular item from the unsealed set. Prepending the guess to the item and encrypting with the public key would yield an item from the set of sealed items only if the guess were correct. This would reveal a single correspondence. De-com pression A compression function F maps a large string of domain bits D into a roughly key-sized string of bits R. The adversary is assumed to have the function F, an element of the domain D of interest., and of course R =F(D). The adversary is successful if a second element of the domain, D', can be produced such that D' ¢ D and R =F(D'). §2 Partial Key Techniques Defines what is expected of a partial key technique, and also makes significant assumptions about their use. It is assumed that the possibility of someone not privy to the seed or sufficient partial keys being able to determine anything about the original key which was divided is so small it can safely be ignored. Also, knowledge of even chosen partial keys never gives any clue about the seed used. 29 The entities holding partial keys in this thesis will be assumed "equally capable". In other words, they will be a homogeneous set, any subset of cardinality greater than the threshold value established for the partial keys will be sufficient to reconstruct the original key. A similar homogeneity assumption will be made about other kinds of voting as well. These assumptions strongly flavor the approach presented in the following chapters. The possibility of other approaches is mentioned in Chapter X. §3 Verification & Certification Defines the requirements of verification and initial certification. Assume that mutually suspicious groups can know that the plan for a vault has the desired properties and that the vault operates correctly according to the plan, as a result of some verification and certification procedures. Verification was discussed in the previous chapter; some new approaches to performing certification are the topic of Chapter IX. §4 Physical Security & Survivability Potential attacks on a vault are described and compared. This section presents a list of possible attacks on a vault. The results of these attacks vary from total covert control of a vault by an attacker, to simple destruction of a vault. The following is a summary of the potential threats against a vault, roughly in decreasing order of difficulty: (1) Surreptitious corruption-vault has been modified, and secret keys within vault may be known; the attack is not detectable by inspection; both tamper-indicating and tamper-responding mechanisms have been defeated. (2) Detectable corruption-same as (1) but inspection will reveal at least attempted tampering; tamper-indicating mechanism has n.ot been defeated. (3) Compromise -secret information within the vault has become known to attacker, but the attack leaves no trace; attack may consist of probing, limited compromise of the tamper-sating mechanism, exploitation of weaknesses in the TEMPEST techniques employed, or possibly cryptanalysis. (4) Covert isolation -node kept from communicating with anyone except attackers; node presumed dead to observers; may be a difficult attack where broadcast style communication channels are used . (5) Overt isolation-communication with outside blocked; attack obvious to observers; e.g. jamming in a system with broadcast style communication. (6) Destruction-vault is disabled. §5 Organizational Structure Defines the three tier organizational structure assumed for the most elaborate application of the proposed systems. Chapter I mentioned the existence of one group in a computer application that is particularly concerned with reliability and survivability of the system. The systems design proposed in subsequent chapters further divides this group into three different bodies, called trustees . The analogs of these bodies in a corporation might be its officers, directors, and stockholders. The following table summariz~s (1) the functions and exposure to the three levels of trustees: trustee level 1-charged with day-to-day operations of the system, which include implementing a policy which balances survivability and performance, within the policy constraints formulated by the trustees at level 2; has no significant advantage in attacking security over anyone. (2) Trustee level 2-charged with policy formation aspects of trusteeship, in which the trustees at level 2 must define how difficult it will be for them and also bow difficult it will be for others to defeat the system. to decide which 31 new vaults will be used; will be able to compromise some security properties without any attack, but only after giving advance notice. (3) Trustee level 3 -charged with the ability to restore the whole system in the event of disaster; can perpetrate certain threats without any attack.
IV Single Vault Systems A simple single vault system is presented to introduce and illustrate some of the basic ideas of the proposed systems, and also to motivate and define the problems to be overcome by multiple vault systems. When a certified vault is first constructed by the techniques presented in Chapter IX, a suitable public key and its inverse private key are chosen by a mechanism within the vault's protected interior, using a physically random process as discussed in Chapter II. The public key is then displayed outside the vault, on a special device certified for this purpose. As far as the world outside the vault i~ concerned, the possessor of the vault's private key is the vault: it can read sealed confidential messages sent to the vault, and it can make the vault's signature. §1 Checkpoints & Restarts Introduces the notions of encrypted checkpoints and the restarts they can allow trustees to perform. 33 What if Something Goes Wrong? If a vault were totally destroyed, computation would be safely halted -no secret information would be revealed, and the vault would not have taken any improper action. Other conditions might require an equally safe halt to computation. If a tamper-responding system detects an attempt to penetrate the vault's protective enclosure, or a fail-safe mechanism determines that the vault's contents can no longer be counted on to operate correctly, then the information stored in the vault, including the vault's private key, must be erased. This information will be encrypted in a special way, and saved outside the vault, so that a safe recovery can be provided. The encryption of the vault's contents, which includes its private key, is called a checkpoint, and is detailed below. At suitable intervals, checkpoints are formed, and then stored outside the vault. In some cases, there may be time to issue un-scheduled checkpoints before an emergency requires the vault's contents to be erased. The primary consideration behind the design of an encryption method for checkpoints is that there exists a means to decrypt them, but only at the appropriate time and place. The decision that some newly sealed vault can, and should, be given the ability to decrypt a checkpoint is necessarily a human one. Assume, for now, that the decision is to be made by unanimous consent of a set of human trustees. Before a checkpoint is released by a vault, it is encrypted with a special key for this purpose. Conventional as opposed to public key cryptography can be used for this. This key used to encrypt checkpoints will be divided into partial keys, one key for each trustee. Public key cryptography will be used to distribute these partial keys to the trustees in a secure manner. As part of the certification process, the vault is supplied with a public key issued by each trustee. Thus, the vault can ensure the confidentiality of the partial key it sends each trustee by sealing that partial 34 key using the trustee's public key. Each trustee now has two keys to keep secret: a private key used to unseal messages received, and a partial key that will be used in connection with decrypting checkpoints. Restarts A restart is the process by which a freshly sealed vault resumes the computation whose state has been saved in a checkpoint. After a replacement vault is certified and sealed, it forms a temporary public key and its inverse private key from a random seed, and then displays the temporary public key, as the permanent public key was displayed in the origi.nal start-up. Then the restarting vault receives partial keys from the trustees. A trustee provides the secrecy of its partial key while it is in transit to the vault by sealing it with the displayed temporary public key. Having received and decrypted the partial keys , the computation within the replacement vault merges them to form the key originally used. to encrypt checkpoints, and uses this to decrypt the checkpoint received. The replacement vault then bootstraps itself into the state saved in the checkpoint. Thus, the original public key found in the checkpoint is reinstated, and the computation within the replacing vault becomes an exact copy of the original computation. The restarted vault can then be safely brought back up to date by replaying all the messages sent it since the checkpoint was made . §2 Limitations of Single Vault Systems Several kinds of abuse of single vault systems by the trustees are described and solutions using multiple vault systems are sketched. It is generally held that networks of computers may be better than a single centralized computer system in many applications, for such reasons as 35 improved performance, increased reliability, and decreased communication costs. The multiple vault systems to be presented in the following chapters may be preferred over single vault systems for similar reasons. In addition to the usual advantages, however, multiple vault systems offer solutions to many of the problems of single vault systems: Destruction of Information. In a single vault system, the partial keys held by the trustees will always be sufficient to decrypt any previous checkpoint. Thus, a conspiracy of a sufficient subset of the trustees will have access to all information, no matter how old the information is . In a multiple vault network, however, the trustees will be forced to request certain partial keys from the network during a restart in order to obtain sufficient partial keys to decrypt a checkpoint. The network will change the keys used to form checkpoints, and the partial keys it maintains, in such a way that obsolete checkpoints can never be decrypted. (A conspiracy of trustees in a single vault system need never be able to forge a vault's signature, since a private key used by a vault only for making signatures need never be saved outside the vault.) Comprehensive Record of Restarts. In a single vault system, a conspiring subset of the trustees can secretly combine their partial keys and obtain keys sufficient to allow them to decrypt checkpoints. In the multiple vault system, the trustees will have to request partial keys from the network to accomplish a restart, as mentioned above, and the network will be able to maintain a record guaranteed to include descriptions of all such requested restarts. Such a record is very useful because it can ensure that only certified vaults have decrypted checkpoints, and that they have done so only during certified restarts. Advance Notice of Security-Relevant Changes . In a single vault system, the trustees can perform a restart using a vault which is certified but which contains an arbitrary change in the security-relevant aspects of the vault's 36 operation. For example, the new vault may give greater power of inspection or modification to the trustees. In multiple vault systems, the trustees can be required to give advance notice of security-relevant changes, such as the public keys of vaults to be added into the network and changes in parameters used by the network to protect itself from the trustees.
Chapter V Multiple Vault Systems Algorithms to be performed by a collection of vaults are defined using an extended formal specification language. § 1 Introduction to Algorithms An overview o[ the algorithms proposed is presented which includes the relationship of this chapter to other chapters. This chapter describes a collection of algorithms to be performed by a number of separate vaults, or nodes . Each node will perform essentially the same algor~thms, but some of its own state may vary. The algorithms are organ- ized as a set of a dozen and a half independently callable routines . A node will perform any one of these routines on request, if it is provided with the appropriate actual parameters. Typically, some of the actual parameters of a call will bear digital signatures formed by other nodes in the system and also by various trustees. 1f these signatures and the rest of the parameters prove acceptable to the called routine within a node, then the node may alter its state and/or produce some signed and possibly sealed output as a result of performing the called routine. Calls are handled one at a time by a node, so that once a node com- 38 pletes processing of one call, it begins waiting for the next call to be requested. The nature of the algorithms and their use of cryptographic techniques ensure that: (1) the various security properties provided by the system can not be violated by any sequence of calls, and (2) the trustees can maintain the reliable operation of the network by performing suitable sequences of calls. Chapter VII argues these points; the present chapter uses a specification language to describe a practical version of the algorithms. Among other things, the algorithms must provide a kind of synchronization and agreement among nodes about allowing new nodes into the network, removing nodes from the network, and the status cf nodes once in the network. The routines will be called a-functions (for Operation function) since they are an extension of the a-functions of the Parnas specification language [Parnas 72], as mentioned in Chapter II. Figure 1 shows seven of the major a-functions. These a-functions can change the membership of the network and the status of nodes within the network. For example, the CERTIFY a-function can bring a new node into the network, leaving the new node in the "initiate" state . Similarly, REMOVE_NODES can take a node in the "participated", "veteran" or initiate states out of the network. These and the other a-functions will be described in detail in sections 6 and 7. Section 2 introduces the basic types, primitives and constants of the specification language . Section 3 and 4 define the state of nodes as a collection of ll-functions (for Value function), which have been extended to include types not in the original Parnas notation. Section 5 defines the rather powerful parameter passing mechanism used both for input and output by the a- functions, which is an extension of the Parnas notation. Finally, as mentioned above, sections 6 and 7 present specifications of the a-functions themselves. veteran ' participated present " ~ t!Q' c"1 (l) ..... ~ w 'I if 'I if () ('1- ....... 0 ~ Ul R' tf (l) ~· z0 p. 'if 'if A_\ ' ~ ..... (l) 'If CERTIFY (T2) CREATE KEYS, ISSUE & RECEIVE NEW PARTIALS " ," vf' '\ 'if CHANGE PRESENT " rvplac:ing nodlil :< ....... ..... ....... " REMOVE (T2) CHANGE KEYS rvpl.ac1d nod• Pl Ul I' I) '\ (l) g initiate v RESTART ,"" 0 ~ APPLY Ul v v '~ A ' ) PARTICIPATE · RECEIVE NEW PARTICIPANTS & NEW PARTICIPANT RECEIVE J 40 Strictly speaking, a specification language is intended to define what a program is to do-and not how it is to do it. Nevertheless, it will be very convenient to apply the familiar terminology of programming languages to the specification language used here. The presentation of the specification language will also use a variety of type fonts and type sizes, roughly based on those used by Parnas [72] . Some symbols will appear in upper case, others in lower case, and a few others will combine the two. A summary of the typographic conventions is presented in Table 1. primitives & constants synlax-Tne ta-s-r.Jmb ols pseudo-types types type-constructors, if then else & with PARAMETEILNAMES & TEMPORARY_ VARIABLES V-FUNCTJON_NAMES & D-FUNCTJON_NAMES AGGREGATE-FUNCTION_NAMES Table 1. Typographic Conventions §2 Simple Types, Primitives & Constants The basic data types of the specification language and the elementary operations which can be performed on them are presented. The specification language is strongly typed , although some primitive func tions can have arguments of any type . Some primitive functions have no arguments, but those entities with fixed values are called constants. 41 Simple Types Some of the simple types are those usually found in programming languages. Others are the keys, seeds, and parts of keys used by the cryptographic transformations. Yet others are simply enumerated types, ala Pascal, used as tags included in signed messages to indicate the kind of message. A special type is used to represent node names. Chapter Vlll contains some discussion of straightforward representation schemes for instances of the simple types, and the constructed types of the next subsection, for purposes of analysis, but further consideration of implementation techniques is beyond the scope of this work. A simple context free grammar will be used to illustrate the basic syntax of the specification language. The first production of the grammar is shown here: elementary-type --) boolean I integer I time I node-id I seed I public-key I private-key I partial-key I proposal-kind I announcement-kind I action-kind I transfer-kind The following is a detailed definition of each of the elementary types: boolean, integer The usual. time The content of a clock or counter. Uniform units are used so that the difference of two times produces an integer which is proportional to the amount of time between the two times. node-id seed public-key A special type whose values are used to uniquely identify nodes and trustees, and whose values are never re-assigned. A randomly selected value preferably from a space at least as large as the space of possible keys , which is returned by the primitive function create-seed and is used by the primitive functions create-public, create-private, and form-partial, to create keys and partial-keys. A public key that was created by a call to creat~-public. Generaly publicly available, and can be a parameter m calls to seal and check-signature. 42 private-key partial-key proposal-kind A private key that was created by a call to crea.te-priva.te. Generally kept secret by its creator, except may be transferred during a RESTART. Used in calls to sign and unsea.l. A partial value of a private-key that is created by a call to formrpa.rtial. Sufficient quantities of these keys can be used by merge-pa.rtials to reconstruct the private key from which they were formed. This is an enumerated type, a. La. Pascal, whose values are denoted by the constants: propose-certify propose-set-minima. and proposeJT"emove . They are used as inclusions in signed proposals of the corresponding names. announcement-kind An enumerated type, whose values are used as inclusions in announcements of proposed actions of the corresponding names. The unique values are denoted by the constants: certify, set-minima., and remove. action-kind Used as an inclusion in signed announcements of trustee level 1 actions . The unique values are denoted by the constants: propose, ca.ncel, a.pply, cha.nge-presents, resta.rt, pa.rticipa.te, crea.te-keys, and cha.nge-keys. transfer-kind Used as an inclusion in signed output generated by an afunction and intended to be consumed by one or two different a-functions. The unique values are denoted by the constants: RESTARLto_ASS UME_APPL!CATION, PARTIC!PATE_to_RECE!VE_NEW_PARTICJPANT, PARTIC!PATE_to_NEW_PART!C!PANLRECEIVE. CREATE_KEYS_to_/SSUE_NEW_PART!ALS&CHANGE_KEYS. CREATE_KEYS_to_NEW_PARTJCJPANLRECEIVE, JSSUE_NEW_PARTIALS_to_RECE/VE_NEW_PARTIALS, RESTARLto_ASSUME_APPL!CAT!ON, pa.rtia.lsJT"eceived, proposa.l, and checkpoint. Constructed Types The elementary types of the previous subsection may be combined into sets or tables. This is an extension of the original notation proposed by Parnas and further developed for HDM [Levi, Robinson and Silverberg 79], but resembles the sets and maps of the SETL programming language [Dewar, Schonberg and Schwartz Bl]. A set of some elementary type is just an unordered collection of elements of the type. The usual set operators will be found in the next section. A table is much like a one or two dimensional array, but it may be sparse and have non-integer subscript types. The following gives a syntax for these 43 constructed types: simple-t11Pe ~ elementary-t11Pe I set of elementary-t11Pe I table[elementa71rtype] of simple-fwe I table[ elementary-type ][elementary-type] of simple-t11Pe 1· Examples of these constructed types will be found in each subsequent. section of this chapter. Simple Primitives These primitive functions take zero or more parameters, and return a value of a simple type. Some are generic in that some parameters need not be of any particular simple type. Such parameters will be shown as type m:ty-type. Many of the primitives are familiar, like those needed to determine the current time and perform the usual arithmetic, set, and boolean operations. A few of the primitives perform the cryptographic functions which were introduced in Chapter II and formalized in Chapter III. Functions are defined which create seeds, create keys and partial keys from seeds , and merge partial keys. The following identity provides an example of the use of the partial key primitives. It simply asserts that partial-keys formed from a key using a common seed can be merged back into the original key. if s =create-seed() then memerge-partials(Jor7Tirpartial(1, s, m, 2),form-partial(2, s, m, 2)) The following provides detailed definitions of the primitive functions. 44 ere ate-seed()-+ seed Returns a seed derived from a physically random process within the instant node, and has no parameters. ere ate -public (s :seed)-+ public-key Returns a public key that is a function of the parameter, seed s. create-private (s:seed) -+private-key Returns a private key that is a function of the seed s. The private key corresponds to the public key created by a call to create-public with the same parameters. JorTTlr']J artial ( n: ~m.y-type, s :seed a.:~my-type , m:integer)-+ partial-key Returns a partial value of the parameter a, with a threshold value of m (see merge-partials), using seed s. Calls with different values or types for n produce distinct partial values. m different partial values created with identical s are necessary and sufficient to determine the original value a. The seed s can not be determined even if all results of all possible calls are available, and without the seed the values of any call give no clue about the values of a used in another call. merge-partials (p :set of partial-key)-+ a: filly-type Returns the original value of a which was divided into parts by form-partial . The parameter p must include at least as many partials formed from the original a as the threshold with which they were formed. compress(a:Blly-type)-+i:integer Returns a cryptographic compression of the argument into an integer. Thus, given a and i = compress( a.) and the function compress, it is infeasible, under the assumptions of Chapter III, for an adversary to produce a.' such that i = compress(a') and a''¢ a. now()-+time Returns the time maintained by the clock of the instant node. suicide (m:integer) . A real-time counter is set to count down for an mterval of m, and if the counter ever reaches 0, the instant vault sets all its secret V-functions to the value erased and in effect kills itself. ca.rdinality(s:set of Blly-type)-+integer Returns the number of distinct members of the sets. +, -, x-+integer These are the usual infix operations performed on integers. Also _ applied to two times is an integer.which is negative when the time on the right is before the time on the left. (See definition of time.) 45 -, u, n _.set of any-type The usual infix operators defined on sets, returning sets. <.~. , ~, >, ~-+boolean Comparison infix operators. E: , ~ , !: -+boolean Set membership, its negation, and subset. Simple Constants Besides the standard use of Arabic numerals as literal constants, there are two major sorts of constants used in the specification language. One kind of constant is used to indicate the various vacuous values, such as the empty set, uninitialized or don't-care values, and a special value indicating that all information about any previous value of the function is lost. The second sort of constant is used to reference information certified into the vault initially which specifies the keys, number and quorum sizes of the two groups of trustees and the enforced delay intervals on their actions. The certification of constant values into vaults is covered in Chapter IX. Of course more elaborate versions of the algorithms presented here might include mechanisms to allow some or all of the constant values related to the trustees to be changed during operation of the network-much as the SET_MJNIMA D-function does in the present algorithms. But such flexibility may actually prove undesirable, since those supplying information to a system may not wish to do so if the ground rules for its security can be revised in an arbitrary way. A detailed definition of the simple constants follows: 46 empty undefined The empty set. No particular value. erased No trace or clue is left about the previous value of any function with this value. coo ling -off.Jj_nterv a1 v- The minimum interval of time required between the time the last mem~er of a majority of present nodes sig·ns a proposal and the bme the first node signs the announcement of the action defined by that proposal. trustee -1-publics The set of public keys held by the trustees at level 1 which are used to check all signatures purported to be made by trustees at level 1. trustee -2-publics The set of public keys held by the trustees at level 2. trustee -1-quorum The number of trustees at level 1 whose signatures are sufficient to author ize anything that can be authorized by trustees at level 1. trustee -2-quorum The number of signatures of trustees at level 2 required to authorize any proposed action. Also the number of trustees at level 2 whose trustee partials are required by the replacing node in a restart. trustee-l-ids The set of node-ids wh ich includes one member for each trustee at level 1. (As mentioned elsewhere, trustees are not nodes, but this convention greatly reduces the proliferation of types and typing mechanisms.) trustee -2-ids The set of node-ids which includes one element for each trustee at level 2. §3 Secret ¥-functions The ¥-functions which record information not publicly available are defined, their usc discussed, and initial values given. Variable functions, or V-functions, ar~ the variables which hold a vault's state. The Y-functions of a vault can be divided into those which the vault must keep secret and those which are public knowledge. This section presents the secret Y-functions; the next section presents the non-secret ¥-functions. The Y-function definitions presented here usually include three parts: (1) a heading which defines the name and type of the Y-function; (2) an initial value 47 part that includes the name and an express 1·0 n wh ose va1ue 1s · th e m1 · ·t·1a1 va1ue; and (2) a comment part which discusses the intended use of the Y..function. The following productions give the basic idea of the syntax, further details being supplied in later sections: v-function ~name :simple-type :V-function initial-value comment initial-value -+ Initial: name = expression I derivation comment -+ Comment: wildcard Vaults must at minimum maintain the secrecy of their private keys upon which the security of the entire system relies. There will be two different kinds of secret keys, as mentioned in the previous chapter. Some keys need never be known outside the vault-these are the node secret keys . Other keys are kept secret by the vault, but they have been divided into partial keys and provided to other vaults for use during a restart-these are the application secret keys. In the following two subsections, each kind of secret Y..functions is considered separately. Node Secret Y-functions The V-functions described in this subsection never leave the vault. When the vault destroys its own information content, the values of these Y..functions are set to erased. This sub-section makes the first formal reference to the notion of subpartial keys. These are just partials of partial keys. In other words, some threshold of sub-partial keys are sufficient to reconstruct the original partial key from which the sub-partials were originally formed. The algorithms in this chapter allow the trustees to decide how many, if any, sub-partial keys will be 48 used by the network. The reason for this is that while the use of sub-partials does provide somewhat more convenience and flexibility in the operation of the network, they also have non-trivial cost in terms of system resources (see Chapter VIII for analysis of resource requirements). Sub-partial keys allow a "quorum" of nodes to, among other things, cause any node not participating in the last key change to become "participated" and enter a state equivalent to that which would have been achieved had it participated in the key change, restart nodes in an arbitrary order, and diminish the quorum size. The essence of this mechanism is that sufficient sub-partial keys allow every quorum of "present'' nodes to form a partial key for other nodes in the network. The following are definitions of the node secret l!-functions: NODE_PRIVATE :private-key: l!-function Initial value: NODE_PRIVATE create-private (let !NITIALNODE_SEED =create-seed()) Comment: The private application key of the instant node. The initial value uses a l!-function which is local to the initialization process = !NITJAL_NODE_SEED. NEW_NODE_PRIVATE :private-key: V-function Initial value: NEW_NODE_PRIVATE =undefined Comment: Returns the application private key which will be assumed by the instant node if it is a participant in a CHANGE_KEYS or subject of a PARTICIPATE before the next key change. This private key is created by CREATE-KEYS and corresponds with NEW_NODE-PUBLJC. PARTIAL_SEED :seed; l!-function Initial value: PARTIAL-SEED= undefined Comment: Returns the randomly create·d seed used to form p~rtial keys. Created and changed by CREATE_KEYS, PARTIAL-SEED ts used by ISSUE_NEW_PARTIALS and also by the subject node of PARTICIPATE. 49 PARTIAL-KEYS:table[node-id] of partial-key: V-function Initial value: \::fp PARTIALKEYS[p] =undefined Comrr:ent: The partial key held by the instant node for the participated node P 1s PARTIAL_KEYS[p]. The constituent partial keys are received by RECEIVE_NEW_PARTIALS and by RECEIVE_NEW_PARTICJPANT. NEW_PART!AL_KEYS :table[node-id] of partial-key: V-function Initial value: \::fn NEW_PARTIAL_KEYS[n] =undefined Comment: Returns the new partial key held by the instant node for the selected node. The value is obtained by RECEIVE_NEW_PARTIALS and will replace PARTIALKEYS iff the instant node participates in a CHANGE_KEYS before the next CREATE_KEYS. SUB -PART/ALS:table[node-id][integer] of partial-key: V-function Initial value: \::fp \::7'i SUB-PARTIALS[p][i] =undefined Comment: The partial partial key held b;r the instant node for the participated node n, to be released to the node assuming the ith set of subpartials. The values are obtained from NEW_SUB-PARTIALS after the instant node participates in a CHANGE_KEYS. or from the input supplied to NEW_PARTICIPANLRECEJVE. The SUB-PARTIALS[p][i]s held by a quorum of present nodes for a particular set of sub-partials indexed by i are sufficient to allow merge-partials to determine a partial for node p. NEW_SUB-PART/ALS:table[nodc-id][integer] of partial-key: V-function Initial value: "dn "di NEW_SUB-PARTIALS[n][i] =undefined Comment: Returns values accumulated since the last CREATE-KEYS which will replace SUB -PARTIALS iff the instant node participates in a CHANGE-KEYS before another CREATE_KEYS. OWN_ TRUSTEE_PARTJALS:table[node-id] of partial-key: Y:.function Initial value: "v'n OWN_ TRUSTEE_PART!ALS[n] =undefined Comment: OWN_TRUSTEE_PART!ALS[n] is a private key which must be present in the instant node when the instant node is the replacing node in a RESTART in which node n is the replaced node. Values of OWN_ TRUSTEE-PARTIALS are obtained by the subject of CERTIFY for_ all the nodes it is certified for for (except itself), and any values for whlCh the subject is not certified are erased. In an app~ication where some different nodes have access to different data, a particular vault may not be approved to restart some nodes. 50 Application Secret V-functions Care is taken to ensure that APPLICATION_PRIVATE can be recovered only with partial keys of the most-recently completed key change, and that NEW_APPLICATION_PRIVATE can be recovered with partial keys distributed for the next key change . Of course there is presumably much secret application data which must be included in checkpoints, and it should also be divided into current change period and new period -so that obsolete application data becomes inaccessible once a node changes keys. The aggregate l'-function, APPLICATION_SECRET_ V-FUNCTIONS, is assumed to contain all application secret data from the current change period; the aggregate NEW_APPLICATION_SECRET_ V-FUNCTIONS contains all application data for the forthcoming key period. The following are definitions of the two application l'-functions relevant here, one for each aggregate : APPLICATION_PRIVATE:private-key: V-function Initial value: APPLICATION_PRIVATE create-private(create-seed()) Comment: The private application key of the instant node. = NEW_APPLICATION_PRIVATE :private-key: l'-function Initial value: NEW_APPLICATION_PRIVATE =undefined Comment: Returns the application private key which will b.e assumed by the instant node if it is a participant in a RESTART or subJect .of a PARTICIPATE before the next CHANGE-KEYS. This private key 1s created by CREATE-KEYS and corresponds with NEW_NODE-PUBLIC. p §4 Non-Secret V-functions Those ¥-functions are pres en t e d whic h relate to node state that is not secret. Some 11-functions in this section are defined in term s o f expresswns · · 1vmvo ing other Y-functions, and they have a "derivation" part instead of an initial value part: derivation ~ Derivation: name = expression The OWN_NODE Y-function is special in that its value never changes during the life of a node, but the actual initial value of each node's OWN_NODE must be unique. No initial value part or derivation is used for OWN_NODE. As will be seen in Chapter VII, it is quite useful to distinguish those functions whose values must be in agreement across nodes, from those vv- functions which are not subject to any consensus constraint. These two kinds of V-functions are covered in separate subsections. Consensus Y-Junctions The non-secret V-functions presented in this subsection are intended to have identical value for all nodes with the same value of CYCLE (which is defined in the next subsection). They define the status of the network. As a notational convenience, the consensus CONSENSUS_ V-FUNCTIONS. Y:.functions are denoted collectively as 52 NODES-IN_ USE:set of node-id; l'-function Initial value: NODES_IN_ USE= empty Comment: Returns the set of node ids which includes an id for every node in the network_. . ~hese exclude all removed nodes and include the newly CERTIFYed m1bate nodes which have not ever been members of PARTICIPATED. and all veteran nodes which are those nodes who have been members of PARTICIPATED at least once, whether or not they are presently participated. USED_NODE_IDS:set of node-id; V-function Initial value: USED_NODE_IDS =trustee-l-ids u trustee-E-1-ds Comment: Returns a set of node ids which are not suitable for use by any new node. CERTIFY ensures that new nodes do not use ids in USED_NODE_IDS, REMOVE_NODES places the id of all removed nodes into USED_NODE_IDS, and RESTART places the id of the replaced node in USED_NODE_IDS. For simplicity in typing and signature checking primitives, as already mentioned, node-ids are also used to identify the trustees. PARTICIPATED:set of node-id: l'-function Initial value: PARTICIPATED= empty Comment: Returns the set of node ids which includes exactly those nodes which were included as PARTICIPANTS in the last CHANGE-KEYS and all those nodes which have been the subject of subsequent PARTICIPATEs. Any node which is to become present must be a member of PARTICIPATED. PRESENT:set of node-id: V-function Initial value: PRESENT = empty Comment: Returns the set of node ids which defines the most privileged and ca able subset of nodes. Every QUORUM of members of PRESENT _have su~icient partial keys to enable them to restart any prese_nt node. Signatures of a QUORUM of members of PRESJ!!NT are requ1red before any node may perform any synchronized D-funcllon. ABSENT:set of node-id: Y-function Derivation: ABSENT= NODES-IN-USE- PRESENT APPLIED:set of node-id: Y-function Initial value: APPLIED= empty d h" h currently have an t 0f de ids of all no es w lC Comment: Returns the se no . h they are the subject of an APPLY application. Nodes enter apph~d wn~~e in a RESTART and they leave or when they are the replacl~g t f REMOVE_NODES or the replaced APPLIED when they are a subJeC o node of a RESTART. 53 - MAJORITY:integer: v-function Initial value: MAJORITY= 0 Comment: The minimum number of . . announcement or action can be . ~lgnatones required before any Must be at least as great carne out. Set by CHANGE_PRESENT. cardinality(PARTICIPATED) and as t· ~UORUM and no greater than ment. ' sa lS Y the MINIMUM_MARGIN require- MARGIN :integer: v-func tion Derivation: MARGIN= (2x MAJO'RITY) d ' l'ty( . . . . - car tna t PRESENT) Comment. The m1rumum mtersection b t PRESENT nodes. e ween any two MAJORITYs of MINIMUM_MARGIN:integer: V-function Initial value: MINIMUM-MARGIN= 1 Comment: The small~st allowable value of MARGIN. The value of MINIMUM-M_ARGIN 1s changed only by SET-MINIMA , and can not be set belo': 1,. Wh1Ch ensures that MAJORITY is always a simple majority of card'Lnal'Lty(PRESENT). MINIMUM_QUORUM :integer: l'-function Initial value: MINIMUM_QUORUM =0 Comment: The smallest allowable value of QUORUM . Set by SET_MINIMA . QUORUM :integer: v-function = Derivation: QUORUM QUORUMS[LAST_CHANGE] Comment: The current quorum. QUORUMS:table[integer] of integer: l'-function = Initial value: QUORUMS[O] 01\ V'n~ if n ~ 1 then QUORUMS[n] = undefinedl Comment: Returns the number of partial keys required for a restart of a f?.Ode who last participated during key change n, for all n~ LAST_CHANGE. Thus, QUORUMS[LASLCHANGE] returns the number of partials of the current key change period which are required by merge-partials. And QUORUMS[LAST_CHANGE + 1], returns the number of nodes whose partials or sub-partials will be required for a successful merge-partials during the next key change period, if no further CREATE-KEYS occurs before the next CHANGE-KEYS. ' I 54 SUB-PARTIALS_REMAINING:table[node-id] 0 f · t . . . m eger: V-funcbon Imtlal value: 'dn SUB-PARTIALS_REMAIN!NG[ J _ n -undefined Comment: Returns the number of sub- artials .. New entries are established by CERTjFY. remammg for the nth node. NEW_SUB-PARTIALS_RE1J.AINING:table[node-1·d] 0 f m · t u . eger: r-funcbon Initial value: 'dn NEW_SUB-PARTIALS REMAINING[ ] n = undefined Comment: Returns the number of sub-partials that node during the current k h . are needed by the nth CREATE_KEYS. ey c ange penod as established in the last LAST-CHANGES:table[node-id] of integer: V-function Initial value: 'dn LAST_CHANGES[n] =undefined Comm_ent: LAST_CHA(V~ES[nJ. retur?~ the last key change period during wh1ch node n parhc1pated m the 1mtial CHANGE_KEYS or in which n was the subject of a PARTICIPATE. New entries are established by CERTIFY. LAST_CHANGE:integer: V-function Derivation: LAST_CHANGE = LAST_CHANGES[i] t'd J ~LAST_CHANGES[i] ~ LASLCHANGESIJ]n Comment: Returns the number of the last key change the instant node has processed, whether or not the instant node participated. KEY_ GREATI ON-# :integer: l'-func lion Initial value: KEY_CREATION_# = 0 Comment: Returns the serial number of action calls of the CREATE_KEYS ~ function. Notice that there may be more than one call to CREATE_KEYS between calls to CHANGE_KEYS and that all but the last such call have no effect on the CHANGE-KEYS because PARTIALS-RECEIVED is emptied by CREATE-KEYS and all relevant transfers include the KELCREATION_fl. (The multiple calls may be convenient since they allow a new quorum and complement of sub-partials to be selected.) SUICIDE_INTERVAL:integcr: l'-function Initial value: SUICIDE-INTERVAL= cooling-off-interval Comment: Returns a time interval (i.e. an integer) during which a node must become participated or it will commit suicide. The actual ~all to. suicide is made on the SUICIDE-INTERVAL minus the amour:t of tu:ne smce the earliest timestamp among the majority of s1gnator~es to . the CHANGE-KEYS or PARTICIPATE in which the instant node 1s a subJect. · ·t·1a1 va1ue lS · s uch that a SET- MINIMA must occur before. .a Th e 1n1 cooling-off-interval has elapsed since the first CHANGE_KEYS participated in. 55 NODE-PUBLICS:table[node-id] of public-k V-f . ey: - unchon Initial value: "v'n NODE_PUBLIC'S[n] _ d fi - un e ned Comment: The current application publi k f . . c ey o every node muse. APPLICATION_PUBLICS:table[node-id] of public-key: Y..function Initial value: "v'n APPLICATION_PUBLJCS[n] =undefined Comment: The current node public k 0 f · established by CERTIFY d . e( eve~y node muse. New entries are CHANGE-KEYS and PART;;IP~;~. mg entnes are changed for subjects of CERTIFICATION:table[node-id] of set of node-id V-function Initial value: "v'n CERTIFICATION[n] =undefined 1\ CERTIFICATION[OWN_NODE] =empty Comment: Each node in use n has associated with it a set of other nodes CERTIFICATION[n] whose applications it is allowed to assume, either by APPLY or RESTART. The nodes comprising the certification of a node are initialized and changed by CERTIFY. PROPOSALS_PENDING:set of integer: V-function Initial value: PROPOSALS_PENDING =empty Comment: Returns the set of all cycle numbers of proposals which have been proposed but not canceled or carried out. COM PRES SED_HIS TOR Y:integer: Y..fun ction Initial value: COMPRESSED-HISTORY= 0 Comment: Returns a compression of CONSENSUS_ V-FUNCTIONS formed before the action of the last cycle was completed. Since COA!PRESSED_HISTORY is included in CONSENSUS_ V-FUNCTIONS, COMPRESSED-HISTORY is a l'-function of the entire series of states obtained by the identical V-functions during all previous cycles. Because COMPRESSED_HISTORY is checked in the input of every synchronized D-function, no node will perform any synchronized action unless its entire history of CONSENSUS_ V-FUNCTIONS states is the same as every other node performing the action. This is largely a redundant mechanism; see Chapter VII. Individual ¥-functions Some of the non-secret l'-functions presented in this subsection will have · · umque values, never obtamable by ano th er n ode · For example, a node's record · be umque. · Other V-functions covered here may of its ·own past public keys will 56 have nearly the same values across nodes, b t th· u lS strict consensus is not as enforced in the previous subsection. For example, PARTIALS-RECEIVED-FROM contains node ids of all the nodes from which a node has received partial keys. These may vary as the p t· l k · d ar 1a eys are rece1ve in different orders and possibly from different sets of nodes, but those main- tained by all participated nodes will ultimately include node ids from all participated nodes. Just as CONSENSUS_ V-FUNCTIONS was used to denote the entire collection of consensus V-functions, INDIVIDUAL_ V-FUNCTIONS will be used to denote the collection of individual V-functions . OWN_NODE:node-icl l'-function Comment: Returns the node-id which identifies the instant node for its entire life. The value should be distinct from that of all other nodes, so that CERTIFY will allow the node to be initiated into the network. Examples of possible actual implementation values include the simple serial numbers of a node or the initial node public key. PHASE :1 .. 2: V-function Initial value : PHASE = 1 Comment: Returns the current phase, either 1 or 2, which is used by all synchronized a-functions. When PHASE= 1 a node will add its signature to any announcement or action which has insufficient signatures and does not raise an exception, then the node will change to PHASE = 2. When PHASE= 2 a node will not add its signature to any a~nounc~~ent. _In either phase, when a node recei:es a~ an_nouncement w1lh sutilCtent _slgnatures and no exception is ra1sed, 1l Wlll perform the effects secllon, which includes setting PHASE= 1 and incrementing CYCLE. CYCLE:integer: l'-function Initial value: CYCLE = 1 Comment: The basis of all synchronization of the_ network, this monot~nically · · 1 that all nodes w11l process synchromzed o1rncret~smg_ va ue telnstuhreessame order Returns the serial number of the unc 1ons m exac Y · d h t t f rm next announcement or action which the present no e as ye o per o . NEW-NODE-PUBLIC:public-key: Y-function Initial value: NEW_NODE_PUBLIC: =undefined Comment: Returns the instant node' corresponds with NEW_NODE_PRIV;T;wn ~ew node public key, which during the last CREATE-KEYS. ' an whose value was determined NEW-APPLICATION_PUBLIC:public-key: V-function Initial value: NEW_APPLICATION_PUBLIC: =undefined Comment: Returns the instant node's own new r t' corresponds with NEW APPL!C'AT app tea lDn public key, which • r1 ION_PRIVATE and whose val determmed during the last CREATE_KEYS. ' ue was ALL-OWN_NODE_PUBLICS :set of public-key: V-function Initial value: create -public (INITIALNODE_EEED) e: ALL_OWN_NODE_PUBLJCS Cor:r:ment: Returns _all the node pu.blic keys that have been used by the mstant node to s1gn proposals whtch are pending. Because the number of proposals pending can be kept from growing too large, through the use of CANCEL_PROJ!OSAL, cardinality(ALL_OWN_NODE_PUBLJCS) can be kept to a modest s1ze. /NITJAL_NODE_SEED is a variable which is local to the initialization and which is defined in the description of NODE_PRJVATE . PARTIALS_RECEIVED_FROM :set of node-id: V-function Initial value: PARTIALS_RECE!VED_FROM =empty Comment: Returns the set of nodes for which the instant node has received partial keys during the current key creation period. This V-funclion is emptied by CREATE-KEYS, and new members are added to it by RECEJVE_NEW_PARTIALS. NEW_PARTIC!PANT_RECEJVE and RECEIVE_NEW_PARTICIPANT. The unsynchronized D-function PARTIALS-RECEIVED issues signed statements of minimum content of PARTIALS_RECEIVED_FROM. These statements must be received from all nodes who participate in a CHANGE-KEYS, and they must include every such participating node. The statements are also checked for by CHANGE-PRESENT to ensure that all nodes made present have partial keys from all other nodes made present, which ensures that all necessary RECEIVE_NEW_PARTIC!PANT and NEW_PART!CIPANLRECEJVEs have completed for any PARTICIPATEed nodes. §5 Templates, Template Types, & Primitives Input and output parameter passing mechanisms are described which include constructed descriptions of hierarchically encrypted data, and primitives for performing cryptographic operations on data. An unusually powerful param t . e er mechamsm has been incorporated into the specification language used he re, f or several reasons. First, it allows the underlying structure of multiply encrypted messages to be shown clearly. Second, it allows much of the routine c h ec k'mg and cryptographic transformations to be handled cleanly, and without c omp rlca t'mg the rest of' the . algorithm description unnecessarily. Third ' th e particular form used here can also provide descriptive names, types, and sometimes v a 1ues for th e parts of parameters. Templates The basic syntax for the parameter description mechanism, called a tem- plate, is shown in the following productions: template --+name :construction construction ~ *constructor-type <item-list> constructor-type <item-list> I constructor-type ~ signed I sealed I signatured item --+ expression =name :type I name :type I expression = :type I name : I :type item-list --+ item-list, item I item type --+ simple-type I construction The constructor types are covered in the next subsection. A * denotes a part of a template, or an entire template, that is optional. The rules for when the optional parts must appear in input, and when they are output are covered in the subsection on template primitives . . the names which may appear in a template serve as the formal parameters. An item in a template may include an expression. When an expression provides a value for an item in a template describing input, the actual parameter supplied must have the identical value; when an expression provides a value for an item in a template describing output, the value provided is output. Notice that all five non-empty possible combinations of the three components of an item can be used in a template · One form of 't t · t em 1s name : ype. It is the usual formal parameter when used for input, and is used to return the value of the formal parameter (which must be of the specified type) in an output template. Another form of item is expression = :type , which is used in an input template to cause an initial "bad template" exception if the corresponding input actual parameter does not have the value of the expression. It is used in an output template to return a value for which a parameter name is not needed. The most elaborate form is expression =name :type. It serves the same function as the previous form, except that a parameter name is associated with the value. When only a name is supplied, name :, the type and value are obtained from another item with the same name. When only a type is supplied, ;type, the value of the parameter is ignored. Several items or even whole templates in an G-function may share the same name . Items with the same name must have the same value . Templates with the same name are just different copies of the same template. The next section contains a number of templates which may serve as instructive examples. Tern plate Types The three template types were shown in the formalism of the previous sub....J..rn, . sec t 1on as cons t rue t OT-·:~r~ · Th'1s subsection gives a detailed description of each, but these descriptions are best ta k en t oge th e r with those of the template primitives of the following subsection. 60 signed signatured sealed A digital signature of a struct . the primitives sign and ch kur~ of conshtuent elements. (See . ' ec -SLgnature .) A collechon of digital signatures of . . the same matenal. There are several possible im 1 tured such as repeated ~::ent.ahons of. the n.otion of signadually signed seperate c . ryp:l~n of a smgle b1t string, indivi0 made on a compression ~f~~ ~~ satme bit. string, signatures nation of these a e rna er 0 be s1gne9., or a combicitly include in ::ro~ches . It may also be desirable to explid h . e stgnatured some bits indicating who has rna e eac s1gnature (See th . . . check si n ) · e pnm1llves sign and provideJ a~~edth A sig~ature~ may also include timestamps . e s1gnatones. (See the primitives latest-stgnature and earliest-signature.) ~ encrypted ~orm of the constituent elements of a structure. hese should mclude a random component, as described in Chapter II. (See the primitives seal and unseal) Template Primitives The following primitive functions are used to perform cryptographic transformations on input and output of D-functions. Input parameters which are included in a signatured, signed or sealed construction must be lhc subject of a check-signatured, check-signature or unseal primitive respectively if the constituent items of the construction are to be accessed. Once the primitive is applied, free use can be made of the items of the construction. The omission of optional input constructions in an "actual parameter" (those marked by a the * in "formal parameter") which are the subject of check-signatured or check-signature cause these primitives to return false. Optional output constructions are output if and only if their signed construction is the subject of a sign primitive. Any signatured constructions appearing as input will be output with an additional signature if they are the subject of a sign primative -even though the construction name does not appear in an output section. The following identity provides an example of some of the template primitive functions. It simply asserts that sealing and signing are inverses when keys created from the same seed are used. 61 if s =create-seed() then m=unseal (seal (m, create-public (s)), create-private (s)) The following are definitions of the templat e pr1m1 · ·t·1ves: sign(signed<a:any-type, · · · >. k:private-key) ... Optio.nal outp~t parameters are output iff their signed struc. ture 1s the subject of a sign primitive. seal(sealed<a:any-type, · · · >. k:public-key) ... Must be applied ~o any_ output structure that is of type sealed if that s~ructure Will be mcluded in D-function output. The public key k 1s used to perform the encryption. unseal(sealed<a:any-type, k :private-key) ... Makes accessible {but does not actually return) the unsealed, i.e. un-encrypted, form of the input structure s iff s was the output of an D-function which resulted from a seal primitive applied with the public key corresponding to the private key k. 0 • • ) , check-signature {s:signed<a:ny-type · k :public-key) ... boolean Checks the digital signature of the subject input structure s by decrypting it with the public key k and checking for the redundancy required by convention, and returns true iff the signature passes the test. o 0 ), check-signatured(s:signatured<any-type · · · >. k:set of public-key, m :integer) ... boolean Returns true iff a set of digital signatures of the subject input structure s can be checked as having been formed by holders of m private keys corresponding to m of the public keys contained in the set of keys k (i.e . 3p:set of public-key ~cardinality (p) = m 1\ p C k 1\ \7'n:public-key ~ if n E:. p then check-signature (s, n)ll latest-signature (s:signatured<any-type · · · >) .... time . . . Returns the most recent timestamp contamed m the s1gnatures of s. earliest-signature (s:signatured<a:ny-type · ·· >)--time . Same as latest-signature except the time of the earliest. OG §6 Synchronized D-functions Presents the remainder of the sp ifi t· ec ca 1on language and uses it to define the major D-functions of the proposed design. The D-functions presented in this section define all the ·synchronized actions performed by the network. These allow for consensus by the nodes on the state of the network, and implement all the change s m · ne t wor k s t a t us. F"lgure 1 shows the D-functions which change the status of individual nodes, such as by certifying them into the network, removing nodes from the network, and restarting a disabled node. The CHANGE_KEYS D-function of the figure allows a set of nodes to each change their public keys and receive new partial keys from the other nodes, once the new partials have been sealed with the receiving node's new keys. One other G-function, not shown in the figure, has an impact on the network status. It establishes the minimum values of important system parameters. Properties of the synchronization mechanism are demonstrated in Chapter VII. For the present purposes, it is important to notice that synchronization is provided by a cycle counter, CYCLE, maintained by each node . Each node can perform the action of only one synchronized Q-function call for each successive cycle. A majority of present nodes must each sign a template which defines every synchronized D-function call and the numbered cycle during which it is to be performed. No node signs more than one template during a single cycle. This arrangement ensures that nodes perform exactly the same D-function call during each cycle number. In particular, the CONSENSUS_ V-FUNCTJONS of all nodes in a particular cycle are guarantee to be identical. Chapter II gave a description of three levels of trustees: trustees at level 1 are not in a position to compromise system security, but are able to perform · t the system's reliability; trustees the day to day operations necessary o ensure 63 at level 2 establish policy and make security r 1 t d .. e evan ec1s10ns; trustees at level 3 are not part of the mechanism of this chapter b t . . • u are constdered m Chapter VII as mentioned above. The present section is di ' d d · Vl e mto those D-functions • callable by trustees at level 1, and those callable by t rus t ees a t 1evel 2. Before any trustee level 2 D-function call can be m a d e, h owever, tt · must be proposed: the definition of the security relevant parts of the call must be included in a trustee level 1 call to PROPOSE, which takes up one cycle. After this call has been made, a delay of length cooling-off-interual is enforced before the trustee level 2 action can be performed, by the corresponding trustee level 2 call. Any other actions may occur during intermediate cycles, and the trustee 2 level call can be blocked from ever occurring by the CANCEL-PROPOSAL synchronized a- function. The following two subsections provide the details of each of these two kinds of synchronized D-functions. Before the D-functions can be presented, however, the remainder of the specification language must be described. 0-function Syntax and Semantics . D-functions are composed of five major parts, roughly following the the structure put forward by Parnas [72). For the purposes of the present work, the simple input parameter list of the Parnas notation has been extended into optional input and output parts, which use the template mechanism described in the previous section. The third part of an a- function is merely for documentation. The fourth part lists a series of named exception conditions, all of which are checked sequentially. If all the checks are successful, then the effects part (the fifth part) is performed. Some of the statements which make up the effects part are boolean expressions. They have the effect of changing their constituent V-functions or formal · t ue Other statements do not parameters to values which make the expresston r · functions with side effects. · T return values, but rather are composed of prtml lVe t' All values of V-functions There . is no implied sequential order of execu lon. within the effects part represent t h e va1ue 0 f the v-function after the entire a- L 64 function is completed. Those Y-functions w h ose names a . smgle . re enc 1osed m quotes represent the value of the V-function before the The foliowing productions give the syntax of D-f call to the D-function. t· .. unc lon defimbons and their five parts: 0-function -+header input output comme n t excep t'tons effects . h ea d. er 'Lnput comment exceptions effects I header output comment exceptions effects header -+name :0-function input -+ Input: template output -+ Output: template comment -+Comment: wildcard exceptions -+ Exceptions: exception-list exception-list -+ exception-list ,exception I exception exception -+ name : boolean-expression effects -+ Effects: statement statement -+ boolean-expression I ~statement-list J I if boolean-expression then statement I if boolean-ex]Jression then statement else statement with name [expression ]statement statement-list -+ statement-list , statement I statement boolean-expression -+ ~boolean-expression I (boolean-expression) I boolean-primitive-function(expressio'Tirlist) I expression predicate expression I if boolean-expression then boolean-expression I if boolean-expression then boalea'Tirexpression else boolean-expression qua.ntifier nrune :elementary·type ~boolean- expression J I quantifier name :elementary-type quantifier nctme :elementan.rtype ~boolean-expression J expression -+ name I 'name •I expression operator expession I (expression) I name [expression] I name [expressian][expression] I let name = expression I with name [expression]expression I primitiv e-Junc tion ( expre s sian-list) expressio'Tirlist -+ expressio'Tirlist, expression I expression · h t ary variables within The keyword "let" is used to establis empor a- functions to avoid re-writing long expressions. The keyword "with" is used, much as in some programming languages • to extend the qua l'fi t· 1 ca wn of a name · d ex ) over an (in this case, a part of a construction selected by a part'tc u 1ar 1n expression. Trustee 2 D-functions There are three trustee level 2 D-functions. The CERTIFY function is used to bring new nodes into the network, as can be seen in Figure 1. This function is critical to the security of the entire system because if sufficient corrupted or even subverted nodes (see Chapter III) are brought into the network, then many of the security measures are useless. It can also be used to establish and modify a set, for each non-applied node, of nodes that the node can replace during a restart. (This might be used in an application where some nodes have data so sensitive that some vaults should never be able to access it.) The SET_MJNIMA function is also very important. It establishes the minimum margin (the significance of which is discussed in Chapter Vll), the minimum quorum of present nodes required for system operation, and the amount of time a node will wait to participate before it erases its own secret. v- function values. All three of these parameters determine the difficulty of the various attacks which could be perpetrated against the system. The final level 2 function is REMOVE_NODES. It simply allows nodes to be taken out of the network, as illustrated in Figure 1. One thing to notice about these func~ion definitions is that some of the latter exceptions and initial effects are the same. These common mechanisms are used to establish synchronization. When one of these functions is called and the ANNOUNCEMENT template does not have signatures from a majority of present nodes _(and the present node has not added its signature to an announcement of the current cycle), then the node simply adds its signature to the announce- uu ment and returns; when one such function is call d d th . . . ere are suff1c1ent stge an natures on the announcement, the node changes to phase 1 of the next cycle and performs the required action. Thus • t o per f orm a particular synchronized action as a particular cycle, at least a majority of present nodes in phase 1 of that cycle must first be called to obtain sufficient signatures on the desired announcement, and then this announcement can be used in subsequent calls to cause any node to perform the synchronized action. The following are the detailed function definitions: CERTIFY: G-function Input: ANNOUNCEMENT:signatured <NODE_CERTIFIED :node-id NODE_KEY: public-key, APPLICATION_KEY:public-key, node-id, TRUSTEES_SUPPLYING :set of node-id NODES_RESTARTABLE :set of TRUSTEES _PART/ALS :table[node-id] of TR USTEE_PARTIALS : scaled <:table[node-id] of partial-key>, PROPOSAL-CYCLE-# :integer, CYCLE = CYCLE-# :integer, COMPRESSED_HJSTORY = :integer, certify= :announcement-kind>, PROPOSAL: signatured <NODE_CERTIFIED:node-id NODE_KEY: public-key, APPL/CAT/ON_KEY:public-key, NODES_RESTARTABLE :set of node-id LATEST_T/MESTAMP:time, PROPOSAL-CYCLE-# :integer, propose-certify= :proposal-kind> Comment: The set of nodes the NODE_CERTIFIED is allowed to restart is changed to NODES_RESTARTABLE. If the NODE-CERTIFIED node id is not in NODES_/N_ USE. then it becomes included in NODES_JN_ USE. and the NODE-KEY and APPL/CAT/ON_KEY parameters input are used to establish table entries corresponding to the new node. All nodes change the set of nodes the NODE_CERTIFIED is allowed to restart to NODES_RESTARTABLE. If a node's own id appears in its NODES_RESTARTABLE then it is allowed to be 67 The NODE-CERTIFIED recovers the OWN_TRUSTEE PARTIALS needed by merging the TRUSTEE-PARTIALS input by a trustee-8-quorum. The OWN_TRUSTEE_PARTIALS that are no longer needed are erased. APPLYed. that are Exceptions: BAD-NODE-CERTIFIED : NODE-CERTIFIED E: USED_NODE-IDS PROPOSAL_NOT-PENDING : PROPOSALCYCLE_fl ~ PROPOSALS-PENDING INS UFFICIENLTR USTEE-2-SIGNATURES : ~ che ck-signrzture d (ANNOUNCEMENT-DEFINITION, trustee-2-publics, trustee-2-quorum) INSTANT-ALREADLSIGNED-ANNOUNCEMENT : PHASE= 2/\ ~(let SIGNATURES_OF_MAJORITY_OF_PRESENTS check-signrztured(ANNOUNCEMENT, ~V'n: node-id ~ ifn E: PRESENT then NODE_PUBLICS[n]jj. MAJORITY)) = INSTANT_NOT_SIGNATORY: ~ 3 K:public-key ~k E: ALLOWN_NODE_PUBLICS /\ check-signrzture (PROPOSAL, k)j TOO_EARLY: now -LATEST-TIMESTAMP< cooling-ojf-intervrzl Effects: if ~SIGNATURES_OF_MAJORITY_OF_PRESENTS then fsign(ANNOUNCEMENT, NODE-PRIVATE), PHASE= 2j else~ PROPOSAL-CYCLE-# ~ PROPOSALS_PENDING, CYCLE= 'CYCLE'+l, PHASE= 1, COMPRESSED-HISTORY= compress('CONSENS US_ V-FUNCTJONS '), CERTIFICATION[NODE_CERTIFIED] = NODES_RESTARTABLE, if NODE-CERTIFIED~ 'NODES_IN_USE' then fNODE_CERTIFIED E: NODES_/N_ USE, APPLICATION_PUBLICS[NODE_CERTIFIED] =APPLICATION_KEY, NODE_PUBLICS[NODE_CERTIFIED] =NODE-KEY, LAST_ CHANGES[NODE-CERTIFIED] = 0, SUB -PARTIALS_REMAINING[NODE_CERTIFIED] =Oj, if NODE-CERTIFIED= OWN_NODE then ~V'k:node-idf if k E: TRUSTEES-SUPPLYING then unseal(TRUSTEES'_PARTIALS[k] , NODE_PRIVATE)j, V'r:node-id ~ if r E: NODES_RESTARTABLE /\ r ~ 'CERTIFICATION'[OWN_NODE] then = OWN_TRUSTEE_PARTIALS[r] merge-przrtials( if k E: TRUSTEES-SUPPLYING then with TRUSTEES'-PARTIALS[k] fTRUSTEE_PARTIALS[r Jlll ), fV'k : node-id~ \:tn:node-id ~if n n t 'CERTIFICATION'[OWN_NODE] /\ NODES-RESTARTABLE then OWN_TRUSTEE-PARTIALS[n] = errzsedlB E: 68 sET-MINIMA: D-function Input: ANNOUNCEMENT:signatured <NEW_M/NIMUM_QUORUM :integer, NEW_M/N/MUM_MARGIN:integer, NEW _s U/ C/DE_/NTERVAL :integer, PROPOSAL-CYCLE-# :integer, CYCLE = CYCLE_# :integer, :integer, set-minima= :announcement-kind>, PROPOSAL :signatured COMPRESSED-HISTORY= <NEW_M/NIMUM_QUORUM :integer, NEW_M/NIMUM_MARG/N :integer, NEW _s U/C/DE_/NTERVAL :integer, LATEST_T/MESTAMP :time, PROPOSAL-CYCLE-# :integer, propose-set-minima= :proposal-kind> Comment: The V-functions holding the minimum values are changed to the values of the corresponding parameters. The new minima must not be larger than a possible current actual as opposed to minimum value. Exceptions: NEW_M/N!MUM_MARG/N_TOO_SMALL : NEW_M/N/MUM_MARGIN <1 NEW_M/NIMUM_MARG/N_TOO_B/G ; NEW_M/N/MUM_MARG/N >MARGIN NEW_M/NIMUM_QUORUM_TOO_B/G : NEfLMINIMUM_QUORUM PROPOSALNOT_PENDING : PROPOSAL-CYCLE_# t > QUORUM PROPOSALS-PENDING INSUFF/C/ENT_TRUSTEE_'LS/GNATURES: ~check-signatured (ANNOUNCEMENT-DEFINITION, trustee-2-publics, trustee-2-quorum) /NSTANLALREADLS/GNED-ANNOUNCEMENT: PHASE= 21\ ~(let S/GNATURES_OF_MAJOR/TLOF_PRESENTS check-signatured(ANNOUNCEMENT, ~Vn:node-id ~ if n E: PRESENT then NODE_PUBLICS[n]jj, MAJORITY)) = INSTANLNOLS/GNATORY: ~:3K : public-k:ey ~k E: ALL_OWN_NODE_PUBLICS 1\ check-signature (PROPOSAL, k)l TOO-EARLY: now - LATEST_T/MESTAMP < cooling-nff-interual Effects: if ~SIGNATURES_OF_MAJOR/TLOF_PRESENTS then ~sign(ANNOUNCEMENT, NODE-PRIVATE), PHASE= else~ PROPOSAL-CYCLE-# t PROPOSALS-PENDING, CYCLE= 'CYCLE'+l, PHASE= 1, COMPRESSED-HISTORY= compress('CONSENSUS_ V-FUNCTIONS '), 2l 69 = NEPI_MJNIMUM_QUORUM, MINIMUM_MARGIN = NEW_MJNIMUM_MARGIN, MINIMUM_QUORUM SUICIDE-INTERVAL= NEPI_SUIC!DE_JNTERVAL~ REMOVE-NODES: D-function Input: ANNO UNCEMENT :signatured <NODES_TO_REMOVE:set of node-id PROPOSAL_CYCLE_fl :integer, CYCLE = CYCLE-# :integer, COMPRESSED_HJSTORY =:integer, remove= :announcement-kind>, PROPOSAL :signatured <NODES_TO-REMOVE:set of node-id LATESLTIMESTAMP :time, PROPOSAL-CYCLE-# :integer, propose-remove = :proposal-kind> Comment: The node ids of the NODES_TO_REMOVE are removed from NODES_fN_USE, and all secret table entries for the NODES_TO_REMOVE are erased. The removed nodes commit suicide. Exceptions: NO_SUCH_NODE_JN_USE: ~NODES-REMOVED C NODES_JN_ USE fn E: NODES-REMOVED 1\ n E: PRESENT PROPOSALNOT_PENDING: PROPOSAL-CYCLE-# t PROPOSALS-PENDING REMOVJNG_PRESENT: 3n:node-id INSUFFICIENT_TR USTEE-2-SIGNATURES: ~check-signatured (ANNOUNCEMENT-DEFINITION, trustee-2-publics, trustee-2-quorum) INSTANT-ALREADLSIGNED-ANNOUNCEMENT: PHASE= 21\ ~(let SJGNATURES_OF_MAJORITLOF_PRESENTS = check-signatured (ANNOUNCEMENT, ~ 'v"n:node-id ~ if n E: PRESENT then NODE_PUBLICS[n]! l. MAJORITY)) INSTANLNOT_SJGNATORY: ~ 3 K:public-key ~k E: ALL_OWN_NODE_PUBLICS 1\ check-signature (PROPOSAL, kH TOO_EARLY: now -LATEST-TIMESTAMP <cooling-off-interval Effects: if ~SIGNATURES_OF_MAJORITLOF-PRESENTS then !sign(ANNOUNCEMENT, NODE-PRIVATE), PHASE= 2~ else! PROPOSAL-CYCLE-# t PROPOSALS-PENDING. CYCLE= 'CYCLE'+l, PHASE= 1, COMPRESSED-HISTORY= compress('CONSENSUS_ V-FUNCTIONS '), NODES_IN_USE = 'NODES_IN_USE'- NODES_TO_REMOVE, = USED-NODE_IDS 'USED_NODE_IDS' u NODES_TO_REMOVE, APPLIED = 'APPLIED'- NODES_TO_REMOVE, 'v"n:nodc-id f if n E: NODES_TQ_REMOVE then fPARTIAL_KEYS[n] =erased, 'v"i:integer f if 1 ~ i~ SUB-PARTIALS_REMAJNING[n] then fSUB-PARTIALS[n][i] erasedllll if OWN_NODE E: NODES_TO_REMOVE then suicide (O)l = Trustee 1 D-functions The PROPOSE and CANCEL_PROPOSAL functions were discussed above as they cross over the boundary between trustee level 1 and trustee level 2. The remaining functions covered in this section are illustrated in Figure 1. The APPLY function takes any suitably certified node in a "veteran" state (i.e. a node that has been present before), and makes it "applied," that is dedicates it to a particular application and disqualifies it from being the replacing node in a restart. The CHANGE_PRESENT function transfers nodes between the present and participated states, and also may change the current majority. The RESTART function was touched on in Chapter IV, and is simply a way for a replacing node to resume the application processing of the disabled replaced node. The PARTICIPATE function can be used to transfer a single node from some state outside the participated state to the participated state, an effect which is usually achieved by a key change. The remaining two functions are relate.d. First, the CREATE-KEYS function is called and results in each node forming a new set of keys, and outputting the appropriate public keys. These public keys are then used in conjunction with un-synchronized D-functions, described in the following section, to distribute new partial and sub-partial keys among the nodes hoping to participate in the key change. Other synchronized a-functions may be taking place while these 71 keys are exchanged. Finally, during some later cycle, the CHANGE_KEYS a- function is called. It defines the new set of participated nodes and causes all business of the network to be conducted under the new keys. Again, there are common exceptions and parts of the effects which provide synchronization. The function definitions are as follows: PROPOSE: D-function Input: ANNO UN CEMENT_DEFINITION:signatured <PROPOSALDEFINITION: * <NODE_CERTIFIED :node-id NODE-KEY:public-key, APPLICATION_KEY:public-key, NODES_RESTARTABLE :set of node-id>, *<NEW_MJNIMUM_QUORUM :integer, NEW_MJNIMUM_MARGIN :integer, NEW_SUJCJDE_JNTERVAL :integer>, * <NODES_TQ_REMOVE:set of node-id>, KJND_QF_PROPOSAL :proposal-kind CYCLE = CYCLE-# :integer, COMPRESSED-HISTORY= :integer, propose= :action-kind> , Output: PROPOSAL :signed <PROPOSALDEFINITION:, LATEST_T/MESTAMP :tim.e, 'CYCLE' = CYCLE_fl :integer, KIND_QF_PROPOSAL :proposal-kind> Comment: A Signed copy of a definition of the proposed action, PROPOSAL, is output which includes the latest single timestamp of the quorum of nodes signing the announcement. Exceptions: INS UFFICIENLTR USTEE-LSIGNATURES: ~check-signatured (ANNOUNCEMENT , trustee-1-publics, trustee-1-quorum) INSTANT-ALREADLSIGNED_ANNOUNCEMENT: PHASE= 21\ ~(let SIGNATURES_QF_MAJORITLOF_PRESENTS = check-signatured(ANNOUNCEMENLDEFINITION, ~'dn: node-id f if n c PRESENT then NODE-PUBLICS[n]ll. MAJORITY)) Effects: 72 if ~SJGNATURES_OF_MAJOR!TY_OF_PRESENTS then ~sign (ANNOUNCEMENLDEFINITION) , PHASE= 2~ else~ CYCLE= 'CYCLE'+1, PHASE= 1. COMPRESSED_HJSTORY = compress('CONSENSUS_ V-FUNCTIONS '), CYCLE-# E PROPOSALS_PEND!NG, LATEST-TIMESTAMP= latest-signature (ANNOUNCEMENT-DEFINITION), sign(PROPOSAL, NODE_PRJVATE)~ CANCEL-PROPOSAL: G-function Input: ANNOUNCEMENT_DEFINITION :signatured <PROPOSALS_TO_CANCEL :set of integer, CYCLE = CYCLE-# :integer, COMPRESSED_HJSTORY = :integer, cancel= :action-kind> Comment: The PROPOSALS_TO_CANCEL are removed PROPOSALS_PENDING and therefore can no longer be used. from Exceptions: BAD-PROPOSALS: ~PROPOSALS_TO_CANCEL!: PROPOSALS_PENDJNG INSUFFICIENT_TR USTEE_LSIGNATURES : ~check-signatured (ANNOUNCEMENT, trustee-1-publics, trustee-1-quorum) JNSTANT-ALREADLSIGNED-ANNOUNCEMENT : PHASE= 2/\ ~(let SIGNATURES_OF_MAJORITLOF_PRESENTS check-signatured (ANNO UN CEMENT_DEFINITION, ~ "v'n:node-id ~ ifn E PRESENT thenNODE_PUBLJCS[n]~l. MAJORITY)) = Effects:· if ~SIGNATURES_OF_MAJORITY_OF_PRESENTS then ~sign (ANNOUNCEMENT-DEFINITION), PHASE= 2~ else ~ CYCLE= 'CYCLE'+l, PHASE= 1, COMPRESSED-HISTORY= compress('CONSENSUS_ V-FUNCTIONS '), PROPOSALS_PENDING =PROPOSALS-PENDING- PROPOSALS_TO_CANCEL~ 73 APPLY: D-function Input: ANNOUNCEMENT-DEFINITION:signatured <NODES_TO_APPLY:set of node-id CYCLE =CYCLE_ff :integer, COMPRESSED-HISTORY= :integer, apply = :action-kind> Comment: The identified node(s) are added to APPLIED, and all their certifica_tion is removed. They expunge their own set of trustee partials. The subJect nodes can now adopt an application, and can no longer be used as the replacing node in a restart. Exceptions: BAD-NODES : ~NODES_TO-APPLY C: NODES_IN_USE ALREADY-APPLIED : 3n:node-id !n E: NODES_TO-APPLY /\ n E: APPLIED~ INADEQUATE_CERTIFICATION: ~ 3n:node-id !n E: NODES_ TO-APPLY/\ n t. CERTIFICATION[n] INS UFF!CIENLTR USTEE_LSIGNATURES : ~check-signatured (ANNOUNCEMENT , trustee-1-publics, trustee-1-quorum) INSTANT-ALREADY-SIGNED-ANNOUNCEMENT: PHASE= 2/\ ~(let SIGNATURES_OF_MAJORITY_OF_PRESENTS = check-signatured(ANNOUNCEMENT_DEFINITION, !'Vn:node-id ! if n E: PRESENT then NODE_PUBLICS[n]ll. MAJORITY)) Effects: if ~SIGNA TURES_OF_MAJORITY_OF_PRESENTS then !sign(ANNOUNCEMENT_DEFINITION) , PHASE= Zl else! CYCLE= 'CYCLE'+l, PHASE= 1, COMPRESSED-HISTORY= compress('CONSENSUS_ V-FUNCTJONS '), Va:node-id! if a E: NODES_TO-APPLY then CERTIFICATION[ a] if OWN_NODE E: NODES_TO-APPLY then "v"n:node-id ! ifn E: CERTIFICATION[OWN_NODE] then OWN_TRUSTEE_PARTIALS[n] =erased!. APPLIED= 'APPLIED' u NODES_TO-APPLYl CHANGE_PRESENT: D-function Input: ANNOUNCEMENT_DEFINITION:signatured <NODES_TO_BECOME-PRESENT:set of node-id NODES_TO_BECOME-ABSENT:set of node-id NEW_MAJORITY:integer, =empty l, 74 CYCLE = CYCLE-# :integer, COMPRESSED_HJSTORY =:integer, change-presents= :action-kind> MIN!MUM_PARTIALS_RECEJVED :signatured <KEY_CREATJON_# = :integer, node-id :transfer-kind> NODES_RECEJVED-FROM :set of partials-received = Output: *SUB-PARTIALS_RELEASED:set of partial-key Comment: The nodes to be made present are made present, the nodes to be made absent are made absent, and the majority assumes the new value provided. The new configuration must be compatible with the MJN!MUM_MARGJN, and the QUORUM. The MINIMUM_PARTIALS_RECEIVED signed by the NODES_TO_BECOME_PRESENT ensure that the nodes made present have received all the partial keys they may require. If the NEW-MAJORITY is less than the current quorum, but not less than the minimum quorum, then sub-partials are publicly released so that the effective quorum is lowered to the NEW_MAJORITY. Exceptions: NEW_MAJORJTY_TOO_SMALL : NEW-MAJORITY< MINIMUM_ QUORUM = NEW_MAJORJTY_TOO_B/G : NEw_MAJORITY >(let NEW_NODE_COUNT cardinality(PRESENT) +cardinality (NODES_TO_BECOME_FRESENT)cardinality (NODES_TO_BECOMK.ABSENT)) NEW_MAJOR/TY_TOO_SMALL : MINJMUM_QUORUM > NEW_MAJORITY INSUFFICIENLMARGIN: NEW_NODE_COUNT > (NEW_MAJORITY x 2)- MINIMUM_MARGIN NOT_ABSENT: ~NODES_TO_BECOME_PRESENT (ABSENT NOT_PRESENT : ~NODES_TO_BECOME-ABSENT (PRESENT INSUFFICIENT_MJNIMUM_PARTIALS_RECEIVED-FROM_S/GNATURES: ~check-signatured (MINIM UM_PARTIALS_RECEIVED , NODE_PUBLJCS[(PRESENT u NODES_TO_BECOME_FRESENT)NODES_ TO_BECOME_ABSENT ], NEfLNODE_COUNT) INS UFF!CIENT_MINIM UJ.LPARTIALS_R ECEIVED_FROM : 3 n :node-id ~n E: NODES_TO_BECOME_PRESENT 1\ n ~ NODES-RECEIVED-FROM l INSUFFICIENT-.SUB-PARTIALS: 3n:nodc-id ~n E: NODES_JN_USE 1\ 3i:integer ~LAST_CHANGES[n] = i l \ SUB-PARTIALS_REMAINJNG[n] < QUORUMS[i]-NEW_MAJORITYll INSUFFICIENT_TR USTEE-LSIGNATURES: ~check-signatured (ANNOUNCEMENT, trustee-1-publics, trustee-1-quorum) INSTANT-ALREADY-SIGNED-ANNOUNCEMENT: PHASE= 21\ ~(let SIGNATURES_OF_MAJORITY_OF-PRESENTS = _ check-signatured(ANNOUNCEMENT-DEFINITION, ~~n:node""id ~ if n E: PRESENT then NODE_PUBLICS[n]ll, MAJORITY)) rv Effects: if ~SIGNATURES_OF_MAJORITLOF-PRESENTS then ~sign(ANNOUNCEMENLDEF!NITION), PHASE: 8J else~ CYCLE= 'CYCLE'+l, PHASE= 1, COMPRESSED-HISTORY= compress('CONSENSUS_ V-FVNCTJONS '), PRESENT= ('PRESENT'-NODES_TO.JJECOME-ABSENT) lJ NODES_TO_BECOME_PRESENT, MAJORITY= NEW_MAJORITYJ if MAJORITY< QUORUM then 'Q-'n:node-id ~if n E: NODES_JN_ USE 1\ (let NS_QUORUM = QUORUMS[LAST_CHANGES[n]]) > NEJL!IAJORITY then HSUB-PARTIALS_REMAINING[n] 'SUB-PARTIALS_REMAINING'[n]NS_QUORUM-NEW_MAJORITYj, f'Q-'i:integer ~if NS_QUORUM < i~ NEW-MAJORITY then SUB-PARTIALS[n] ['SUB-PARTI ALS_REMAIN IN G '[n] -iNEW_MAJORITY] E: SUB -PARTIALS-RELEASED~~ J~ = RESTART: D-function Input: ANNOUNCEMENT_f)EFJNIT/ON:signatured <REPLACED-NODE :node-id REPLACING_NODE :node-id CHECKPOINT: (see ISSUE_CHECKPOINT ), CYCLE =CYCLE-II :integer, COMPRESSED-HISTORY= :integer, restart= :action-kind> Output: *PARTJAL_FOR-.A.SSUME_APPLICATION:signed <REPLACED_NODE:node-hl. REPLACING_NODE :node-id PARTJAL_SUPPLIED :sealed<partial-key>, RESTART_to_ASSUME_APPLICATION =:transfer-kind> Comment: The replaced node, which must be applied and not present, is in effect REMOVE_NODESed. The replacing node must be certified to replace the replaced node, and it becomes applied. The replacing node _is supplied with partials for the replaced node. These are used m ASSUME_APPLICATION to recover the replaced node's application data and messages sent after the last checkpoint. Exceptions: BAD-REPLACED-NODE: REPLACED-NODE E: PRESENT V REPLACED-NODE~ NODES_IN_ USE BAD-REPLACEMENT-NODE: REPLACING-NODE REPLACING_NODE E: APPLIED t. PARTICIPATED INADEQUATE_CERTIFICATION: REPLACED-NODE~ CERTIFICATION[REPLACING_NODE] INS UFFICIENLTR USTEE_LS/GNATURES: ~check-signatured (ANNOUNCEMENT, trustee-1-publics, trustee-1-quorum) = INSTANT-ALREADLS/GNED-ANNOUNCEMENT: PHASE 2/\ ~(let S/GNATURES_OF_MAJOR!TLOF_PRESENTS = check-signatured(ANNOUNCEMENLDEF!NIT!ON, ~'dn: node-id ~if n E: PRESENT then NODE_PUBLICS[n]l!. MAJORITY)) Effects: if ~SIGNATURES_OF_MAJORITY_OF_PRESENTS then ~sign(ANNOUNCEMENT_DEF!NIT!ON), PHASE= 2! else~ CYCLE= 'CYCLE'+l, PHASE= 1, COMPRESSED_HISTORY = compress('CONSENSUS_ V-FUNCTIONS'), REPLACED-NODE~ NODES_IN_ USE, REPLACED-NODE E: USED_N ODE_IDS I APPLICATION_PUBLICS[REPLACING_NODE] = APPLICATION_PUBLICS[REPLACED_NODE], REPLACING_NODE E: APPLIED, REPLACED_NODE ~ APPLIED, PARTIAL_KEYS[REPLACED-NODE] = erased, 'Vi:integer ~if 1 ~ i~ SUB-PARTIALS_REMAINING[n] then ~SUB-PARTIALS[REPLACED_NODE][i] = era.sedj, = PART/AL_SUPPLIED 'PARTIAL-KEYS '[REPLACED-NODE], seal(PARTIALSUPPLIED, NODE_PUBL!CS[REPLACING_NODE]), sign.(PARTIAL_FOR_ASSUME_APPLICATION, NODE-PRIVATE), if OWN_NODE = REPLACING_NODE then 'Vn:node-id ~if n E: CERTIFICATION[REPLACING_NODE] then OWN_TRUSTEE-PARTIALS[n] = erasedn, if 0 WN _NODE = REPLACED-NODE then suicide ( 0) l I pARTICIPATE: D-function Input: ANNOUNCEMENT_DEFINITION:signatured <NODE_PARTICIPATED :node-id NODES_RECEIVED_FROM:set of node-id PARTIALS_ALR EADLR ECEIVED :signatured <KEY_CREATION_# = :integer, NODES_RECEIVED.J'ROM:set of node-id partials-received :transfer-kind>, CYCLE = CYCLE-# :integer, = COM PRES SED_HIS TORY= :integer, participate = :action-kind> Output: *SUB-PARTIALS._SUPPLIED:signed <CYCLE = CYCLE_# :integer, SUB-PART/ALS:sealed<:table[node-id] of partial-key>, PARTICIPATE_to_NEW_PARTICIPANLRECEIVE transfer-kind> =: *PARTIALS-AND_SUB-PARTIALS:table[PARTICIPATED] of PARTIAL_AND_SUB-PARTIALS :signed <RECIPIENT:node-id PARTIAL :sealed< partial-key>, NUMBER_OF_SUB-PARTIALS:integer, SUB-PARTIALS :sealed<table[integer] of partial-key>, PARTICIPATE_to_RECEIVE_NEW_PARTICIPANT =: transfer-kind> Comment: Participated nodes each supply the node to be participated with sub-partials of every node for which the node to be participated is missing partial keys . The node to be participated issues partials and subpartials for itself to all the participated nodes, just as in issue-partials. Two unsynchronized a-functions are allowed: RECEIVE_NEW_PARTICIPANT for the participated nodes to pick up their partials and sub-partials (not as new), and NEW_PARTICIPANT_RECEIVE for the entering node to pick up a set of sub-partials. Exceptions: BAD_NODE_PAJ?TICIPATED: NODE.YARTICIFATED E PARTICIPATED V NODE-PARTICIPATED ~ NODES_IN- USE INSUFFICIENT_SUB-PARTIALS: 3n:node-idtn E: NODES-IN_ USE 1\ LAST_CHANGES[NODE-PARTICIPATED] < LAST_CHANGES[n] 1\ SUB-PARTIALS_REMAINING[n] < lj BAD-ALREADY-RECEIVED-FROM_S/GNATURES: ~check-signatured (PARTIALS-ALREADLRECEIVED. NODE_PUBLICS[NODES_RECEIVED-FROM] V NODE_PUBLICS[OWN_NODE]. cardinality (NODES-RECEIVED-FROM+ 1)) I 78 JNSUFFICIENT_TRUSTEE_LSIGNATURES: ~check-signatured (ANNOUNCEMENT, trustee-1-publics, trustee-1-quorum) INSTANT......ALREADLSIGNED-ANNOUNCEMENT: PHASE= 21\ ~(let SIGNATURES_OF_MAJORITLOF_PRESENTS check-si~na.tured(ANNOUNCEMENLDEF!NITION, ~'<>~n: node-id ~ 1f n E: PRESENT then NODE_PUBLICS[n]!j. MAJORITY)) Effects: = if ~SIGNATURES_OF-MAJORITLOF_PRESENTS then ~sign (ANNOUNCEMENT_DEF!NITION), PHASE= 2j else ~ CYCLE= 'CYCLE'+1, PHASE= 1. COMPRESSED-HISTORY= compress('CONSENS US_ V-FUNCTJONS '), SUB -PARTIALS_REMAJNING[NODE-PARTICIPATED] = NUMBER_OF_SUB-PARTIALS, if 3n:node-i~n E NODES_IN_ USE 1\ LAST_CHANGES[NODE_PARTICIPATED] < LAST_CHANGES[n] then SUB-PARTIALS_REMAINING[n] = 'SUB -PARTIALS_REMAINING'[n]-1j if NODE-PARTICIPATED~ OWN_NODE then ~~ p :node-id ~ if p E PARTICIPATED 1\p ~SUB-PARTIALS[p] = ~ NODES_RECEIVED_FROM then SUB-PARTIALS[p]['SUB-PARTIALS_REMAINING'[p]], sea.l(SUB-PARTIALS[p]. NODE_PUBLICS[NODE-PARTICIPATED])!, sign(SUB-PARTIALS_SUPPL!ED, NODE-PRIVATE)!, else ~~ p:node-id l if p PARTICIPATED 1\p ~ NODES-RECEIVED-FROM then ~with PARTIALS-AND_SUBPARTIALS[p] E ~RECIPIENT =p, PARTIAL = forrrLJfla.rtia.l (p, PARTJAL_SEED, APPLICATION_PRIVATE, QUORUM), sea.l(PARTIAL, NODE_PUBLICS[p]), '<>~i:integer ~if 1 ~ i~ NUMBER_OF_SUBPARTIALS then ~SUB-PARTIALS[i] formrpa.rtia.l( p, PARTIAL-SEED, form-pa.rtia.l(i, PARTIAL-SEED, APPLICATION-PRIVATE, QUORUM) , QUORUM) sea.l(SUB-PARTIALS, NODE_PUBLJCS[p]])ll = sign(PARTIALAND-SUB-PARTIALS, NODE-PRIVATE)!, . 79 suicide ((earliest-signature (ANNOUNC'EMENT ) -DEFINITION + SUICIDE-INTERVAL)_ now())~~~ CREATE-KEYS: ~function Input: ANNO UN CEMENT-DEFINITION :signatured <NEFY-QUORUM :integer, NEW_SUB-PARTIALS-NEEDED :table[NODES_IN_USE] of integer, CYCLE CYCLE-II :integer, = COMPRESSED-HISTORY= :integer. create-keys= :action-kind> Output: NEW-KEYS: signed <KEY-CREATION_#= :integer, NEW-APPLICATION_PUBL!C :public-key, NEW_NODE_PUBLIC :public-key, CREATE_KEYS_ta_ISSUE_NEW_PARTIALS&CHANGE_KEYS = : transfer-kind> EXTENDERS :table[integer] of EXTENDER:signed <KEY-CREATION_#= :integer. INDEX :integer, EXTENS/ON:sealed<table[integer] of partial-key>. CREATE-KEYS_ta_NEW_PARTICIPANT_RECEIVE =: transfer-kind> Comment: New node and application keys are created. Also a new seed for the new partial keys, which will use the new quorum, is created. The initial number of sub-partials needed for each node is recorded. New publics are output. The issue new partials and receive new partials unsynchronized actions are allowed. This action may occur more than once to change the new quorum, even though no change to new keys has occurred. The set of nodes the instant node would allow to become participated in a CHANGE_KEYS is emptied. If a node is to become participated but lacks partials for some other node which is not going to be participated, then the first node must be the subject of a PARTICIPATE before a CHANGE_KEYS. Exceptions: NEW_QUORUM_TOO_SMALL : NEW_QUORUM <MINIMUM_ QUORUM INS UFF!CIENT-TR USTEE_LSIGNATURES: ~check-signatured (ANNOUNCEMENT, trustee-1-publics, trustee-1-quorum) INSTANT-ALREADY-SIGNED_ANNOUNCEMENT: PHASE= 21\ ~(let SIGNATURES_OF_MAJORITLOF_PRESENTS = check-signatured(ANNOUNCEMENT_DEFINIT!ON, l"v'n:node-id ~if n E: PRESENT then NODE-PUBLICS[n]ll. MAJORITY)) 80 Effects: if ~SIGNATURES_OF_MAJORITY_Qp_pRESENTS then ~sign (ANNOUNCEMENLDEFINITION), PHASE= 2f else l CYCLE= 'CYCLE'+l, PHASE= 1, COMPRESSED_HJSTORY = compress('CONSENSUS_ V-FUNCTIONS '), KEY_ CREATION_# = 'KEy_ CREATION_# '+1, QUORUMS[LAST_CHANGE + 1] = NEW_QUORUM, PARTIALS_RECEIVED_FROM =empty, APPLICATJON_SEED =create-seed(), NEW_APPLICATION_PRIVATE =create-private (APPLICATION_SEED), NEW_APPLICATION_PUBLIC =create-public (APPL!CATION_SEED), NODE-SEED= create-seed(), NEW_NODE_PRIVATE = create-private(NODE_SEED), NEW_NODE_PUBLIC = create-public(NODE_SEED), PARTJAL_SEED create-seed()f, = NEW_SUB-PARTIALS_REMAJNING =NE'rLSUB-PARTIALS_NEEDED, ~i:integer l if 1 < i~ NEW_SUB-PARTIALS_REMAINJNG[OWN_NODE] then ~/ : integer l if 1 < J < i then lwith EXTENDERS[i] UNDEX = i, EXTENSION[!]= form-partial( i, PART!AL_SEED, form-partial (J, PART!AL_SEED, NEW_APPLICATJON_PRIVATE, QUORUMS[LAST_CHANGE + 1]), QUORUMS[LAST_CHANGE + l])lll seal(EXTENSION, create-public (form-partial (i, PARTIAL-SEED, NEW_APPLICATION_PRIVATE, QUORUMS[LAST_CHANGE + 1]))), sign(EXTENDER, NEW_NODE_PRJVATE)f CHANGE-KEYS: D-function Input: ANNOUNCEMENT_DEFINITION:signatured <NODES_PARTICIPATING:set of node-id, EVERy_pARTICIFANTS_NE W_KEYS :table [node-id] of NEW_KEYs:JiioM_CREATE_KEYS :signed 81 <KEY_ CREATION_# = :integer, NE fLAPPL/ CATION_PUBL/C :public-key, NEW-NODE_PUBLIC :public-key, CREATE_KEYS_to_ISSUE_NEW_PARTIALS&CHANGE_KEYS =: transfer-kind> CYCLE = CYCLE-# :integer, COMPRESSED-HISTORY= :integer, change-keys = :action-kind> MINIMUM_PARTIALS_RECEIVED :signatured <KEY_ CREATION_# =:integer, NODES_RECEIVED_FROM :set of node-id partials-received = :transfer-kind> Comment: The new keys, partials and sub-partials for all the included nodes are changed to their new values that have previously been supplied. (Conflict between the supplied publics and any publics already received are ignored because this causes no real security problem, and if the afunction were blocked by a conflict, a single node could deadlock the system.) The new keys, partials, and sub-partials for all un-included nodes, except the present node, are erased. The set of participated nodes is changed to the included nodes. Exceptions: INSUFFICIENT-PARTICIPATION : ~PRESENT C NODES-PARTICIPATING BAD-PARTICIPANTS : ~NODES-PARTICIPATING C NODES_fN_ USE INVALID-NEW-KEYS : 3n:node-id ~n E: NODES-PARTICIPATING 1\ ~check-signature (EVERLPARTICIPANTS_NEW_KEYS[n], NODE-PUBLICS[n]) PARTICIPANTS_LACK_NON-PARTICIPANTS_PARTIALS :3p, n :node-id fp E: NODES_PARTICPATING 1\ n E: (NODES_IN_ USE-NODES-PARTICIPATING) 1\ LAST_ CHANGES~]< LAST_CHANGES[n]l INSUFFICIENT_MINIM UM_PARTIALS_RECEIVED_FROM_SIGNATURES: ~ check-signatured(MINIMUM_PARTIALS-RECEIVED, N ODE_P UBLI CS [NODES-PARTICIPATING], cardinality (NODES-PARTICIPATING)) INS UFFICIENLMINIM UM_PARTIALS_RECEIVED_FROM : ~NODES_PARTICIPATING C NODES-RECEIVED-FROM NEW_QUORUM_TOO_BJG : QUORUMS[LASLCHANGE + 1] >MAJORITY INS UFFICIENLTR USTEE-LSIGNATURES: ~check-signatured (ANNOUNCEMENT, trustee-1-publics, trustee-1-quorum) INSTANLALREADY_S!GNED-ANNOUNCEMENT: PHASE= 21\ ~(let SIGNATURES-OF_MAJORITLOF-PRESENTS = . check-signatured(ANNOUNCEMENT_DEFINITION, ~"dn: node-id ~if n E: PRESENT then NODE_PUBLICS[n]ll . MAJORITY)) Effects: . if ~SIGNATURES_OF-MAJORITLOF-PRESENTS then (sign(ANNOUNCEMENT_DEFINITION), PHASE= 2l else~ CYCLE= 'CYCLE'+l, PHASE= 1, COMPRESSED-HISTORY= compress('CONSENSUS_ V-FUNCTIONS'}, PARTICIPATED =NODES-PARTICIPATING, QUORUM= QUORUMS[LAST_CHANGE + 1], SUB-PARTIALS-REMAINING= NEW_SUB-PARTIALS_REMAJNING, NODE_PUBLICS[OWN_NODE] E ALL_OWN_NODE_PUBLICS, PARTIALS_RECEIVED_FROM = NODES_PARTICIPATING, V'p:node-id ~ if p E PARTICIPATED then ~with EVERY_PARTICIPANTS_NEW_KEYS[p] ~APPLICATION_PUBLJCS[p] =NEfLAPPLJCAT/ONYUBLJCj, NODE_PUBLICS[p] =NEW_NODEYUBLICj, PARTIAL_KEYS[p] = NEW_PARTIAL_KEYS[p], V'i:integer ~if 1 ~ i~ NEW_SUB-PARTIALS_REMAINING[p] then SUB-PARTIALS[p][i] = NEW_SUB-PARTIALS[p][i]jj, suicide ((earliest-signature (ANNOUNCEMENT_DEFJNITION) + SUICIDE-INTERVAL)- now(})j §7 Un-Synchronizcd 0-functions Presented are the remaining a-functions, which support the o- functions of the previous section and allow release of information. The previous section was concerned with synchronized D-functions, which are designed in such a way that every node will accept only the same sequence of calls and in the same order. The present section is concerned with the other D-functions: those which can be invoked in many possible orders. The fact that they can be used in a less structured way than those previously discussed does not mean that these Q-functions are an invitation to chaos. On the contrary, some of these Q-functions provide increased reliability and robustness of the network even in spite of the trustees. Others of these D-functions have no effect on a node's state, and are mer.e ly used to obtain signed and possibly sealed data about the node's state. Yet others are tied directly into the synchronized D- 83 functions, and merely act as extensions of these D-functions to allow additional rounds of information exchange. Synchronized D-function Support This subsection defines five un-synchronized D-functions. The first two are used between the initial CREATE-KEYS and the closing CHANGE-KEYS, as described in the previous section. The first of these, ISSUE_NEW_PARTIALS, takes as input the new public keys of a node released during CREATE_KEYS and outputs partial keys and sub-partial keys sealed with the new public key received. The second D-function, RECEIVE_NEW_PARTIALS, takes as input the output of this first D-function created by another node and simply records the partials and sub-partials after unsealing with its new private key. A second pair of D-functions serves a similar purpose, but is used following a PARTICIPATE D-function call. One D-function, RECEIVE_NEW_PARTICIPANT, is used by all but the node to be participated, and simply records the public, partial, and sub-partial keys released by the subject node during the PARTICIPATE. The other D-function of the pair, NEW_PARTICIPANT_RECEIVE, is used by the subject node to collect the sub-partials and extenders provided it by the nonsubjects during the PARTICIPATE. The fifth and final D-function, ASSUME-APPLICATION, allows the replacing node of a restart to assume the application key of the replaced node. The following are the unsynchronized supporting D-functions: 84- JSSUE-NEW-PARTIALS:D-function Input: SUPPLIER :node-id NEW_pUBLICS :signed <KEY_CREATION_# = :integer, SUPPLIER_NEW_NODE-PUBLIC:public-key, SUPPLIER_NEW_APPLICATION-PUBLIC:public-key, CREATE_KEYS_to_JSSUE_NEW_PARTIALS&CHANGE_KEYS transfer-kind> = : Output: PARTIAL-AND-SUB -PARTIALS :signed <KEY_ GREAT! ON_# =:integer, SUPPLIER:node-id PARTIAL: sealed< :partial-key>, SUB -PARTIALS :sealed< :table[integer] of partial-key>, ISSUE_NEW_PARTIALS_ta_RECE!VE_NEW_PARTIALS =: transfer-kind> Comment: The supplied new public application key is used to seal the partial and the number of sub-partials for each node established in CREATE_KEYS. Exceptions: INVALJD_SUPPLIER : SUPPLIER ~ NODES_/N_ USE, INVALJD_SUPPLIER_SIGNATURE : ~check -signature (NEW-PUBLICS, NODE_PUBL!CS(SUPPLIER)), Effects: PARTIAL= form-partial(SUPPLIER, PARTJAL_SEED, NEW_APPL!CAT!ON_PRJVATE, QUORUMS[LAST_CHANGE + 1]), seal(PARTIAL, SUPPLIER_NEW_NODE_PUBLIC), \:ti:integer ~if 1 ~ i~ NEW_SUB-PARTIALS-REMAINJNG[OWN_NODE] then ~SUB-PARTIALS[i] =form-partial (SUPPLIER, PARTJAL_SEED , farmrpartial (i, PARTJAL_SEED, NEW_APPLICATJON_PRIVATE, QUORUMS[LASLCHANGE + 1]) , QUORUM$[LAST_CHANGE + l])l. seal(SUB-PARTIALS, SUPPLIER-NEW_NODE_PUBLIC), sign(PARTIAL-AND_$UB-PARTIALS, NODE-PRIVATE) 85 RECEIVE-NEW_PARTIALS: D-function Input: SUPPLIER :node-id PARTIAL-AND-SUB-PART!ALS :signed <KEY_CREATION_# = :integer, OWN_NODE:node-id PARTIAL: sealed< :partial-key>, SUB-PARTIALS :sealed<:table[integer] of partial-key>. JSSUE_NEW_PARTIALS_to_RECE!VE_NEW_PARTIALS =: transfer-kind> Comment: The new partials and sub-partials output JSSUE_NEW_PARTIALS are recorded. Exceptions: by INVAL/D_SUPPLIER :SUPPLIER t NODES_fN_USE JNVALJD_SUPPLIER_SJGNATURE : check-signature (PARTIAL-AND_SUB-PARTIALS, NODE_PUBL!CS[SUPPLIER]} Effects: unseal (PARTIAL, NEW_APPLJCATJON_PRJVATE), NEW_PARTIAL-KEYS[SUPPLIER] =PARTIAL, unseal(SUB-PARTIALS, NEW_APPLICATION_PRIVATE) ~i: integer ~if 1 ~ i~ NEW_SUB-PARTJALS_REMAJNJNG[SUPPUER] then NEW_SUB-PARTJALS[SUPPLIER][i] SUB-PARTIALS[i]l, SUPPLIER e: PARTJALS_RECEJVED_FROM, = RECE!VE_NEW_PARTICIPANT:D-function Input: NODE-BECOM!NG-PARTICIPATED:node-id PARTIAL-AND-SUB -PARTIALS :signed <OWN_NODE = RECIPIENT:node-id PARTIAL:sealed<:partial-key>. NUMBER_OF_SUB-PARTIALS :integer, SUB-PART/ALS :sealed<:table[integer] of partial-key>, PARTICJPATE_to_RECEIVE_NEW_PARTICIPANT =: transfer-kind> Comment: The participated nodes making an addition~! node participa_ted are allowed to use this a-function to record the partials and sub-partials issued to them by the entering node during the BECOME_JJARTICIPATED. Exceptions: BAD_SJGNATURE: check-signature (PARTIAL-AND-SUB-PARTIALS NODE_PUBL!CS[NODE-BECOM!NG_PARTICIPATED]) I 86 Effects: unseal (PARTIAL, APPLICATION_PRIVATE), pARTI AL_KEYS [NODE_BECOM!NG_PARTICIPATED] = PARTIAL ~unseal (SUB-PARTIALS, APPL!CATION_PRIVATE) V'i~ if 1 ~ i~ NUMBER_OF_SUB-PARTIALS then I SUB-PARTIALS[NODE_BECOMING_PARTICIPATED][i] = SUB-PART!ALS[i]jj, NODE-BECOMING_PARTICIPATED E: PARTIALS_RECEIVED_FROM, NEW_PARTICIPANT_RECEIVE: D-function Input: SUB-PART/AL_SUPPLIERS:set of node-id ALLSUB-PARTIALS_SUPPLIED :table[SUB-PARTIALSUPPLIERS] of SUB-PARTIALS_SUPPLIED :signed <CYCLE = CYCLE_# :integer, SUB-PART/ALS:sealed<:table[node-id] of partial-key>, PARTICIPATE_to_NEW_PARTICIPANT_RECEIVE = : transfer-kind.> EXTENDERS :table[node-id] of EXTENDER: signed <KEY_ CREATION_# INDEX :integer, =:integer, EXTENS/ON:sealed< :table[integer] of partial-key>. CREATE_KEYS_to_NEW_PARTICIPANLRECEIVE = : transfer-kind> Comment: The node which has become participated is allowed to use this afunction to obtain the sub-partials issued it by the quorum of participated nodes during a PARTICIPATE, and thereby obtain a full set of partials and also · sub-partials. It is then able to list itself in its PARTIALS_RECEIVED_FROM, indicating it has received sufficient partials and allowing it to become present. Exceptions: NOT_ENOUGlLSUPPLIERS : cardinality(SUB-PARTIAL-SUPPLIERS) QUORUM . < BAD.....SUPPLIERS : ~SUB-PART/AL_SUPPLIERS c PARTICIPATED BAD.....SUPPLIER_SJGNATURE: 3n:node-id in E: SUB-PARTIAL-SUPPLIERS 1\ . ~check-signature (SUB-PARTIALS-SUPPLIED[n], NODE_PUBLICS[nB BAD-EXTENDER.....SIGNATURE : 3n:node-id ~LAST_CHANGES[OWN_NODE] < LAST_CHANGES[n] 1\ ~check-signature (EXTENDERS[n], NODE-PUBLICS[n]) l . WRONG-EXTENDER: 3n:node-id ~LAST_CHANGES[OWN_NODE] < LAST-CHANGES[n] A ~with EXTENDERS[n] 87 fiNDEX ¢. SUB-PARTIALS_REMAIN!NG[n]B Effects: 'v"s:node-td ~if s E: SUB-PARTIAL-SUPPLIERS then with ALL_SUB-PARTIALS_SUPPL/ED[s] unseal (SUB-PARTIALS, APPLICATION_PR!VATE) j, 'v"p:node-i.d ~if LAST_CHANGES[OWN_NQDE] < LAST_CHANGES[p] then PARTJAL_KEYS[p] = merge-partials('v"s:node-id ~if s E: SUB-PARTIAL-SUPPUERS then with SUB-PARTIAL_SUPPLIERS[s] !SUB-PARTIALS[p] jj ), 'Q/p:node-id ! if LAST_CHANGES[OWN_NODE] < LAST_CHANGES[:p] then ~with EXTENDERS[p] ~unseal(EXTENSION, create-private (PART!AL_KEYS[p])), f'v'i:integer ! if 1 ~i~ SUB-PART!ALS_REMA!N!NG[:p] then OWN_NODE E: SUB-PART!ALS[:p]l:i] = EXTENDER[i]jljl. PARTJALS_RECE!VED_FROM ASSUME_APPLICATJON: a-function Input: PARTIAL_SUPPLIERS :set of node-id PARTIALS_SUPPLIED :table[node-id] of PARTIAL :signed <REPLACED-NODE :node-id OWN_NODE = REPLACING_NODE:node-id.. PARTIAL-BUPPLIED :sealed<:partial-key>, RESTART_to_ASSUME_APPLJCATJON = :transfer-kind> CHECKPOINT: (see JSSUE_CHECKPOJNT) Comment: The replacing node of a restart is enabled to perform this operation, which involves receiving partials for the replaced node, and using them to obtain the saved application data from the checkpoint formed by the replaced node, and messages sent after the checkpoint was formed. Exceptions: BAD-SUPPLIERS: ~PART/AL_SUPPLIERS C NODES_JN_ USE BAD-BUPPLIER_S/GNATURES : 3n:node-id !n E: PARTIAL-SUPPLIERS 1\ ~with PARTIALS_SUPPLIED[n] ~check-signature (PARTIAL , NODE_PUBL!CS[n]) l Effects: 'v"n:node-id ~if n E: PARTIAL-SUPPLIERS then with PARTIALS_SUPPUED[n] unseal (PARTIAL-SUPPLIED, APPL!CATJQN_PRIVATE)j, 88 'Vn:node-id ~if n E: PARTIAL-SUPPLIERS then APPLICATION_PUBLICS merge-partials (with PARTIALS-SUPPL!ED[n]PARTIALSUPPLIED H = Information Releasing D-functions The last two D-functions are given in this subsection. Unlike the previous ~functions, they are not closely tied to any particular synchronized D-functions. They release information about the node's state, but do not alter its state. The PARTIALS-RECEIVED D-function allows a node to provide a signed statement about those nodes it has received current partial keys from. The JSSUE_CHECKPOINT D-function is unique in that it includes no input template, which means it does not check any signatures of input parameters, and thus can be freely called by anyone. This is appropriate because the output of this o- function provides, among other things, an authenticated snap-shot of the node's public state, which Chapter VII will show to be useful to those seeking to trust the network. Another use of checkpoints, that of saving enough of a node's state to make restart possible, was mentioned in Chapter IV. A further practical use of this D-function is to allow verification of the. state certified into a node, which can allow new nodes to skip over a possibly long prefix of synchronized o- function calls. The following are the information releasing un-synchronized D-functions: PARTIALS_RECEIVED: D-function Input: MINIMUM_PARTIALS_RECEIVED:signatured <KEY_CREATION-# =:integer, NODES-RECEIVED_FROM :set of node-id. partials..JT"eceived = :transfer-kind> . . . Comment: The instant node adds its signature to the set of node lds mput lff this set is a subset of the instant node's PARTIALS-RECEIVED-FROM. 89 Exceptions: NOT_ALL-PARTIALS_RECEIVED : 3n:node-id ~n E: NODES-RECEIVED-FROM 1\ n ~ PARTIALS_RECEIVED_FROM 1\ n OWN_NODEjl\ KEY_CREATION_# ¢: 0 ¢: Effects: sign (MINIM UM_PARTIALS-RECEIVED, N ODE_PR!VATE) ISSUE- CHECKPOINT: D-function Output: CHECKPOINT :signed <INDIVIDUAL_ V-FUNCTIONS = : e.ny-type, CONSENSUS_ V-FUNCTIONS = : any-type, ALL_CURRENLSECRETS : sealed<APPLICATION_SECRET_ V-FUNCTIONS =: e.ny-typc)' ALL-NE'r'I_SECRETS : sealed <NEW_APPLICATION_SECRET_ V-FUNCTIONS = : any-type), transfer-kind> Comment: Causes the receiving node to output a signed copy of all its INDIVIDUAL_ V-FUNCTIONS and CONSENSUS_ V-FUNCTJONS state. A copy of its current secret state sealed with its current APPLICATJON_PUBLICS and a copy of its new secret state sealed with NEW-APP LICATI ON_PUBLJC. Effects: checkpoint: seal(ALL-CURRENT_SECRETS, APPLJCATJON_PUBLJCS), seal (ALL-NEW-SECRETS, NEW_APPLICAT!ON_PUBL!C), sign( CHECKPOINT, APPL!CATJON_PRIVATE)
Chapter IV Single Vault Systems A simple single vault system is presented to introduce and illustrate some of the basic ideas of the proposed systems, and also to motivate and define the problems to be overcome by multiple vault systems. When a certified vault is first constructed by the techniques presented in Chapter IX, a suitable public key and its inverse private key are chosen by a mechanism within the vault's protected interior, using a physically random process as discussed in Chapter II. The public key is then displayed outside the vault, on a special device certified for this purpose. As far as the world outside the vault i~ concerned, the possessor of the vault's private key is the vault: it can read sealed confidential messages sent to the vault, and it can make the vault's signature. §1 Checkpoints & Restarts Introduces the notions of encrypted checkpoints and the restarts they can allow trustees to perform.
